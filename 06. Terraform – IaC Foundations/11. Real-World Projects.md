# **11. Real-World Projects**

You've learned the pieces. Variables. Modules. State. Remote backends. Security. Validation.

Now it's time to put them all together.

This isn't another tutorial explaining individual concepts. This is a complete, production-ready infrastructure project that combines everything you've learned across the previous 10 files.

We're building a real application stack:
- Multi-AZ VPC with public and private subnets
- Auto Scaling EC2 instances behind an Application Load Balancer
- RDS PostgreSQL database with Multi-AZ and encryption
- S3 bucket with CloudFront CDN for static assets
- Complete monitoring and logging
- CI/CD pipeline with GitHub Actions

This is what real Terraform projects look like. Not toy examples. Not simplified demos. Real infrastructure that you'd deploy to production.

By the end, you'll see how all 10 previous files connect into a working system.

---

## Table of Contents
1. [Architecture Overview](#1-architecture-overview)
2. [Project Structure](#2-project-structure)
3. [VPC & Networking Setup](#3-vpc--networking-setup)
4. [Compute Layer (EC2 + Auto Scaling)](#4-compute-layer-ec2--auto-scaling)
5. [Load Balancing](#5-load-balancing)
6. [Database Layer (RDS)](#6-database-layer-rds)
7. [Storage & CDN (S3 + CloudFront)](#7-storage--cdn-s3--cloudfront)
8. [Monitoring & Logging](#8-monitoring--logging)
9. [CI/CD Pipeline](#9-cicd-pipeline)
10. [Complete Code Walkthrough](#10-complete-code-walkthrough)
11. [Deployment Process](#11-deployment-process)

---

<details>
<summary><strong>1. Architecture Overview</strong></summary>

<div style="margin-left: 16px; margin-right: 16px; margin-top: 8px; margin-bottom: 8px;">

Here's what we're building: a three-tier web application with high availability, auto-scaling, and security best practices.

**ASCII Architecture Diagram:**

```
                                    ┌─────────────────────┐
                                    │   Route 53 (DNS)    │
                                    └──────────┬──────────┘
                                               │
                                    ┌──────────▼──────────┐
                                    │   CloudFront CDN    │
                                    │   (Static Assets)   │
                                    └──────────┬──────────┘
                                               │
                    ┌──────────────────────────┼──────────────────────────┐
                    │                          │                          │
         ┌──────────▼──────────┐    ┌─────────▼─────────┐    ┌──────────▼──────────┐
         │   S3 Bucket         │    │  Application      │    │                     │
         │  (Static Files)     │    │  Load Balancer    │    │                     │
         └─────────────────────┘    └─────────┬─────────┘    │                     │
                                               │              │                     │
                              ┌────────────────┼────────────┐ │                     │
                              │                │            │ │                     │
                   ┌──────────▼──────┐  ┌──────▼──────┐   │ │    VPC              │
                   │  Public Subnet   │  │ Public Subnet│   │ │  10.0.0.0/16        │
                   │   us-east-1a     │  │  us-east-1b  │   │ │                     │
                   │  10.0.1.0/24     │  │ 10.0.2.0/24  │   │ │                     │
                   └────────┬─────────┘  └──────┬───────┘   │ │                     │
                            │                   │            │ │                     │
                   ┌────────▼─────────┐ ┌───────▼────────┐  │ │                     │
                   │  NAT Gateway     │ │  NAT Gateway   │  │ │                     │
                   └────────┬─────────┘ └───────┬────────┘  │ │                     │
                            │                   │            │ │                     │
                   ┌────────▼──────────┐ ┌──────▼─────────┐ │ │                     │
                   │  Private Subnet   │ │ Private Subnet │ │ │                     │
                   │   us-east-1a      │ │  us-east-1b    │ │ │                     │
                   │  10.0.11.0/24     │ │ 10.0.12.0/24   │ │ │                     │
                   └────────┬──────────┘ └──────┬─────────┘ │ │                     │
                            │                   │            │ │                     │
              ┌─────────────▼─────┐   ┌─────────▼─────────┐ │ │                     │
              │  Auto Scaling     │   │  Auto Scaling     │ │ │                     │
              │  EC2 Instances    │   │  EC2 Instances    │ │ │                     │
              │  (App Servers)    │   │  (App Servers)    │ │ │                     │
              └─────────┬─────────┘   └─────────┬─────────┘ │ │                     │
                        │                       │            │ │                     │
                        └───────────┬───────────┘            │ │                     │
                                    │                        │ │                     │
                          ┌─────────▼─────────┐              │ │                     │
                          │  RDS Database     │              │ │                     │
                          │  (PostgreSQL)     │              │ │                     │
                          │  Multi-AZ         │              │ │                     │
                          │  Private Subnets  │              │ │                     │
                          │  10.0.21.0/24     │              │ │                     │
                          │  10.0.22.0/24     │              │ │                     │
                          └───────────────────┘              │ │                     │
                                                             └─┴─────────────────────┘

┌─────────────────────────────────────────────────────────────────────────────┐
│  Monitoring & Logging                                                        │
│  ├─ CloudWatch Logs (Application logs)                                      │
│  ├─ CloudWatch Metrics (CPU, Memory, Network)                               │
│  ├─ CloudWatch Alarms (Auto Scaling triggers, Health checks)                │
│  └─ SNS Topics (Alert notifications)                                        │
└─────────────────────────────────────────────────────────────────────────────┘
```

**What this architecture provides:**

**High Availability:**
- Multi-AZ deployment (us-east-1a and us-east-1b)
- Auto Scaling Group maintains desired instance count
- Application Load Balancer distributes traffic
- RDS Multi-AZ automatic failover

**Security:**
- Private subnets for application and database
- Public subnets only for ALB and NAT Gateways
- Security groups restrict traffic flow
- Database encrypted at rest
- S3 bucket encryption enabled
- CloudFront with HTTPS

**Scalability:**
- Auto Scaling based on CPU/memory metrics
- Load balancer distributes traffic evenly
- CloudFront CDN reduces origin load
- RDS can scale vertically

**Monitoring:**
- CloudWatch Logs for application debugging
- CloudWatch Metrics for performance tracking
- CloudWatch Alarms for proactive alerting
- SNS notifications for incidents

**Traffic Flow:**

1. User requests `app.example.com`
2. Route 53 resolves to CloudFront
3. CloudFront serves static assets from S3
4. CloudFront forwards dynamic requests to ALB
5. ALB distributes requests across EC2 instances in private subnets
6. EC2 instances process requests, query RDS database
7. NAT Gateways allow outbound internet access (updates, API calls)
8. CloudWatch collects logs and metrics
9. Alarms trigger Auto Scaling or notifications

**This is production-grade infrastructure.** Every component serves a purpose. Nothing is here for show.

</div>

</details>

---

<details>
<summary><strong>2. Project Structure</strong></summary>

<div style="margin-left: 16px; margin-right: 16px; margin-top: 8px; margin-bottom: 8px;">

Organization matters. Here's how a real project is structured:

```
terraform-webapp/
├── modules/
│   ├── vpc/
│   │   ├── main.tf
│   │   ├── variables.tf
│   │   ├── outputs.tf
│   │   └── README.md
│   ├── compute/
│   │   ├── main.tf
│   │   ├── variables.tf
│   │   ├── outputs.tf
│   │   ├── user_data.sh
│   │   └── README.md
│   ├── alb/
│   │   ├── main.tf
│   │   ├── variables.tf
│   │   ├── outputs.tf
│   │   └── README.md
│   ├── rds/
│   │   ├── main.tf
│   │   ├── variables.tf
│   │   ├── outputs.tf
│   │   └── README.md
│   ├── cdn/
│   │   ├── main.tf
│   │   ├── variables.tf
│   │   ├── outputs.tf
│   │   └── README.md
│   └── monitoring/
│       ├── main.tf
│       ├── variables.tf
│       ├── outputs.tf
│       └── README.md
├── environments/
│   ├── dev/
│   │   ├── main.tf
│   │   ├── variables.tf
│   │   ├── terraform.tfvars
│   │   ├── backend.tf
│   │   └── outputs.tf
│   ├── staging/
│   │   ├── main.tf
│   │   ├── variables.tf
│   │   ├── terraform.tfvars
│   │   ├── backend.tf
│   │   └── outputs.tf
│   └── prod/
│       ├── main.tf
│       ├── variables.tf
│       ├── terraform.tfvars
│       ├── backend.tf
│       └── outputs.tf
├── .github/
│   └── workflows/
│       ├── terraform-plan.yml
│       └── terraform-apply.yml
├── .gitignore
├── README.md
└── LICENSE
```

**Why this structure:**

**Modules** (`modules/`) — Reusable components (File 06)
- Each module is self-contained
- Can be used across environments
- Versioned and documented

**Environments** (`environments/`) — Per-environment configurations (File 07)
- Separate state for dev/staging/prod
- Different variable values per environment
- Isolated backends

**CI/CD** (`.github/workflows/`) — Automation (this file, section 9)
- Automated testing on pull requests
- Controlled deployments to production

**Why NOT workspaces?** (File 07)
Workspaces are convenient for experiments but dangerous for production. Separate directories give you:
- Clear separation of state
- Explicit configuration per environment
- No accidental deployments to wrong environment
- Better access control (different IAM roles per environment)

**Module responsibilities:**

| Module | Purpose | Outputs |
|--------|---------|---------|
| `vpc` | Network foundation | VPC ID, subnet IDs, NAT Gateway IPs |
| `compute` | EC2 + Auto Scaling | Auto Scaling Group ID, Launch Template ID |
| `alb` | Load balancing | ALB DNS name, Target Group ARN |
| `rds` | Database | RDS endpoint, connection string |
| `cdn` | Static assets | CloudFront domain, S3 bucket name |
| `monitoring` | Observability | CloudWatch Log Group, SNS Topic ARN |

**Environment configurations:**

Each environment uses the same modules with different values:

**Dev:**
- 1 NAT Gateway (cost savings)
- t3.micro instances
- db.t3.micro database
- Minimal Auto Scaling (1-2 instances)

**Staging:**
- 2 NAT Gateways (Multi-AZ)
- t3.small instances
- db.t3.small database
- Moderate Auto Scaling (2-4 instances)

**Prod:**
- 2 NAT Gateways (Multi-AZ)
- t3.medium instances
- db.t3.medium database (Multi-AZ)
- Aggressive Auto Scaling (3-10 instances)

**This structure scales.** Add a new environment? Copy `prod/` to `dr/`. Add a new module? Drop it in `modules/`. Everything stays organized.

</div>

</details>

---

<details>
<summary><strong>3. VPC & Networking Setup</strong></summary>

<div style="margin-left: 16px; margin-right: 16px; margin-top: 8px; margin-bottom: 8px;">

The foundation of everything. VPC, subnets, routing, NAT Gateways, security.

**Concepts from File 03** (Resources & Data Sources)

**modules/vpc/main.tf:**

```hcl
# VPC
resource "aws_vpc" "main" {
  cidr_block           = var.vpc_cidr
  enable_dns_hostnames = true
  enable_dns_support   = true

  tags = merge(
    var.common_tags,
    {
      Name = "${var.project_name}-vpc-${var.environment}"
    }
  )
}

# Internet Gateway
resource "aws_internet_gateway" "main" {
  vpc_id = aws_vpc.main.id

  tags = merge(
    var.common_tags,
    {
      Name = "${var.project_name}-igw-${var.environment}"
    }
  )
}

# Public Subnets (for ALB and NAT Gateways)
resource "aws_subnet" "public" {
  count             = length(var.availability_zones)
  vpc_id            = aws_vpc.main.id
  cidr_block        = cidrsubnet(var.vpc_cidr, 8, count.index)
  availability_zone = var.availability_zones[count.index]

  map_public_ip_on_launch = true

  tags = merge(
    var.common_tags,
    {
      Name = "${var.project_name}-public-${var.availability_zones[count.index]}-${var.environment}"
      Type = "public"
    }
  )
}

# Private Subnets (for application servers)
resource "aws_subnet" "private" {
  count             = length(var.availability_zones)
  vpc_id            = aws_vpc.main.id
  cidr_block        = cidrsubnet(var.vpc_cidr, 8, count.index + 10)
  availability_zone = var.availability_zones[count.index]

  tags = merge(
    var.common_tags,
    {
      Name = "${var.project_name}-private-${var.availability_zones[count.index]}-${var.environment}"
      Type = "private"
    }
  )
}

# Database Subnets (isolated from application)
resource "aws_subnet" "database" {
  count             = length(var.availability_zones)
  vpc_id            = aws_vpc.main.id
  cidr_block        = cidrsubnet(var.vpc_cidr, 8, count.index + 20)
  availability_zone = var.availability_zones[count.index]

  tags = merge(
    var.common_tags,
    {
      Name = "${var.project_name}-database-${var.availability_zones[count.index]}-${var.environment}"
      Type = "database"
    }
  )
}

# Elastic IPs for NAT Gateways
resource "aws_eip" "nat" {
  count  = var.enable_nat_gateway ? length(var.availability_zones) : 0
  domain = "vpc"

  tags = merge(
    var.common_tags,
    {
      Name = "${var.project_name}-nat-eip-${var.availability_zones[count.index]}-${var.environment}"
    }
  )

  depends_on = [aws_internet_gateway.main]
}

# NAT Gateways (for private subnet internet access)
resource "aws_nat_gateway" "main" {
  count         = var.enable_nat_gateway ? length(var.availability_zones) : 0
  allocation_id = aws_eip.nat[count.index].id
  subnet_id     = aws_subnet.public[count.index].id

  tags = merge(
    var.common_tags,
    {
      Name = "${var.project_name}-nat-${var.availability_zones[count.index]}-${var.environment}"
    }
  )

  depends_on = [aws_internet_gateway.main]
}

# Public Route Table
resource "aws_route_table" "public" {
  vpc_id = aws_vpc.main.id

  route {
    cidr_block = "0.0.0.0/0"
    gateway_id = aws_internet_gateway.main.id
  }

  tags = merge(
    var.common_tags,
    {
      Name = "${var.project_name}-public-rt-${var.environment}"
    }
  )
}

# Associate Public Subnets with Public Route Table
resource "aws_route_table_association" "public" {
  count          = length(aws_subnet.public)
  subnet_id      = aws_subnet.public[count.index].id
  route_table_id = aws_route_table.public.id
}

# Private Route Tables (one per AZ for NAT Gateway redundancy)
resource "aws_route_table" "private" {
  count  = length(var.availability_zones)
  vpc_id = aws_vpc.main.id

  route {
    cidr_block     = "0.0.0.0/0"
    nat_gateway_id = var.enable_nat_gateway ? aws_nat_gateway.main[count.index].id : null
  }

  tags = merge(
    var.common_tags,
    {
      Name = "${var.project_name}-private-rt-${var.availability_zones[count.index]}-${var.environment}"
    }
  )
}

# Associate Private Subnets with Private Route Tables
resource "aws_route_table_association" "private" {
  count          = length(aws_subnet.private)
  subnet_id      = aws_subnet.private[count.index].id
  route_table_id = aws_route_table.private[count.index].id
}

# Database Route Tables
resource "aws_route_table" "database" {
  count  = length(var.availability_zones)
  vpc_id = aws_vpc.main.id

  tags = merge(
    var.common_tags,
    {
      Name = "${var.project_name}-database-rt-${var.availability_zones[count.index]}-${var.environment}"
    }
  )
}

# Associate Database Subnets with Database Route Tables
resource "aws_route_table_association" "database" {
  count          = length(aws_subnet.database)
  subnet_id      = aws_subnet.database[count.index].id
  route_table_id = aws_route_table.database[count.index].id
}

# VPC Flow Logs (monitoring network traffic)
resource "aws_flow_log" "main" {
  count                = var.enable_flow_logs ? 1 : 0
  iam_role_arn         = aws_iam_role.flow_logs[0].arn
  log_destination      = aws_cloudwatch_log_group.flow_logs[0].arn
  traffic_type         = "ALL"
  vpc_id               = aws_vpc.main.id
}

resource "aws_cloudwatch_log_group" "flow_logs" {
  count             = var.enable_flow_logs ? 1 : 0
  name              = "/aws/vpc/${var.project_name}-${var.environment}"
  retention_in_days = 30

  tags = var.common_tags
}

resource "aws_iam_role" "flow_logs" {
  count = var.enable_flow_logs ? 1 : 0
  name  = "${var.project_name}-vpc-flow-logs-${var.environment}"

  assume_role_policy = jsonencode({
    Version = "2012-10-17"
    Statement = [
      {
        Action = "sts:AssumeRole"
        Effect = "Allow"
        Principal = {
          Service = "vpc-flow-logs.amazonaws.com"
        }
      }
    ]
  })

  tags = var.common_tags
}

resource "aws_iam_role_policy" "flow_logs" {
  count = var.enable_flow_logs ? 1 : 0
  name  = "flow-logs-policy"
  role  = aws_iam_role.flow_logs[0].id

  policy = jsonencode({
    Version = "2012-10-17"
    Statement = [
      {
        Action = [
          "logs:CreateLogGroup",
          "logs:CreateLogStream",
          "logs:PutLogEvents",
          "logs:DescribeLogGroups",
          "logs:DescribeLogStreams"
        ]
        Effect   = "Allow"
        Resource = "*"
      }
    ]
  })
}
```

**modules/vpc/variables.tf:**

```hcl
variable "project_name" {
  type        = string
  description = "Project name for resource naming"
}

variable "environment" {
  type        = string
  description = "Environment (dev, staging, prod)"
  
  validation {
    condition     = contains(["dev", "staging", "prod"], var.environment)
    error_message = "Environment must be dev, staging, or prod."
  }
}

variable "vpc_cidr" {
  type        = string
  description = "CIDR block for VPC"
  
  validation {
    condition     = can(cidrhost(var.vpc_cidr, 0))
    error_message = "VPC CIDR must be valid IPv4 CIDR notation."
  }
}

variable "availability_zones" {
  type        = list(string)
  description = "List of availability zones"
}

variable "enable_nat_gateway" {
  type        = bool
  description = "Enable NAT Gateway for private subnets"
  default     = true
}

variable "enable_flow_logs" {
  type        = bool
  description = "Enable VPC Flow Logs"
  default     = true
}

variable "common_tags" {
  type        = map(string)
  description = "Common tags for all resources"
  default     = {}
}
```

**modules/vpc/outputs.tf:**

```hcl
output "vpc_id" {
  value       = aws_vpc.main.id
  description = "ID of the VPC"
}

output "vpc_cidr" {
  value       = aws_vpc.main.cidr_block
  description = "CIDR block of the VPC"
}

output "public_subnet_ids" {
  value       = aws_subnet.public[*].id
  description = "List of public subnet IDs"
}

output "private_subnet_ids" {
  value       = aws_subnet.private[*].id
  description = "List of private subnet IDs"
}

output "database_subnet_ids" {
  value       = aws_subnet.database[*].id
  description = "List of database subnet IDs"
}

output "nat_gateway_ips" {
  value       = aws_eip.nat[*].public_ip
  description = "Public IPs of NAT Gateways"
}
```

**Key concepts used:**

✅ **count** (File 05) — Creates multiple subnets across AZs
✅ **cidrsubnet()** (File 04) — Automatically calculates subnet CIDRs
✅ **merge()** (File 04) — Combines common tags with resource-specific tags
✅ **Validation** (File 10) — Validates environment and CIDR inputs
✅ **Outputs** (File 04) — Exports values for other modules

**Network isolation:**
- Public subnets: ALB, NAT Gateways
- Private subnets: Application servers
- Database subnets: RDS (no direct internet)

**This is the foundation.** Everything else builds on this VPC.

</div>

</details>

---

<details>
<summary><strong>4. Compute Layer (EC2 + Auto Scaling)</strong></summary>

<div style="margin-left: 16px; margin-right: 16px; margin-top: 8px; margin-bottom: 8px;">

Application servers running in Auto Scaling Groups. They scale up when traffic increases, scale down when it decreases.

**Concepts from File 05** (Loops & Conditionals)

**modules/compute/main.tf:**

```hcl
# Security Group for EC2 instances
resource "aws_security_group" "app" {
  name        = "${var.project_name}-app-sg-${var.environment}"
  description = "Security group for application servers"
  vpc_id      = var.vpc_id

  ingress {
    description     = "HTTP from ALB"
    from_port       = 80
    to_port         = 80
    protocol        = "tcp"
    security_groups = [var.alb_security_group_id]
  }

  ingress {
    description     = "HTTPS from ALB"
    from_port       = 443
    to_port         = 443
    protocol        = "tcp"
    security_groups = [var.alb_security_group_id]
  }

  egress {
    description = "Allow all outbound"
    from_port   = 0
    to_port     = 0
    protocol    = "-1"
    cidr_blocks = ["0.0.0.0/0"]
  }

  tags = merge(
    var.common_tags,
    {
      Name = "${var.project_name}-app-sg-${var.environment}"
    }
  )
}

# IAM Role for EC2 instances
resource "aws_iam_role" "app" {
  name = "${var.project_name}-app-role-${var.environment}"

  assume_role_policy = jsonencode({
    Version = "2012-10-17"
    Statement = [
      {
        Action = "sts:AssumeRole"
        Effect = "Allow"
        Principal = {
          Service = "ec2.amazonaws.com"
        }
      }
    ]
  })

  tags = var.common_tags
}

# IAM Policy for CloudWatch Logs
resource "aws_iam_role_policy" "cloudwatch_logs" {
  name = "cloudwatch-logs"
  role = aws_iam_role.app.id

  policy = jsonencode({
    Version = "2012-10-17"
    Statement = [
      {
        Effect = "Allow"
        Action = [
          "logs:CreateLogGroup",
          "logs:CreateLogStream",
          "logs:PutLogEvents",
          "logs:DescribeLogStreams"
        ]
        Resource = "arn:aws:logs:*:*:*"
      }
    ]
  })
}

# IAM Policy for Systems Manager (SSM Session Manager)
resource "aws_iam_role_policy_attachment" "ssm" {
  role       = aws_iam_role.app.name
  policy_arn = "arn:aws:iam::aws:policy/AmazonSSMManagedInstanceCore"
}

# IAM Instance Profile
resource "aws_iam_instance_profile" "app" {
  name = "${var.project_name}-app-profile-${var.environment}"
  role = aws_iam_role.app.name

  tags = var.common_tags
}

# Get latest Amazon Linux 2 AMI
data "aws_ami" "amazon_linux" {
  most_recent = true
  owners      = ["amazon"]

  filter {
    name   = "name"
    values = ["amzn2-ami-hvm-*-x86_64-gp2"]
  }

  filter {
    name   = "virtualization-type"
    values = ["hvm"]
  }
}

# Launch Template
resource "aws_launch_template" "app" {
  name_prefix   = "${var.project_name}-app-${var.environment}-"
  image_id      = data.aws_ami.amazon_linux.id
  instance_type = var.instance_type

  iam_instance_profile {
    name = aws_iam_instance_profile.app.name
  }

  network_interfaces {
    associate_public_ip_address = false
    security_groups            = [aws_security_group.app.id]
    delete_on_termination      = true
  }

  user_data = base64encode(templatefile("${path.module}/user_data.sh", {
    environment         = var.environment
    db_endpoint         = var.db_endpoint
    db_name            = var.db_name
    cloudwatch_log_group = var.cloudwatch_log_group
  }))

  tag_specifications {
    resource_type = "instance"
    tags = merge(
      var.common_tags,
      {
        Name = "${var.project_name}-app-${var.environment}"
      }
    )
  }

  tag_specifications {
    resource_type = "volume"
    tags = merge(
      var.common_tags,
      {
        Name = "${var.project_name}-app-volume-${var.environment}"
      }
    )
  }

  metadata_options {
    http_endpoint               = "enabled"
    http_tokens                 = "required"  # IMDSv2 required
    http_put_response_hop_limit = 1
  }

  monitoring {
    enabled = true
  }

  lifecycle {
    create_before_destroy = true
  }

  tags = var.common_tags
}

# Auto Scaling Group
resource "aws_autoscaling_group" "app" {
  name                = "${var.project_name}-app-asg-${var.environment}"
  vpc_zone_identifier = var.private_subnet_ids
  target_group_arns   = [var.target_group_arn]
  health_check_type   = "ELB"
  health_check_grace_period = 300

  min_size         = var.min_size
  max_size         = var.max_size
  desired_capacity = var.desired_capacity

  launch_template {
    id      = aws_launch_template.app.id
    version = "$Latest"
  }

  enabled_metrics = [
    "GroupDesiredCapacity",
    "GroupInServiceInstances",
    "GroupMinSize",
    "GroupMaxSize",
    "GroupTotalInstances"
  ]

  tag {
    key                 = "Name"
    value               = "${var.project_name}-app-${var.environment}"
    propagate_at_launch = true
  }

  dynamic "tag" {
    for_each = var.common_tags
    content {
      key                 = tag.key
      value               = tag.value
      propagate_at_launch = true
    }
  }

  lifecycle {
    create_before_destroy = true
  }
}

# Auto Scaling Policy - Scale Up
resource "aws_autoscaling_policy" "scale_up" {
  name                   = "${var.project_name}-scale-up-${var.environment}"
  autoscaling_group_name = aws_autoscaling_group.app.name
  adjustment_type        = "ChangeInCapacity"
  scaling_adjustment     = 1
  cooldown              = 300
}

# CloudWatch Alarm - High CPU (triggers scale up)
resource "aws_cloudwatch_metric_alarm" "high_cpu" {
  alarm_name          = "${var.project_name}-high-cpu-${var.environment}"
  comparison_operator = "GreaterThanThreshold"
  evaluation_periods  = 2
  metric_name         = "CPUUtilization"
  namespace           = "AWS/EC2"
  period              = 120
  statistic           = "Average"
  threshold           = 70

  dimensions = {
    AutoScalingGroupName = aws_autoscaling_group.app.name
  }

  alarm_description = "This metric monitors EC2 CPU utilization"
  alarm_actions     = [aws_autoscaling_policy.scale_up.arn]

  tags = var.common_tags
}

# Auto Scaling Policy - Scale Down
resource "aws_autoscaling_policy" "scale_down" {
  name                   = "${var.project_name}-scale-down-${var.environment}"
  autoscaling_group_name = aws_autoscaling_group.app.name
  adjustment_type        = "ChangeInCapacity"
  scaling_adjustment     = -1
  cooldown              = 300
}

# CloudWatch Alarm - Low CPU (triggers scale down)
resource "aws_cloudwatch_metric_alarm" "low_cpu" {
  alarm_name          = "${var.project_name}-low-cpu-${var.environment}"
  comparison_operator = "LessThanThreshold"
  evaluation_periods  = 2
  metric_name         = "CPUUtilization"
  namespace           = "AWS/EC2"
  period              = 120
  statistic           = "Average"
  threshold           = 20

  dimensions = {
    AutoScalingGroupName = aws_autoscaling_group.app.name
  }

  alarm_description = "This metric monitors EC2 CPU utilization"
  alarm_actions     = [aws_autoscaling_policy.scale_down.arn]

  tags = var.common_tags
}
```

**modules/compute/user_data.sh:**

```bash
#!/bin/bash
set -e

# Update system
yum update -y

# Install CloudWatch Logs agent
yum install -y amazon-cloudwatch-agent

# Install application dependencies
yum install -y docker

# Start Docker
systemctl start docker
systemctl enable docker

# Configure CloudWatch Logs
cat > /opt/aws/amazon-cloudwatch-agent/etc/cloudwatch-config.json <<EOF
{
  "logs": {
    "logs_collected": {
      "files": {
        "collect_list": [
          {
            "file_path": "/var/log/app.log",
            "log_group_name": "${cloudwatch_log_group}",
            "log_stream_name": "{instance_id}/app.log"
          }
        ]
      }
    }
  }
}
EOF

# Start CloudWatch agent
/opt/aws/amazon-cloudwatch-agent/bin/amazon-cloudwatch-agent-ctl \
  -a fetch-config \
  -m ec2 \
  -c file:/opt/aws/amazon-cloudwatch-agent/etc/cloudwatch-config.json \
  -s

# Pull and run application container
docker run -d \
  --name app \
  --restart always \
  -p 80:3000 \
  -e ENVIRONMENT=${environment} \
  -e DB_HOST=${db_endpoint} \
  -e DB_NAME=${db_name} \
  your-docker-image:latest

echo "Setup complete!"
```

**modules/compute/variables.tf:**

```hcl
variable "project_name" {
  type = string
}

variable "environment" {
  type = string
}

variable "vpc_id" {
  type = string
}

variable "private_subnet_ids" {
  type = list(string)
}

variable "alb_security_group_id" {
  type = string
}

variable "target_group_arn" {
  type = string
}

variable "instance_type" {
  type    = string
  default = "t3.micro"
  
  validation {
    condition     = can(regex("^t[23]\\.(nano|micro|small|medium|large|xlarge|2xlarge)$", var.instance_type))
    error_message = "Instance type must be valid t2 or t3 size."
  }
}

variable "min_size" {
  type    = number
  default = 1
}

variable "max_size" {
  type    = number
  default = 5
}

variable "desired_capacity" {
  type    = number
  default = 2
}

variable "db_endpoint" {
  type = string
}

variable "db_name" {
  type = string
}

variable "cloudwatch_log_group" {
  type = string
}

variable "common_tags" {
  type = map(string)
}
```

**modules/compute/outputs.tf:**

```hcl
output "asg_id" {
  value = aws_autoscaling_group.app.id
}

output "asg_name" {
  value = aws_autoscaling_group.app.name
}

output "launch_template_id" {
  value = aws_launch_template.app.id
}

output "security_group_id" {
  value = aws_security_group.app.id
}
```

**Key concepts used:**

✅ **Data sources** (File 03) — Fetches latest Amazon Linux AMI
✅ **dynamic blocks** (File 05) — Dynamically adds tags to ASG
✅ **templatefile()** (File 04) — Passes variables to user_data script
✅ **Lifecycle** (File 09) — create_before_destroy for zero-downtime updates
✅ **CloudWatch integration** (File 08) — Logs and metrics

**Auto Scaling in action:**
- CPU > 70% for 4 minutes → Add 1 instance
- CPU < 20% for 4 minutes → Remove 1 instance
- Min 1 instance (dev), 2 instances (staging/prod)
- Max 5 instances (dev), 10 instances (prod)

</div>

</details>

---

<details>
<summary><strong>5. Load Balancing</strong></summary>

<div style="margin-left: 16px; margin-right: 16px; margin-top: 8px; margin-bottom: 8px;">

Application Load Balancer distributes traffic across EC2 instances. Health checks ensure only healthy instances receive traffic.

**modules/alb/main.tf:**

```hcl
# Security Group for ALB
resource "aws_security_group" "alb" {
  name        = "${var.project_name}-alb-sg-${var.environment}"
  description = "Security group for Application Load Balancer"
  vpc_id      = var.vpc_id

  ingress {
    description = "HTTP from internet"
    from_port   = 80
    to_port     = 80
    protocol    = "tcp"
    cidr_blocks = ["0.0.0.0/0"]
  }

  ingress {
    description = "HTTPS from internet"
    from_port   = 443
    to_port     = 443
    protocol    = "tcp"
    cidr_blocks = ["0.0.0.0/0"]
  }

  egress {
    description = "Allow all outbound"
    from_port   = 0
    to_port     = 0
    protocol    = "-1"
    cidr_blocks = ["0.0.0.0/0"]
  }

  tags = merge(
    var.common_tags,
    {
      Name = "${var.project_name}-alb-sg-${var.environment}"
    }
  )
}

# Application Load Balancer
resource "aws_lb" "main" {
  name               = "${var.project_name}-alb-${var.environment}"
  internal           = false
  load_balancer_type = "application"
  security_groups    = [aws_security_group.alb.id]
  subnets            = var.public_subnet_ids

  enable_deletion_protection = var.environment == "prod" ? true : false
  enable_http2              = true
  enable_cross_zone_load_balancing = true

  access_logs {
    bucket  = var.log_bucket_name
    prefix  = "alb-logs"
    enabled = var.enable_access_logs
  }

  tags = merge(
    var.common_tags,
    {
      Name = "${var.project_name}-alb-${var.environment}"
    }
  )
}

# Target Group
resource "aws_lb_target_group" "app" {
  name     = "${var.project_name}-tg-${var.environment}"
  port     = 80
  protocol = "HTTP"
  vpc_id   = var.vpc_id

  health_check {
    enabled             = true
    healthy_threshold   = 2
    interval            = 30
    matcher            = "200"
    path               = "/health"
    port               = "traffic-port"
    protocol           = "HTTP"
    timeout            = 5
    unhealthy_threshold = 2
  }

  deregistration_delay = 30

  stickiness {
    type            = "lb_cookie"
    cookie_duration = 86400
    enabled         = true
  }

  tags = merge(
    var.common_tags,
    {
      Name = "${var.project_name}-tg-${var.environment}"
    }
  )
}

# HTTP Listener (redirect to HTTPS)
resource "aws_lb_listener" "http" {
  load_balancer_arn = aws_lb.main.arn
  port              = 80
  protocol          = "HTTP"

  default_action {
    type = "redirect"

    redirect {
      port        = "443"
      protocol    = "HTTPS"
      status_code = "HTTP_301"
    }
  }
}

# HTTPS Listener (requires ACM certificate)
resource "aws_lb_listener" "https" {
  count             = var.certificate_arn != "" ? 1 : 0
  load_balancer_arn = aws_lb.main.arn
  port              = 443
  protocol          = "HTTPS"
  ssl_policy        = "ELBSecurityPolicy-TLS-1-2-2017-01"
  certificate_arn   = var.certificate_arn

  default_action {
    type             = "forward"
    target_group_arn = aws_lb_target_group.app.arn
  }
}

# HTTP Listener (for non-HTTPS setup)
resource "aws_lb_listener" "http_forward" {
  count             = var.certificate_arn == "" ? 1 : 0
  load_balancer_arn = aws_lb.main.arn
  port              = 80
  protocol          = "HTTP"

  default_action {
    type             = "forward"
    target_group_arn = aws_lb_target_group.app.arn
  }
}
```

**modules/alb/variables.tf:**

```hcl
variable "project_name" {
  type = string
}

variable "environment" {
  type = string
}

variable "vpc_id" {
  type = string
}

variable "public_subnet_ids" {
  type = list(string)
}

variable "certificate_arn" {
  type        = string
  description = "ARN of ACM certificate for HTTPS"
  default     = ""
}

variable "enable_access_logs" {
  type    = bool
  default = false
}

variable "log_bucket_name" {
  type    = string
  default = ""
}

variable "common_tags" {
  type = map(string)
}
```

**modules/alb/outputs.tf:**

```hcl
output "alb_dns_name" {
  value       = aws_lb.main.dns_name
  description = "DNS name of the load balancer"
}

output "alb_arn" {
  value = aws_lb.main.arn
}

output "target_group_arn" {
  value = aws_lb_target_group.app.arn
}

output "security_group_id" {
  value = aws_security_group.alb.id
}
```

**Key features:**

✅ **Health checks** — Only route to healthy instances
✅ **Sticky sessions** — Same user → same instance (for session management)
✅ **HTTP → HTTPS redirect** — Force secure connections
✅ **Cross-zone load balancing** — Even distribution across AZs
✅ **Deletion protection** — Prevent accidental deletion in prod
✅ **Access logs** — Track all requests (S3)

**Traffic flow:**
1. User requests `app.example.com`
2. Request hits ALB in public subnet
3. ALB checks health of target instances
4. ALB forwards request to healthy instance in private subnet
5. Instance processes request
6. Response flows back through ALB to user

</div>

</details>

---

<details>
<summary><strong>6. Database Layer (RDS)</strong></summary>

<div style="margin-left: 16px; margin-right: 16px; margin-top: 8px; margin-bottom: 8px;">

RDS PostgreSQL with Multi-AZ, encryption, automated backups, and monitoring.

**Concepts from File 02** (State) and **File 10** (Security)

**modules/rds/main.tf:**

```hcl
# Security Group for RDS
resource "aws_security_group" "rds" {
  name        = "${var.project_name}-rds-sg-${var.environment}"
  description = "Security group for RDS database"
  vpc_id      = var.vpc_id

  ingress {
    description     = "PostgreSQL from application"
    from_port       = 5432
    to_port         = 5432
    protocol        = "tcp"
    security_groups = [var.app_security_group_id]
  }

  egress {
    description = "Allow all outbound"
    from_port   = 0
    to_port     = 0
    protocol    = "-1"
    cidr_blocks = ["0.0.0.0/0"]
  }

  tags = merge(
    var.common_tags,
    {
      Name = "${var.project_name}-rds-sg-${var.environment}"
    }
  )
}

# DB Subnet Group
resource "aws_db_subnet_group" "main" {
  name       = "${var.project_name}-db-subnet-${var.environment}"
  subnet_ids = var.database_subnet_ids

  tags = merge(
    var.common_tags,
    {
      Name = "${var.project_name}-db-subnet-${var.environment}"
    }
  )
}

# DB Parameter Group
resource "aws_db_parameter_group" "postgres" {
  name   = "${var.project_name}-postgres-${var.environment}"
  family = "postgres15"

  parameter {
    name  = "log_connections"
    value = "1"
  }

  parameter {
    name  = "log_disconnections"
    value = "1"
  }

  parameter {
    name  = "log_duration"
    value = "1"
  }

  tags = var.common_tags
}

# Generate random password for RDS
resource "random_password" "db_password" {
  length  = 32
  special = true
}

# Store password in Secrets Manager (File 10 - Security)
resource "aws_secretsmanager_secret" "db_password" {
  name = "${var.project_name}-db-password-${var.environment}"

  tags = var.common_tags
}

resource "aws_secretsmanager_secret_version" "db_password" {
  secret_id     = aws_secretsmanager_secret.db_password.id
  secret_string = random_password.db_password.result
}

# RDS Instance
resource "aws_db_instance" "main" {
  identifier = "${var.project_name}-db-${var.environment}"

  engine               = "postgres"
  engine_version       = "15.4"
  instance_class       = var.instance_class
  allocated_storage    = var.allocated_storage
  storage_type         = "gp3"
  storage_encrypted    = true
  kms_key_id          = var.kms_key_arn

  db_name  = var.database_name
  username = var.database_username
  password = random_password.db_password.result

  db_subnet_group_name   = aws_db_subnet_group.main.name
  vpc_security_group_ids = [aws_security_group.rds.id]
  parameter_group_name   = aws_db_parameter_group.postgres.name

  multi_az               = var.multi_az
  publicly_accessible    = false
  skip_final_snapshot    = var.environment != "prod"
  final_snapshot_identifier = var.environment == "prod" ? "${var.project_name}-db-final-${formatdate("YYYY-MM-DD-hhmm", timestamp())}" : null

  backup_retention_period = var.backup_retention_days
  backup_window          = "03:00-04:00"
  maintenance_window     = "Mon:04:00-Mon:05:00"

  enabled_cloudwatch_logs_exports = ["postgresql", "upgrade"]

  deletion_protection = var.environment == "prod"

  tags = merge(
    var.common_tags,
    {
      Name = "${var.project_name}-db-${var.environment}"
    }
  )

  lifecycle {
    ignore_changes = [password]
  }
}

# CloudWatch Alarms for RDS
resource "aws_cloudwatch_metric_alarm" "database_cpu" {
  alarm_name          = "${var.project_name}-db-cpu-${var.environment}"
  comparison_operator = "GreaterThanThreshold"
  evaluation_periods  = 2
  metric_name         = "CPUUtilization"
  namespace           = "AWS/RDS"
  period              = 300
  statistic           = "Average"
  threshold           = 80

  dimensions = {
    DBInstanceIdentifier = aws_db_instance.main.id
  }

  alarm_description = "RDS CPU utilization is too high"
  alarm_actions     = var.sns_topic_arn != "" ? [var.sns_topic_arn] : []

  tags = var.common_tags
}

resource "aws_cloudwatch_metric_alarm" "database_storage" {
  alarm_name          = "${var.project_name}-db-storage-${var.environment}"
  comparison_operator = "LessThanThreshold"
  evaluation_periods  = 1
  metric_name         = "FreeStorageSpace"
  namespace           = "AWS/RDS"
  period              = 300
  statistic           = "Average"
  threshold           = 5000000000  # 5 GB in bytes

  dimensions = {
    DBInstanceIdentifier = aws_db_instance.main.id
  }

  alarm_description = "RDS free storage space is low"
  alarm_actions     = var.sns_topic_arn != "" ? [var.sns_topic_arn] : []

  tags = var.common_tags
}

resource "aws_cloudwatch_metric_alarm" "database_connections" {
  alarm_name          = "${var.project_name}-db-connections-${var.environment}"
  comparison_operator = "GreaterThanThreshold"
  evaluation_periods  = 2
  metric_name         = "DatabaseConnections"
  namespace           = "AWS/RDS"
  period              = 300
  statistic           = "Average"
  threshold           = 80

  dimensions = {
    DBInstanceIdentifier = aws_db_instance.main.id
  }

  alarm_description = "RDS database connections are high"
  alarm_actions     = var.sns_topic_arn != "" ? [var.sns_topic_arn] : []

  tags = var.common_tags
}
```

**modules/rds/variables.tf:**

```hcl
variable "project_name" {
  type = string
}

variable "environment" {
  type = string
}

variable "vpc_id" {
  type = string
}

variable "database_subnet_ids" {
  type = list(string)
}

variable "app_security_group_id" {
  type = string
}

variable "instance_class" {
  type    = string
  default = "db.t3.micro"
}

variable "allocated_storage" {
  type    = number
  default = 20
}

variable "database_name" {
  type = string
}

variable "database_username" {
  type    = string
  default = "dbadmin"
}

variable "multi_az" {
  type    = bool
  default = false
}

variable "backup_retention_days" {
  type    = number
  default = 7
}

variable "kms_key_arn" {
  type    = string
  default = ""
}

variable "sns_topic_arn" {
  type    = string
  default = ""
}

variable "common_tags" {
  type = map(string)
}
```

**modules/rds/outputs.tf:**

```hcl
output "db_endpoint" {
  value       = aws_db_instance.main.endpoint
  description = "RDS instance endpoint"
}

output "db_name" {
  value = aws_db_instance.main.db_name
}

output "db_port" {
  value = aws_db_instance.main.port
}

output "db_password_secret_arn" {
  value       = aws_secretsmanager_secret.db_password.arn
  description = "ARN of Secrets Manager secret containing DB password"
}
```

**Key security features:**

✅ **Random password generation** — Never hardcode passwords
✅ **Secrets Manager** — Secure password storage (File 10)
✅ **Storage encryption** — Data encrypted at rest with KMS
✅ **Multi-AZ** — Automatic failover for high availability
✅ **Private subnets** — No public access
✅ **Automated backups** — 7-day retention (configurable)
✅ **Final snapshot** — Prevent data loss on prod deletion
✅ **CloudWatch alarms** — CPU, storage, connections
✅ **ignore_changes** (File 09) — Don't reset password on apply

**Connection from EC2:**
```bash
# Password stored in Secrets Manager, retrieved by application
psql -h $DB_ENDPOINT -U dbadmin -d myapp
```

</div>

</details>

---

<details>
<summary><strong>7. Storage & CDN (S3 + CloudFront)</strong></summary>

<div style="margin-left: 16px; margin-right: 16px; margin-top: 8px; margin-bottom: 8px;">

S3 for static assets, CloudFront for global content delivery with caching.

**modules/cdn/main.tf:**

```hcl
# S3 Bucket for static assets
resource "aws_s3_bucket" "assets" {
  bucket = "${var.project_name}-assets-${var.environment}-${data.aws_caller_identity.current.account_id}"

  tags = merge(
    var.common_tags,
    {
      Name = "${var.project_name}-assets-${var.environment}"
    }
  )
}

# Get AWS account ID
data "aws_caller_identity" "current" {}

# Block public access
resource "aws_s3_bucket_public_access_block" "assets" {
  bucket = aws_s3_bucket.assets.id

  block_public_acls       = true
  block_public_policy     = true
  ignore_public_acls      = true
  restrict_public_buckets = true
}

# Enable versioning
resource "aws_s3_bucket_versioning" "assets" {
  bucket = aws_s3_bucket.assets.id

  versioning_configuration {
    status = "Enabled"
  }
}

# Enable encryption
resource "aws_s3_bucket_server_side_encryption_configuration" "assets" {
  bucket = aws_s3_bucket.assets.id

  rule {
    apply_server_side_encryption_by_default {
      sse_algorithm = "AES256"
    }
  }
}

# Lifecycle policy (delete old versions)
resource "aws_s3_bucket_lifecycle_configuration" "assets" {
  bucket = aws_s3_bucket.assets.id

  rule {
    id     = "delete-old-versions"
    status = "Enabled"

    noncurrent_version_expiration {
      noncurrent_days = 30
    }
  }

  rule {
    id     = "delete-incomplete-multipart-uploads"
    status = "Enabled"

    abort_incomplete_multipart_upload {
      days_after_initiation = 7
    }
  }
}

# CloudFront Origin Access Control
resource "aws_cloudfront_origin_access_control" "main" {
  name                              = "${var.project_name}-oac-${var.environment}"
  description                       = "OAC for ${var.project_name} ${var.environment}"
  origin_access_control_origin_type = "s3"
  signing_behavior                  = "always"
  signing_protocol                  = "sigv4"
}

# CloudFront Distribution
resource "aws_cloudfront_distribution" "main" {
  enabled             = true
  is_ipv6_enabled     = true
  comment             = "${var.project_name} CDN - ${var.environment}"
  default_root_object = "index.html"
  price_class         = var.price_class

  origin {
    domain_name              = aws_s3_bucket.assets.bucket_regional_domain_name
    origin_id                = "S3-${aws_s3_bucket.assets.id}"
    origin_access_control_id = aws_cloudfront_origin_access_control.main.id
  }

  default_cache_behavior {
    allowed_methods  = ["GET", "HEAD", "OPTIONS"]
    cached_methods   = ["GET", "HEAD"]
    target_origin_id = "S3-${aws_s3_bucket.assets.id}"

    forwarded_values {
      query_string = false

      cookies {
        forward = "none"
      }
    }

    viewer_protocol_policy = "redirect-to-https"
    min_ttl                = 0
    default_ttl            = 3600
    max_ttl                = 86400
    compress               = true
  }

  restrictions {
    geo_restriction {
      restriction_type = "none"
    }
  }

  viewer_certificate {
    cloudfront_default_certificate = true
  }

  tags = merge(
    var.common_tags,
    {
      Name = "${var.project_name}-cdn-${var.environment}"
    }
  )
}

# S3 Bucket Policy (allow CloudFront access)
resource "aws_s3_bucket_policy" "assets" {
  bucket = aws_s3_bucket.assets.id

  policy = jsonencode({
    Version = "2012-10-17"
    Statement = [
      {
        Sid    = "AllowCloudFrontServicePrincipal"
        Effect = "Allow"
        Principal = {
          Service = "cloudfront.amazonaws.com"
        }
        Action   = "s3:GetObject"
        Resource = "${aws_s3_bucket.assets.arn}/*"
        Condition = {
          StringEquals = {
            "AWS:SourceArn" = aws_cloudfront_distribution.main.arn
          }
        }
      }
    ]
  })
}
```

**modules/cdn/variables.tf:**

```hcl
variable "project_name" {
  type = string
}

variable "environment" {
  type = string
}

variable "price_class" {
  type        = string
  description = "CloudFront price class"
  default     = "PriceClass_100"  # US, Canada, Europe

  validation {
    condition     = contains(["PriceClass_All", "PriceClass_200", "PriceClass_100"], var.price_class)
    error_message = "Price class must be PriceClass_All, PriceClass_200, or PriceClass_100."
  }
}

variable "common_tags" {
  type = map(string)
}
```

**modules/cdn/outputs.tf:**

```hcl
output "bucket_name" {
  value = aws_s3_bucket.assets.id
}

output "bucket_arn" {
  value = aws_s3_bucket.assets.arn
}

output "cloudfront_domain_name" {
  value       = aws_cloudfront_distribution.main.domain_name
  description = "CloudFront distribution domain name"
}

output "cloudfront_distribution_id" {
  value = aws_cloudfront_distribution.main.id
}
```

**Key features:**

✅ **Private S3 bucket** — No public access, only via CloudFront
✅ **Origin Access Control** — Modern authentication (replaces OAI)
✅ **Encryption at rest** — AES256
✅ **Versioning** — Track file changes
✅ **Lifecycle policies** — Delete old versions automatically
✅ **HTTPS enforcement** — Redirect HTTP → HTTPS
✅ **Compression** — Gzip compression for faster delivery
✅ **Global caching** — CloudFront edge locations worldwide

**Usage:**
```bash
# Upload assets to S3
aws s3 cp static/ s3://my-project-assets-prod-123456789012/ --recursive

# Assets available via CloudFront
https://d1234567890.cloudfront.net/logo.png
```

</div>

</details>

---

<details>
<summary><strong>8. Monitoring & Logging</strong></summary>

<div style="margin-left: 16px; margin-right: 16px; margin-top: 8px; margin-bottom: 8px;">

CloudWatch Logs, Metrics, Alarms, and SNS for complete observability.

**modules/monitoring/main.tf:**

```hcl
# CloudWatch Log Group for application logs
resource "aws_cloudwatch_log_group" "app" {
  name              = "/aws/${var.project_name}/${var.environment}/app"
  retention_in_days = var.log_retention_days

  tags = merge(
    var.common_tags,
    {
      Name = "${var.project_name}-app-logs-${var.environment}"
    }
  )
}

# SNS Topic for alarms
resource "aws_sns_topic" "alarms" {
  name = "${var.project_name}-alarms-${var.environment}"

  tags = var.common_tags
}

# SNS Topic Subscription (email)
resource "aws_sns_topic_subscription" "alarms_email" {
  count     = var.alarm_email != "" ? 1 : 0
  topic_arn = aws_sns_topic.alarms.arn
  protocol  = "email"
  endpoint  = var.alarm_email
}

# CloudWatch Dashboard
resource "aws_cloudwatch_dashboard" "main" {
  dashboard_name = "${var.project_name}-${var.environment}"

  dashboard_body = jsonencode({
    widgets = [
      {
        type = "metric"
        properties = {
          metrics = [
            ["AWS/EC2", "CPUUtilization", { stat = "Average" }],
            ["AWS/RDS", "CPUUtilization", { stat = "Average" }]
          ]
          period = 300
          stat   = "Average"
          region = var.region
          title  = "CPU Utilization"
        }
      },
      {
        type = "metric"
        properties = {
          metrics = [
            ["AWS/ApplicationELB", "RequestCount", { stat = "Sum" }],
            [".", "TargetResponseTime", { stat = "Average" }]
          ]
          period = 300
          region = var.region
          title  = "ALB Metrics"
        }
      },
      {
        type = "metric"
        properties = {
          metrics = [
            ["AWS/RDS", "DatabaseConnections", { stat = "Average" }],
            [".", "FreeStorageSpace", { stat = "Average" }]
          ]
          period = 300
          region = var.region
          title  = "RDS Metrics"
        }
      }
    ]
  })
}

# CloudWatch Alarm - ALB Target Health
resource "aws_cloudwatch_metric_alarm" "unhealthy_targets" {
  alarm_name          = "${var.project_name}-unhealthy-targets-${var.environment}"
  comparison_operator = "GreaterThanThreshold"
  evaluation_periods  = 2
  metric_name         = "UnHealthyHostCount"
  namespace           = "AWS/ApplicationELB"
  period              = 60
  statistic           = "Average"
  threshold           = 0

  dimensions = {
    TargetGroup  = var.target_group_arn_suffix
    LoadBalancer = var.alb_arn_suffix
  }

  alarm_description = "Unhealthy targets detected in target group"
  alarm_actions     = [aws_sns_topic.alarms.arn]

  tags = var.common_tags
}

# CloudWatch Alarm - ALB 5xx Errors
resource "aws_cloudwatch_metric_alarm" "alb_5xx" {
  alarm_name          = "${var.project_name}-alb-5xx-${var.environment}"
  comparison_operator = "GreaterThanThreshold"
  evaluation_periods  = 2
  metric_name         = "HTTPCode_Target_5XX_Count"
  namespace           = "AWS/ApplicationELB"
  period              = 300
  statistic           = "Sum"
  threshold           = 10

  dimensions = {
    LoadBalancer = var.alb_arn_suffix
  }

  alarm_description = "Too many 5xx errors from targets"
  alarm_actions     = [aws_sns_topic.alarms.arn]

  tags = var.common_tags
}

# CloudWatch Alarm - High Response Time
resource "aws_cloudwatch_metric_alarm" "high_response_time" {
  alarm_name          = "${var.project_name}-high-response-time-${var.environment}"
  comparison_operator = "GreaterThanThreshold"
  evaluation_periods  = 2
  metric_name         = "TargetResponseTime"
  namespace           = "AWS/ApplicationELB"
  period              = 300
  statistic           = "Average"
  threshold           = 1  # 1 second

  dimensions = {
    LoadBalancer = var.alb_arn_suffix
  }

  alarm_description = "Response time is too high"
  alarm_actions     = [aws_sns_topic.alarms.arn]

  tags = var.common_tags
}

# CloudWatch Log Metric Filter (track specific errors)
resource "aws_cloudwatch_log_metric_filter" "error_count" {
  name           = "${var.project_name}-error-count-${var.environment}"
  log_group_name = aws_cloudwatch_log_group.app.name
  pattern        = "[ERROR]"

  metric_transformation {
    name      = "ErrorCount"
    namespace = "${var.project_name}/${var.environment}"
    value     = "1"
  }
}

# CloudWatch Alarm for error logs
resource "aws_cloudwatch_metric_alarm" "error_logs" {
  alarm_name          = "${var.project_name}-error-logs-${var.environment}"
  comparison_operator = "GreaterThanThreshold"
  evaluation_periods  = 1
  metric_name         = "ErrorCount"
  namespace           = "${var.project_name}/${var.environment}"
  period              = 300
  statistic           = "Sum"
  threshold           = 10

  alarm_description = "Too many errors in application logs"
  alarm_actions     = [aws_sns_topic.alarms.arn]

  tags = var.common_tags
}
```

**modules/monitoring/variables.tf:**

```hcl
variable "project_name" {
  type = string
}

variable "environment" {
  type = string
}

variable "region" {
  type = string
}

variable "log_retention_days" {
  type    = number
  default = 30
}

variable "alarm_email" {
  type        = string
  description = "Email address for alarm notifications"
  default     = ""
}

variable "target_group_arn_suffix" {
  type = string
}

variable "alb_arn_suffix" {
  type = string
}

variable "common_tags" {
  type = map(string)
}
```

**modules/monitoring/outputs.tf:**

```hcl
output "log_group_name" {
  value = aws_cloudwatch_log_group.app.name
}

output "sns_topic_arn" {
  value = aws_sns_topic.alarms.arn
}

output "dashboard_name" {
  value = aws_cloudwatch_dashboard.main.dashboard_name
}
```

**What we're monitoring:**

✅ **CPU Utilization** — EC2 and RDS
✅ **Request Count** — Traffic volume
✅ **Response Time** — Application performance
✅ **Unhealthy Targets** — Instance health
✅ **5xx Errors** — Server errors
✅ **Database Connections** — Connection pool usage
✅ **Free Storage Space** — Disk capacity
✅ **Application Errors** — Log-based error tracking

**When alarms trigger:**
1. CloudWatch detects threshold breach
2. SNS topic receives notification
3. Email sent to ops team
4. Auto Scaling may trigger (if CPU-based)

</div>

</details>

---

<details>
<summary><strong>9. CI/CD Pipeline</strong></summary>

<div style="margin-left: 16px; margin-right: 16px; margin-top: 8px; margin-bottom: 8px;">

Automated testing and deployment with GitHub Actions.

**Concepts from File 10** (Testing Strategies)

**.github/workflows/terraform-plan.yml:**

```yaml
name: Terraform Plan

on:
  pull_request:
    paths:
      - 'environments/**'
      - 'modules/**'
      - '.github/workflows/terraform-plan.yml'

jobs:
  plan:
    name: Terraform Plan
    runs-on: ubuntu-latest
    strategy:
      matrix:
        environment: [dev, staging, prod]
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v2
        with:
          terraform_version: 1.9.0

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v2
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: us-east-1

      - name: Terraform Format Check
        run: |
          cd environments/${{ matrix.environment }}
          terraform fmt -check -recursive

      - name: Terraform Init
        run: |
          cd environments/${{ matrix.environment }}
          terraform init

      - name: Terraform Validate
        run: |
          cd environments/${{ matrix.environment }}
          terraform validate

      - name: TFLint
        uses: terraform-linters/setup-tflint@v3
        with:
          tflint_version: latest
      
      - name: Run TFLint
        run: |
          cd environments/${{ matrix.environment }}
          tflint --init
          tflint

      - name: Checkov Security Scan
        uses: bridgecrewio/checkov-action@master
        with:
          directory: environments/${{ matrix.environment }}
          framework: terraform

      - name: Terraform Plan
        run: |
          cd environments/${{ matrix.environment }}
          terraform plan -out=tfplan

      - name: Upload Plan
        uses: actions/upload-artifact@v3
        with:
          name: tfplan-${{ matrix.environment }}
          path: environments/${{ matrix.environment }}/tfplan

      - name: Comment PR
        uses: actions/github-script@v6
        with:
          script: |
            const fs = require('fs');
            const plan = fs.readFileSync('environments/${{ matrix.environment }}/tfplan', 'utf8');
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: `## Terraform Plan - ${{ matrix.environment }}\n\`\`\`\n${plan}\n\`\`\``
            });
```

**.github/workflows/terraform-apply.yml:**

```yaml
name: Terraform Apply

on:
  push:
    branches:
      - main
    paths:
      - 'environments/**'
      - 'modules/**'

jobs:
  apply-dev:
    name: Apply to Dev
    runs-on: ubuntu-latest
    environment: dev
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v2
        with:
          terraform_version: 1.9.0

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v2
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: us-east-1

      - name: Terraform Init
        run: |
          cd environments/dev
          terraform init

      - name: Terraform Apply
        run: |
          cd environments/dev
          terraform apply -auto-approve

  apply-staging:
    name: Apply to Staging
    runs-on: ubuntu-latest
    environment: staging
    needs: apply-dev
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v2
        with:
          terraform_version: 1.9.0

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v2
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: us-east-1

      - name: Terraform Init
        run: |
          cd environments/staging
          terraform init

      - name: Terraform Apply
        run: |
          cd environments/staging
          terraform apply -auto-approve

  apply-prod:
    name: Apply to Prod (Manual Approval)
    runs-on: ubuntu-latest
    environment: prod
    needs: apply-staging
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v2
        with:
          terraform_version: 1.9.0

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v2
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: us-east-1

      - name: Terraform Init
        run: |
          cd environments/prod
          terraform init

      - name: Terraform Plan
        run: |
          cd environments/prod
          terraform plan -out=tfplan

      - name: Manual Approval Required
        uses: trstringer/manual-approval@v1
        with:
          secret: ${{ github.TOKEN }}
          approvers: devops-team
          minimum-approvals: 2

      - name: Terraform Apply
        run: |
          cd environments/prod
          terraform apply tfplan
```

**CI/CD Workflow:**

**Pull Request:**
1. Developer opens PR
2. GitHub Actions triggers
3. Runs for all environments (dev, staging, prod)
4. Format check (`terraform fmt -check`)
5. Syntax validation (`terraform validate`)
6. Linting (`tflint`)
7. Security scan (`checkov`)
8. Generate plan
9. Comment plan on PR
10. Team reviews plan before merge

**Merge to Main:**
1. PR merged to main branch
2. Deploy to Dev (automatic)
3. Deploy to Staging (automatic, after Dev succeeds)
4. Deploy to Prod (manual approval required)
5. Requires 2 approvals from devops-team
6. Apply changes

**Safety features:**

✅ **Automated testing** — Every PR tested
✅ **Multi-environment validation** — Test all environments
✅ **Security scanning** — Checkov finds misconfigurations
✅ **Progressive deployment** — Dev → Staging → Prod
✅ **Manual approval for prod** — Human review required
✅ **Plan visibility** — See changes before apply
✅ **Rollback capability** — Git revert triggers redeploy

**GitHub Secrets needed:**
- `AWS_ACCESS_KEY_ID`
- `AWS_SECRET_ACCESS_KEY`

**Environment protection rules (GitHub):**
- Dev: No restrictions
- Staging: Requires successful Dev deployment
- Prod: Requires 2 approvals + successful Staging

</div>

</details>

---

<details>
<summary><strong>10. Complete Code Walkthrough</strong></summary>

<div style="margin-left: 16px; margin-right: 16px; margin-top: 8px; margin-bottom: 8px;">

Now let's see how all the modules come together in an environment configuration.

**environments/prod/main.tf:**

```hcl
terraform {
  required_version = ">= 1.5.0"

  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = "~> 5.0"
    }
    random = {
      source  = "hashicorp/random"
      version = "~> 3.0"
    }
  }
}

provider "aws" {
  region = var.region

  default_tags {
    tags = local.common_tags
  }
}

locals {
  environment = "prod"
  common_tags = {
    Project     = var.project_name
    Environment = local.environment
    ManagedBy   = "Terraform"
    Owner       = var.owner
    CostCenter  = var.cost_center
  }
}

# VPC Module (File 03 - Resources)
module "vpc" {
  source = "../../modules/vpc"

  project_name       = var.project_name
  environment        = local.environment
  vpc_cidr           = var.vpc_cidr
  availability_zones = var.availability_zones
  enable_nat_gateway = true
  enable_flow_logs   = true
  common_tags        = local.common_tags
}

# Monitoring Module
module "monitoring" {
  source = "../../modules/monitoring"

  project_name              = var.project_name
  environment               = local.environment
  region                    = var.region
  log_retention_days        = 90  # Longer retention for prod
  alarm_email               = var.alarm_email
  target_group_arn_suffix   = module.alb.target_group_arn_suffix
  alb_arn_suffix            = module.alb.alb_arn_suffix
  common_tags               = local.common_tags
}

# ALB Module
module "alb" {
  source = "../../modules/alb"

  project_name       = var.project_name
  environment        = local.environment
  vpc_id             = module.vpc.vpc_id
  public_subnet_ids  = module.vpc.public_subnet_ids
  certificate_arn    = var.certificate_arn
  enable_access_logs = true
  log_bucket_name    = var.log_bucket_name
  common_tags        = local.common_tags
}

# RDS Module (File 10 - Security with Secrets Manager)
module "rds" {
  source = "../../modules/rds"

  project_name           = var.project_name
  environment            = local.environment
  vpc_id                 = module.vpc.vpc_id
  database_subnet_ids    = module.vpc.database_subnet_ids
  app_security_group_id  = module.compute.security_group_id
  instance_class         = "db.t3.medium"
  allocated_storage      = 100
  database_name          = var.database_name
  multi_az               = true  # High availability
  backup_retention_days  = 30    # 30-day retention for prod
  sns_topic_arn          = module.monitoring.sns_topic_arn
  common_tags            = local.common_tags
}

# Compute Module (File 05 - Loops, File 09 - Lifecycle)
module "compute" {
  source = "../../modules/compute"

  project_name           = var.project_name
  environment            = local.environment
  vpc_id                 = module.vpc.vpc_id
  private_subnet_ids     = module.vpc.private_subnet_ids
  alb_security_group_id  = module.alb.security_group_id
  target_group_arn       = module.alb.target_group_arn
  instance_type          = "t3.medium"
  min_size               = 3
  max_size               = 10
  desired_capacity       = 5
  db_endpoint            = module.rds.db_endpoint
  db_name                = module.rds.db_name
  cloudwatch_log_group   = module.monitoring.log_group_name
  common_tags            = local.common_tags
}

# CDN Module
module "cdn" {
  source = "../../modules/cdn"

  project_name = var.project_name
  environment  = local.environment
  price_class  = "PriceClass_All"  # Global distribution for prod
  common_tags  = local.common_tags
}
```

**environments/prod/variables.tf:**

```hcl
variable "region" {
  type    = string
  default = "us-east-1"
}

variable "project_name" {
  type = string
}

variable "owner" {
  type = string
}

variable "cost_center" {
  type = string
}

variable "vpc_cidr" {
  type    = string
  default = "10.0.0.0/16"
}

variable "availability_zones" {
  type    = list(string)
  default = ["us-east-1a", "us-east-1b"]
}

variable "database_name" {
  type = string
}

variable "certificate_arn" {
  type        = string
  description = "ACM certificate ARN for HTTPS"
}

variable "alarm_email" {
  type = string
}

variable "log_bucket_name" {
  type = string
}
```

**environments/prod/terraform.tfvars:**

```hcl
project_name   = "myapp"
owner          = "devops-team@example.com"
cost_center    = "engineering"
database_name  = "myapp_prod"
certificate_arn = "arn:aws:acm:us-east-1:123456789012:certificate/abc123"
alarm_email    = "alerts@example.com"
log_bucket_name = "myapp-logs-prod"
```

**environments/prod/backend.tf (File 08 - Remote State):**

```hcl
terraform {
  backend "s3" {
    bucket         = "myapp-terraform-state"
    key            = "prod/terraform.tfstate"
    region         = "us-east-1"
    encrypt        = true
    dynamodb_table = "terraform-state-locks"
  }
}
```

**environments/prod/outputs.tf (File 04 - Outputs):**

```hcl
output "alb_dns_name" {
  value       = module.alb.alb_dns_name
  description = "DNS name of the load balancer"
}

output "cloudfront_domain" {
  value       = module.cdn.cloudfront_domain_name
  description = "CloudFront distribution domain"
}

output "vpc_id" {
  value = module.vpc.vpc_id
}

output "database_endpoint" {
  value     = module.rds.db_endpoint
  sensitive = true
}
```

**Cross-references to previous files:**

- **File 03** (Resources & Data Sources) — VPC, subnets, security groups
- **File 04** (Variables & Outputs) — Input variables, output values, locals
- **File 05** (Loops) — count for multi-AZ resources, dynamic tags
- **File 06** (Modules) — Module structure, inputs, outputs
- **File 08** (Remote State) — S3 backend with DynamoDB locking
- **File 09** (Lifecycle) — create_before_destroy for zero-downtime updates
- **File 10** (Security) — Secrets Manager, encryption, IAM roles, validation

**Everything connects.**

</div>

</details>

---

<details>
<summary><strong>11. Deployment Process</strong></summary>

<div style="margin-left: 16px; margin-right: 16px; margin-top: 8px; margin-bottom: 8px;">

Let's walk through deploying this entire stack to production.

**Step 1: Set up state backend**

```bash
# Create S3 bucket for state
aws s3api create-bucket \
  --bucket myapp-terraform-state \
  --region us-east-1

# Enable versioning
aws s3api put-bucket-versioning \
  --bucket myapp-terraform-state \
  --versioning-configuration Status=Enabled

# Enable encryption
aws s3api put-bucket-encryption \
  --bucket myapp-terraform-state \
  --server-side-encryption-configuration '{
    "Rules": [{
      "ApplyServerSideEncryptionByDefault": {
        "SSEAlgorithm": "AES256"
      }
    }]
  }'

# Create DynamoDB table for state locking
aws dynamodb create-table \
  --table-name terraform-state-locks \
  --attribute-definitions AttributeName=LockID,AttributeType=S \
  --key-schema AttributeName=LockID,KeyType=HASH \
  --billing-mode PAY_PER_REQUEST \
  --region us-east-1
```

**Step 2: Deploy to Dev first**

```bash
cd environments/dev

# Initialize
terraform init

# Format code
terraform fmt -recursive

# Validate
terraform validate

# Plan
terraform plan -out=tfplan

# Review plan
terraform show tfplan

# Apply
terraform apply tfplan
```

**Step 3: Test Dev environment**

```bash
# Get outputs
terraform output

# Test ALB endpoint
curl http://$(terraform output -raw alb_dns_name)/health

# Check CloudWatch Logs
aws logs tail /aws/myapp/dev/app --follow

# Verify RDS connection
aws rds describe-db-instances --db-instance-identifier myapp-db-dev

# Check Auto Scaling
aws autoscaling describe-auto-scaling-groups --auto-scaling-group-names myapp-app-asg-dev
```

**Step 4: Deploy to Staging**

```bash
cd ../staging

terraform init
terraform plan -out=tfplan
terraform apply tfplan
```

**Step 5: Deploy to Production**

```bash
cd ../prod

# Initialize
terraform init

# Plan (review carefully)
terraform plan -out=tfplan

# Review plan thoroughly
terraform show tfplan

# Apply (with approval)
terraform apply tfplan
```

**Step 6: Configure DNS**

```bash
# Get ALB DNS name
terraform output alb_dns_name

# Create CNAME record in Route 53 or your DNS provider
# app.example.com → myapp-alb-prod-123456789.us-east-1.elb.amazonaws.com
```

**Step 7: Upload static assets**

```bash
# Get S3 bucket name
terraform output -raw cdn_bucket_name

# Upload files
aws s3 sync ./static/ s3://$(terraform output -raw cdn_bucket_name)/

# Invalidate CloudFront cache
aws cloudfront create-invalidation \
  --distribution-id $(terraform output -raw cloudfront_distribution_id) \
  --paths "/*"
```

**Step 8: Monitor deployment**

```bash
# Watch CloudWatch dashboard
aws cloudwatch get-dashboard --dashboard-name myapp-prod

# Check ALB target health
aws elbv2 describe-target-health \
  --target-group-arn $(terraform output -raw target_group_arn)

# Monitor Auto Scaling
watch -n 5 aws autoscaling describe-auto-scaling-groups \
  --auto-scaling-group-names myapp-app-asg-prod
```

**Step 9: Test production**

```bash
# Health check
curl https://app.example.com/health

# Load test (optional)
ab -n 1000 -c 10 https://app.example.com/

# Check error logs
aws logs tail /aws/myapp/prod/app --follow --filter-pattern "[ERROR]"
```

**Step 10: Set up monitoring alerts**

```bash
# Subscribe to SNS topic
aws sns subscribe \
  --topic-arn $(terraform output -raw sns_topic_arn) \
  --protocol email \
  --notification-endpoint ops@example.com

# Confirm subscription (check email)
```

**Common operations:**

**Update application:**
```bash
# Update AMI or user_data
terraform plan
terraform apply
# Auto Scaling will roll out new instances
```

**Scale up:**
```bash
# Edit terraform.tfvars
# desired_capacity = 10
terraform apply
```

**Rollback:**
```bash
git revert HEAD
git push
# CI/CD automatically deploys previous version
```

**Disaster recovery:**
```bash
# State stored in S3 with versioning
aws s3api list-object-versions \
  --bucket myapp-terraform-state \
  --prefix prod/terraform.tfstate

# Restore previous version if needed
aws s3api get-object \
  --bucket myapp-terraform-state \
  --key prod/terraform.tfstate \
  --version-id <version-id> \
  terraform.tfstate.recovered
```

**Cost estimation:**

**Dev environment:**
- 2 t3.micro EC2 instances: ~$15/month
- 1 NAT Gateway: ~$32/month
- db.t3.micro RDS: ~$15/month
- **Total: ~$62/month**

**Prod environment:**
- 5 t3.medium EC2 instances: ~$210/month
- 2 NAT Gateways: ~$64/month
- db.t3.medium RDS Multi-AZ: ~$120/month
- ALB: ~$20/month
- CloudFront: ~$10/month (depends on traffic)
- **Total: ~$424/month**

**Success criteria:**

✅ All resources created without errors
✅ ALB health checks passing
✅ Application responding to requests
✅ RDS database accessible from EC2
✅ CloudFront serving static assets
✅ CloudWatch alarms configured
✅ Auto Scaling working (scale up/down test)
✅ SNS notifications arriving
✅ CI/CD pipeline functional

**You've deployed production infrastructure from code.**

</div>

</details>

---

**This is what real Terraform looks like.**

Not toy examples. Not hello-world demos. Real infrastructure with:
- High availability across multiple AZs
- Auto Scaling based on demand
- Encrypted databases with automated backups
- Global content delivery with CloudFront
- Complete monitoring and alerting
- Automated testing and deployment
- Security best practices throughout

Every concept from Files 01-10 came together here:
- **File 01** — Terraform foundations
- **File 02** — State management
- **File 03** — Resources and data sources
- **File 04** — Variables, outputs, locals
- **File 05** — Loops and conditionals
- **File 06** — Modules
- **File 07** — Multi-environment setup (directories, not workspaces)
- **File 08** — Remote state in S3 with DynamoDB locking
- **File 09** — Lifecycle rules, create_before_destroy
- **File 10** — Security, validation, testing, monitoring

You started with "What is Terraform?"

You ended with production-ready infrastructure that companies actually use.

**You're ready to build real systems.**