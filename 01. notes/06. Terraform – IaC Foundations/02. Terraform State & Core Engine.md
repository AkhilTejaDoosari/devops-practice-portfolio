# **02. State & Core Engine**

You just created your first S3 bucket with Terraform. You ran `terraform apply`, saw it spin up, then ran `terraform destroy` and watched it disappear.
But here's what you didn't see: between those commands, Terraform was tracking something — silently, persistently, in a file called `terraform.tfstate`.

That file is Terraform's memory. Without it, Terraform would be blind. It wouldn't know what it created, what exists, or what needs to change. Every time you run `apply`, Terraform compares your code against that memory to figure out the smallest possible set of changes needed.

State isn't optional. It's not a nice-to-have feature. It's the core engine that makes everything work.
Let's see what's inside it, why it matters, and how to work with it safely.

---

## Table of Contents
1. [What Is State & Why It Matters](#what-is-state--why-it-matters)
2. [How State Tracking Works](#how-state-tracking-works)
3. [The Core Workflow](#the-core-workflow)
4. [Understanding terraform.tfstate](#understanding-terraformtfstate)
5. [When State Gets Created/Updated](#when-state-gets-createdupdated)
6. [Common State Issues & Solutions](#common-state-issues--solutions)

---

<details>
<summary><strong>1. What Is State & Why It Matters</strong></summary>

<div style="margin-left: 16px; margin-right: 16px; margin-top: 8px; margin-bottom: 8px;">

Here's the challenge: Terraform is declarative. You write what you want, not how to get there.
But to figure out what to do, Terraform needs to know what already exists.

**The problem without state:**
You write code that says "I want 3 EC2 instances."
Terraform connects to AWS. Sees 2 instances already running.
Now what? Create 3 more? Delete the 2 and start over? Create 1 to reach 3?

Without memory, Terraform can't tell the difference between:
- Resources it created
- Resources someone else created
- Resources that were deleted outside Terraform

**State solves this by recording everything Terraform manages.**

When you run `terraform apply`:
1. Terraform reads your code (desired state)  
2. Terraform reads `terraform.tfstate` (current state)  
3. Terraform calculates the difference  
4. Terraform applies only what changed  

**State tracks three critical things:**
- **Resource IDs** — The unique identifier AWS returned (like `i-0abc123`)  
- **Resource Attributes** — Every property (IP address, tags, size)  
- **Resource Dependencies** — What relies on what (subnet depends on VPC)  

Think of state like a receipt. When you buy something online, you get a confirmation number. If you need to return it, track it, or prove you bought it, you show the receipt.  
State is Terraform's receipt for everything it created.  

**State is not a cache.** It's not optional. It's not something you can regenerate easily.  
It's the source of truth that connects your code to real infrastructure.  

</div>

</details>

---

<details>
<summary><strong>2. How State Tracking Works</strong></summary>

<div style="margin-left: 16px; margin-right: 16px; margin-top: 8px; margin-bottom: 8px;">

Let's walk through what happens under the hood when you work with Terraform.  

**Scenario: Creating Your First Resource**. 

You write this:
```hcl
resource "aws_s3_bucket" "demo" {
  bucket = "my-terraform-bucket-12345"
}
```

**Step 1: terraform init**
- Terraform downloads the AWS provider plugin  
- No state file exists yet  
- Nothing is tracked  

**Step 2: terraform plan**
```
Terraform reads:
├── Your code (main.tf) — "I want bucket X"
├── State file — (doesn't exist yet)
└── AWS API — "Does bucket X exist?" → No

Conclusion: CREATE bucket X
```

Terraform shows you:
```
Plan: 1 to add, 0 to change, 0 to destroy.
```

**Step 3: terraform apply**
```
1. Terraform calls AWS API: CreateBucket("my-terraform-bucket-12345")
2. AWS creates the bucket
3. AWS returns: {id: "my-terraform-bucket-12345", arn: "arn:aws:s3:::..."}
4. Terraform saves this to terraform.tfstate
```

**Now the state file exists:**
```json
{
  "resources": [
    {
      "type": "aws_s3_bucket",
      "name": "demo",
      "instances": [{
        "attributes": {
          "bucket": "my-terraform-bucket-12345",
          "id": "my-terraform-bucket-12345",
          "arn": "arn:aws:s3:::my-terraform-bucket-12345"
        }
      }]
    }
  ]
}
```

**Scenario: Updating a Resource**

You change your code:
```hcl
resource "aws_s3_bucket" "demo" {
  bucket = "my-terraform-bucket-12345"
  
  tags = {
    Environment = "dev"
  }
}
```

**terraform plan again:**
```
Terraform reads:
├── Your code — "bucket X with tag Environment=dev"
├── State file — "bucket X exists, no tags"
└── Conclusion: UPDATE bucket X (add tags)

Plan: 0 to add, 1 to change, 0 to destroy.
```

Terraform only changes what's different. It doesn't recreate the entire bucket.

**Scenario: Deleting a Resource**

You remove the bucket from your code entirely.

**terraform plan:**
```
Terraform reads:
├── Your code — (no bucket defined)
├── State file — "bucket X exists"
└── Conclusion: DELETE bucket X

Plan: 0 to add, 0 to change, 1 to destroy.
```

**The State File Enables:**
- **Incremental changes** — Only update what changed
- **Dependency resolution** — Delete in the right order
- **Drift detection** — Spot manual changes made outside Terraform
- **Performance** — No need to query AWS for every resource on every plan

Without state, every `terraform plan` would need to:
1. Query AWS for every resource type
2. Try to match them to your code
3. Guess which ones Terraform created

State removes the guesswork. It's a map from code to reality.

</div>

</details>

---

<details>
<summary><strong>3. The Core Workflow</strong></summary>

<div style="margin-left: 16px; margin-right: 16px; margin-top: 8px; margin-bottom: 8px;">

**The Three Core Commands**
```
Write → Init → Plan → Apply → (Repeat)
```

**1. Write**
Edit your `.tf` files:
```hcl
resource "aws_instance" "web" {
  ami           = "ami-0c55b159cbfafe1f0"
  instance_type = "t3.micro"
}
```

**2. Init (Once per project)**
```bash
terraform init
```

Downloads providers and prepares the working directory.
Run this:
- First time in a new project
- When you add a new provider
- When you change backend configuration

**3. Plan (Every time before apply)**
```bash
terraform plan
```

This is where Terraform does its thinking. Before showing you what will change, it performs a **refresh** — querying AWS (or your cloud provider) to check the current state of every resource. This refresh happens automatically; you don't need to run it separately.

**What plan actually does:**
1. Reads your code (desired state)
2. Reads `terraform.tfstate` (last known state)
3. **Refreshes** — Queries AWS API to get current reality
4. Compares all three: code vs state vs reality
5. Shows you the difference

This is why `terraform plan` can detect **drift** — changes someone made manually in the AWS console:
```
Note: Objects have changed outside of Terraform

Terraform detected the following changes made outside of Terraform:

  # aws_instance.web has been changed
  ~ resource "aws_instance" "web" {
      ~ tags = {
          ~ "Name" = "WebServer" -> "ProductionServer"  # Changed manually
        }
    }
```

Terraform sees the difference between what your code says (`WebServer`) and what actually exists in AWS (`ProductionServer`).

**Plan output for new resources:**
```
Terraform will perform the following actions:

  # aws_instance.web will be created
  + resource "aws_instance" "web" {
      + ami           = "ami-0c55b159cbfafe1f0"
      + instance_type = "t3.micro"
      + id            = (known after apply)
    }

Plan: 1 to add, 0 to change, 0 to destroy.
```

**Always review the plan.** This is your safety net.
Look for:
- Resources being created when they shouldn't
- Resources being destroyed accidentally
- Unexpected changes (drift from manual edits)

**4. Apply**
```bash
terraform apply
```

Executes the plan and updates state.
Terraform will show the plan again and ask for confirmation.

**Pro workflow:**
```bash
# Save plan to a file
terraform plan -out=tfplan

# Review the saved plan
terraform show tfplan

# Apply the exact plan (no confirmation prompt)
terraform apply tfplan
```

This ensures what you reviewed is exactly what gets applied.

**The Destroy Command**
```bash
terraform destroy
```

Deletes all resources tracked in state.
Equivalent to removing all resources from your code and running apply.

Use this to:
- Clean up test environments
- Tear down infrastructure completely
- Start fresh

**Never use destroy in production without extreme caution.**

**Skipping Refresh (Rare)**

In some cases, you might want to skip the refresh step — for example, if AWS API is slow or you're certain nothing changed:
```bash
terraform plan -refresh=false
```

This uses only the state file without querying AWS. Use sparingly — you'll miss any drift.

**Command Comparison**

| Command | Reads Code | Reads State | Queries AWS | Modifies State | Modifies AWS |
|---------|-----------|-------------|-------------|----------------|--------------|
| `init` | No | No | No | No | No |
| `plan` | Yes | Yes | Yes (refresh) | No | No |
| `apply` | Yes | Yes | Yes (refresh) | Yes | Yes |
| `destroy` | Yes | Yes | Yes (refresh) | Yes | Yes |

</div>

</details>

---

<details>
<summary><strong>4. Understanding terraform.tfstate</strong></summary>

<div style="margin-left: 16px; margin-right: 16px; margin-top: 8px; margin-bottom: 8px;">

The state file is a JSON document that acts as Terraform's memory. Every resource you create, every attribute AWS returns, every dependency between resources — it's all recorded here.

Let's break down exactly what's inside and why each piece matters.

**A Complete State File:**
```json
{
  "version": 4,
  "terraform_version": "1.9.0",
  "serial": 12,
  "lineage": "a1b2c3d4-e5f6-7890-abcd-ef1234567890",
  "outputs": {
    "instance_ip": {
      "value": "54.123.45.67",
      "type": "string",
      "sensitive": false
    }
  },
  "resources": [
    {
      "mode": "managed",
      "type": "aws_instance",
      "name": "web",
      "provider": "provider[\"registry.terraform.io/hashicorp/aws\"]",
      "instances": [
        {
          "schema_version": 1,
          "attributes": {
            "id": "i-0abc123def456",
            "ami": "ami-0c55b159cbfafe1f0",
            "instance_type": "t3.micro",
            "public_ip": "54.123.45.67",
            "private_ip": "10.0.1.50",
            "subnet_id": "subnet-xyz789",
            "vpc_security_group_ids": ["sg-abc123"],
            "tags": {
              "Name": "WebServer"
            },
            "availability_zone": "us-east-1a",
            "arn": "arn:aws:ec2:us-east-1:123456789012:instance/i-0abc123def456"
          },
          "sensitive_attributes": [],
          "dependencies": [
            "aws_subnet.public",
            "aws_security_group.web"
          ]
        }
      ]
    }
  ]
}
```

This looks like a lot. Let's break it into pieces.

**The Header Fields**

**`version`** — The state file format version. Currently `4` for modern Terraform. If you see version 3 or lower, it's from an older Terraform version. Terraform automatically upgrades the format when needed.

**`terraform_version`** — Which Terraform version last touched this state. Newer Terraform can read older state, but older Terraform cannot always read newer state. If state shows `1.9.0` but you're running `1.5.0`, you might get compatibility warnings.

**`serial`** — A counter that increments every time state changes. This is how Terraform detects conflicts.

Imagine Alice and Bob both start with serial `12`. Alice runs apply, state becomes serial `13`. Bob runs apply at the same time — his Terraform also tries to write serial `13`. Conflict detected. Two different changes can't both be serial `13`.

Remote backends use this for locking and conflict prevention.

**`lineage`** — A UUID that identifies this state file's entire history. Created once when state is first initialized, never changes after that.

Why does this matter? If you accidentally point Terraform at the wrong state file (maybe staging instead of production), the lineage mismatch helps catch the mistake. It's a fingerprint saying "this state file belongs to this specific infrastructure."

**The Outputs Section**
```json
"outputs": {
  "instance_ip": {
    "value": "54.123.45.67",
    "type": "string",
    "sensitive": false
  }
}
```

Every `output` block in your code gets recorded here with its computed value.  
This is how:  
- You see outputs after running `terraform apply`
- Other Terraform configurations can read your outputs using `terraform_remote_state`
- CI/CD pipelines can extract values with `terraform output -raw instance_ip`

If you mark an output as `sensitive = true`, it still appears in state — sensitive doesn't mean hidden from state, just hidden from CLI output.

**The Resources Array**

This is where all your infrastructure lives in Terraform's memory.

**`mode`** — Two possible values:
- `"managed"` — A resource Terraform created and controls (from `resource` blocks)
- `"data"` — A data source Terraform queried but doesn't control (from `data` blocks)

**`type`** — The resource type: `aws_instance`, `aws_s3_bucket`, `aws_vpc`, etc.

**`name`** — The local name you gave it. When you write `resource "aws_instance" "web"`, the name is `web`.

**`provider`** — Which provider manages this resource. The format `provider["registry.terraform.io/hashicorp/aws"]` tells Terraform exactly which provider plugin handles API calls for this resource.

**The Instances Array**
```json
"instances": [
  {
    "schema_version": 1,
    "attributes": { ... },
    "sensitive_attributes": [],
    "dependencies": [...]
  }
]
```

Why is this an array? Because of `count` and `for_each`.

If you write:
```hcl
resource "aws_instance" "web" {
  count = 3
  ami   = "ami-0c55b159cbfafe1f0"
  ...
}
```

The instances array has 3 entries — one for each EC2 instance. Each entry represents one actual resource in AWS with its own ID, IP address, and attributes.

**`schema_version`** — Providers sometimes change how they structure attributes between versions. This number helps Terraform handle migrations when you upgrade providers.

**`attributes`** — Everything AWS told Terraform about this resource:
```json
"attributes": {
  "id": "i-0abc123def456",
  "ami": "ami-0c55b159cbfafe1f0",
  "instance_type": "t3.micro",
  "public_ip": "54.123.45.67",
  "private_ip": "10.0.1.50",
  "subnet_id": "subnet-xyz789",
  "tags": {
    "Name": "WebServer"
  }
}
```

Notice three types of values here:
- **Things you specified** — `ami`, `instance_type`, `tags` (from your code)
- **Things AWS assigned** — `id`, `public_ip`, `private_ip` (computed when resource was created)
- **Things AWS defaulted** — `subnet_id` if you didn't specify one

**`dependencies`** — Other resources this one depends on:
```json
"dependencies": [
  "aws_subnet.public",
  "aws_security_group.web"
]
```

Terraform uses this to determine:
- **Creation order** — Create subnet and security group FIRST, then instance
- **Destruction order** — Destroy instance FIRST, then subnet and security group

If you delete everything, Terraform won't try to delete the subnet while the instance still needs it.

**What "known after apply" Means**

When you run `terraform plan` on a new resource:
```
+ resource "aws_instance" "web" {
    + ami           = "ami-0c55b159cbfafe1f0"
    + instance_type = "t3.micro"
    + id            = (known after apply)
    + public_ip     = (known after apply)
    + private_ip    = (known after apply)
    + arn           = (known after apply)
  }
```

Those `(known after apply)` values don't exist yet. You specified the `ami` and `instance_type`, but `id`, `public_ip`, `private_ip`, and `arn` are assigned by AWS when it creates the instance.

After `terraform apply`, state now contains:
```json
"attributes": {
  "id": "i-0abc123def456",
  "public_ip": "54.123.45.67",
  "private_ip": "10.0.1.50",
  "arn": "arn:aws:ec2:us-east-1:123456789012:instance/i-0abc123def456"
}
```

Now Terraform knows them. Next time you reference `aws_instance.web.public_ip` anywhere in your code, Terraform reads `54.123.45.67` from state.

**How State Connects Code to Reality**
```
Your Code                    State File                     AWS
───────────                  ──────────                     ───
resource "aws_instance"  →   "id": "i-0abc123"         →   Actual EC2
  name = "web"               "type": "aws_instance"        instance with
  ami = "ami-xyz"            "name": "web"                 that ID running
                             "attributes": {...}           in us-east-1
```

When you change your code:
1. Terraform reads your new code (desired state)
2. Terraform reads state file to find `i-0abc123def456`
3. Terraform queries AWS: "What's the current state of `i-0abc123def456`?"
4. Terraform compares all three and calculates what needs to change

State is the bridge. Without it, Terraform can't map `aws_instance.web` in your code to `i-0abc123def456` in AWS.

**Sensitive Data Warning**

State files contain secrets in plain text. If you put a password in your Terraform code:
```hcl
resource "aws_db_instance" "main" {
  password = "super-secret-password-123"
}
```

That password appears in state:
```json
"attributes": {
  "password": "super-secret-password-123",
  "endpoint": "mydb.abc123.us-east-1.rds.amazonaws.com:5432"
}
```

This is why you must:
- Never commit state to Git
- Use remote backends with encryption (S3 + KMS)
- Restrict access to state files via IAM
- Use secrets managers instead of hardcoding passwords (covered in later files)

**The Backup File**

Every `terraform apply` creates two files:
- `terraform.tfstate` — Current state
- `terraform.tfstate.backup` — State before this apply

If an apply goes wrong:
```bash
cp terraform.tfstate.backup terraform.tfstate
```

This is your local safety net. Remote backends (S3 with versioning) provide better protection — you can restore any previous version, not just the last one.

**State File Size**

State grows with your infrastructure:
- 10 resources → ~10 KB
- 100 resources → ~100 KB  
- 1000 resources → ~1 MB+

Large state files slow down every Terraform operation because the entire file must be read, parsed, and refreshed against AWS. This is one reason teams split infrastructure into smaller, focused Terraform configurations rather than one giant state file for everything.

**Never Edit State Manually**

The state file is JSON, so it's tempting to open it in an editor and "fix" something. Don't.
```bash
# ❌ Bad — Opens state in editor, easy to corrupt
vim terraform.tfstate

# ✅ Good — Uses Terraform's state commands
terraform state list                              # See all resources
terraform state show aws_instance.web             # See one resource
terraform state mv aws_instance.old aws_instance.new   # Rename
terraform state rm aws_instance.obsolete          # Remove from state
```

Terraform's state commands handle the serial number, validate JSON structure, and maintain consistency. Manual edits can corrupt state, break the serial counter, or leave Terraform confused about what actually exists.

</div>

</details>

---

<details>
<summary><strong>5. When State Gets Created/Updated</strong></summary>

<div style="margin-left: 16px; margin-right: 16px; margin-top: 8px; margin-bottom: 8px;">

**State File Lifecycle:**

**State is created** when you run `terraform apply` for the first time in a directory.
Before that, no state file exists.

**State is updated** every time you run:
- `terraform apply` — Adds/modifies/removes resources
- `terraform destroy` — Removes resources
- `terraform import` — Adds existing resources to state
- `terraform state` commands — Manual state manipulation

Note: `plan` and `apply` automatically refresh state by querying your cloud provider before calculating changes. You don't need a separate refresh step.

**State is NOT updated** when you:
- Edit `.tf` files (just code changes)
- Run `terraform plan` (read-only operation)
- Run `terraform validate` (syntax check)
- Run `terraform fmt` (formatting)

**Example Timeline:**

```bash
# Day 1: Create infrastructure
terraform init        # No state yet
terraform plan        # Still no state (read-only)
terraform apply       # State file created (1 resource)

# Day 2: Add more resources
# Edit main.tf, add EC2 instance
terraform plan        # Reads existing state
terraform apply       # State updated (2 resources now)

# Day 3: Someone deletes bucket manually in AWS
terraform plan        # State still shows bucket exists (out of sync)
terraform apply       # State updated to match reality (1 resource)
```

**State Serial Number:**

Every state change increments the `serial` field:
```json
{
  "version": 4,
  "serial": 1,  // First apply
  ...
}
```

After second apply:
```json
{
  "version": 4,
  "serial": 2,  // Incremented
  ...
}
```

This prevents concurrent modifications. If two people run `apply` simultaneously, Terraform detects the conflict:
```
Error: state lock conflict
Serial number mismatch (expected 2, got 3)
```

**Manual State Updates (Advanced):**

You can manipulate state with `terraform state` commands:
```bash
# List all resources in state
terraform state list

# Show details of a specific resource
terraform state show aws_instance.web

# Remove a resource from state (doesn't delete in AWS)
terraform state rm aws_instance.web

# Move a resource to a different name
terraform state mv aws_instance.web aws_instance.app
```

Use these carefully. They change state without touching AWS.

</div>

</details>

---

<details>
<summary><strong>6. Common State Issues & Solutions</strong></summary>

<div style="margin-left: 16px; margin-right: 16px; margin-top: 8px; margin-bottom: 8px;">

**Problem 1: State File is Missing**

**Scenario:** You deleted `terraform.tfstate` accidentally.

**Impact:** Terraform thinks nothing exists. Running `terraform plan` shows it wants to create everything again, even though resources exist in AWS.

**Solution A — Restore from Backup:**
```bash
cp terraform.tfstate.backup terraform.tfstate
terraform plan  # Should show no changes
```

**Solution B — Import Existing Resources:**
```bash
terraform import aws_s3_bucket.demo my-terraform-bucket-12345
terraform import aws_instance.web i-0abc123def456
```

Import tells Terraform: "This resource exists, add it to state."

**Solution C — Start Fresh (Last Resort):**
Delete everything in AWS manually, then run `terraform apply` to recreate.

**Problem 2: State is Out of Sync (Drift)**

**Scenario:** Someone manually changed a tag in AWS Console. State still shows the old tag.

**Detection:**
```bash
terraform plan
```

Output:
```
Note: Objects have changed outside of Terraform

Terraform detected the following changes made outside of Terraform since the last apply:

  # aws_instance.web has been modified
  ~ resource "aws_instance" "web" {
      ~ tags = {
          ~ "Name" = "WebServer" -> "ProductionServer"
        }
    }
```

**Solution — Let Terraform Fix It:**
```bash
terraform apply
```

Terraform will change the tag back to what your code says (`WebServer`).

**Alternative — Accept the Drift:**
If you want to keep the manual change, update your code:
```hcl
resource "aws_instance" "web" {
  tags = {
    Name = "ProductionServer"  # Match reality
  }
}
```

**Problem 3: State Lock Conflict**

**Scenario:** Two people run `terraform apply` at the same time.

**Error:**
```
Error: Error acquiring the state lock

Lock Info:
  ID:        abc-123-def
  Path:      terraform.tfstate
  Operation: apply
  Who:       alice@laptop
  Created:   2024-01-15 10:30:00 UTC
```

**Solution — Wait:**
The first person's `apply` will finish, then the second person can try again.

**Force Unlock (Dangerous):**
```bash
terraform force-unlock abc-123-def
```

Only do this if you're CERTAIN no one else is running Terraform.

**Problem 4: State File is Corrupted**

**Symptoms:**
- Terraform crashes with JSON parsing errors
- State file contains invalid JSON
- State file is empty or truncated

**Solution:**
```bash
# Restore from backup
cp terraform.tfstate.backup terraform.tfstate

# Verify state is valid
terraform state list

# If backup is also corrupted, import resources one by one
```

**Problem 5: Accidentally Committed State to Git**

**Problem:** State file contains secrets (database passwords, API keys) and is now in Git history.

**Immediate Action:**
```bash
# Remove from current commit
git rm terraform.tfstate
git rm terraform.tfstate.backup
git commit -m "Remove state files"

# Add to .gitignore
echo "terraform.tfstate" >> .gitignore
echo "terraform.tfstate.backup" >> .gitignore
git add .gitignore
git commit -m "Ignore state files"
```

**Rotate ALL secrets that were in the state file.** Git history is permanent.

**Better Approach (Next File):**
Use remote state (S3 + DynamoDB) with encryption. Never store state locally for real projects.

**Problem 6: Need to Rename a Resource**

**Scenario:** You renamed `aws_instance.web` to `aws_instance.app` in your code.

**Bad Approach:**
```bash
terraform plan
# Shows: destroy web, create app (downtime!)
```

**Good Approach — Use moved block (Terraform 1.1+):**
```hcl
moved {
  from = aws_instance.web
  to   = aws_instance.app
}

resource "aws_instance" "app" {
  # ... same config
}
```

Or use state commands:
```bash
terraform state mv aws_instance.web aws_instance.app
```

No downtime. Just a state update.

---

**Key Lessons:**

- Always back up state before manual changes
- Use version control for `.tf` files, NOT state files
- Test state operations in a safe environment first
- When in doubt, restore from backup and try again
- Plan carefully before running state commands

---

**State is the foundation.** Every Terraform operation relies on it. Now that you understand how it works, we can build on this knowledge — adding providers, resources, and eventually remote state management.

Next, we'll explore how Terraform talks to AWS (and other clouds) through providers, and how to create real infrastructure with resources and data sources.

</div>

</details>

---