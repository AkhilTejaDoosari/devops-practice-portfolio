# **08. Remote State & Backends — Team Collaboration with S3 + DynamoDB**
# Remote State & Backends

You've been running Terraform on your laptop. The state file sits right there in your project directory.
That works fine when you're the only one touching the infrastructure.

But what happens when your teammate needs to make a change? Or when you want to run Terraform from CI/CD?
Or when your laptop crashes and the state file is gone?

**Local state doesn't scale beyond one person.**

Remote state solves this by storing `terraform.tfstate` in a shared location — typically S3 with DynamoDB for locking.
Multiple people can collaborate safely. State is backed up automatically. Access is controlled through IAM.

We'll set up S3 backends, configure locking, migrate from local to remote state, and implement security best practices.

---

## Table of Contents
1. [Why Remote State Matters](#1-why-remote-state-matters)
2. [Local vs Remote State](#2-local-vs-remote-state)
3. [S3 Backend Setup](#3-s3-backend-setup)
4. [State Locking with DynamoDB](#4-state-locking-with-dynamodb)
5. [Backend Configuration](#5-backend-configuration)
6. [State Migration (Local → Remote)](#6-state-migration-local--remote)
7. [Sharing State Across Teams](#7-sharing-state-across-teams)
8. [State Security & Encryption](#8-state-security--encryption)

---

<details>
<summary><strong>1. Why Remote State Matters</strong></summary>

<div style="margin-left: 16px; margin-right: 16px; margin-top: 8px; margin-bottom: 8px;">

Local state worked fine when you were learning. But in real environments, it creates problems.

**Problem 1: No Collaboration**

Alice runs `terraform apply` on her laptop.
State is stored locally on her machine.
Bob wants to make changes. He runs `terraform plan` on his laptop.
Bob's Terraform has no state — it thinks nothing exists.
Bob's plan wants to create everything again.

**Problem 2: No Backup**

Your laptop crashes. State file is gone.
Terraform no longer knows what it created.
You can't update or destroy resources without manually importing everything.

**Problem 3: No Audit Trail**

Who changed what? When? Why?
With local state, there's no history.

**Problem 4: CI/CD Can't Work**

Your CI/CD pipeline needs to run Terraform.
Where does it get the state file?
You can't commit state to Git (it contains secrets).

**Problem 5: State Conflicts**

Alice and Bob both run `terraform apply` at the same time.
Both read state, make changes, write state.
One of them overwrites the other's changes.
Infrastructure drift happens silently.

**Remote state solves all of this:**

- **Shared location** — Everyone reads from the same state
- **Automatic backups** — S3 versioning protects against corruption
- **Access control** — IAM decides who can read/write
- **Locking** — DynamoDB prevents concurrent modifications
- **Encryption** — State is encrypted at rest and in transit
- **CI/CD friendly** — Pipeline authenticates via IAM role

**The flow with remote state:**

```
Developer 1 → terraform apply → S3 State (locked)
Developer 2 → terraform plan → Waits for lock
Developer 2 → terraform apply → Gets lock, applies changes
```

Everyone works from the same source of truth.

</div>

</details>

---

<details>
<summary><strong>2. Local vs Remote State</strong></summary>

<div style="margin-left: 16px; margin-right: 16px; margin-top: 8px; margin-bottom: 8px;">

Let's compare the two approaches directly.

**Local State:**

```
project/
├── main.tf
├── variables.tf
└── terraform.tfstate  ← Stored locally
```

**Backend configuration:**
```hcl
# No backend block = local state
```

**Pros:**
- Simple setup
- No external dependencies
- Fast (no network calls)

**Cons:**
- Single point of failure (your laptop)
- No collaboration
- No locking
- No backup
- Not suitable for teams
- Can't use in CI/CD

**Remote State (S3 + DynamoDB):**

```
project/
├── main.tf
├── variables.tf
└── backend.tf
```

**Backend configuration:**
```hcl
terraform {
  backend "s3" {
    bucket         = "my-terraform-state"
    key            = "project/terraform.tfstate"
    region         = "us-east-1"
    encrypt        = true
    dynamodb_table = "terraform-state-lock"
  }
}
```

State stored in:
- **S3** — `s3://my-terraform-state/project/terraform.tfstate`
- **DynamoDB** — Manages locks

**Pros:**
- Team collaboration
- Automatic backups (S3 versioning)
- State locking (prevents conflicts)
- Encryption at rest
- Access control via IAM
- CI/CD friendly
- Disaster recovery

**Cons:**
- Requires AWS resources (S3 bucket, DynamoDB table)
- Slightly slower (network latency)
- More complex setup (initial bootstrap)

**Comparison Table:**

| Feature | Local State | Remote State (S3) |
|---------|-------------|-------------------|
| **Collaboration** | ❌ No | ✅ Yes |
| **Locking** | ❌ No | ✅ Yes (DynamoDB) |
| **Backup** | ❌ Manual | ✅ Automatic (versioning) |
| **Encryption** | ❌ No | ✅ Yes (at rest & transit) |
| **Access Control** | ❌ No | ✅ Yes (IAM) |
| **CI/CD** | ❌ Difficult | ✅ Easy |
| **Audit Trail** | ❌ No | ✅ Yes (S3 logs) |
| **Speed** | ✅ Fast | ⚠️ Network latency |
| **Setup** | ✅ Simple | ⚠️ Requires resources |

**When to use local state:**
- Personal learning/testing
- Temporary experiments
- Single developer, non-critical infrastructure

**When to use remote state:**
- Team collaboration
- Production environments
- CI/CD pipelines
- Any infrastructure that matters

**The rule:**
If your infrastructure is important enough to be in Git, it's important enough for remote state.

</div>

</details>

---

<details>
<summary><strong>3. S3 Backend Setup</strong></summary>

<div style="margin-left: 16px; margin-right: 16px; margin-top: 8px; margin-bottom: 8px;">

Let's set up remote state step by step.

**Step 1: Create S3 Bucket for State**

```bash
aws s3api create-bucket \
  --bucket my-terraform-state \
  --region us-east-1
```

For regions other than us-east-1:
```bash
aws s3api create-bucket \
  --bucket my-terraform-state \
  --region us-west-2 \
  --create-bucket-configuration LocationConstraint=us-west-2
```

**Step 2: Enable Versioning**

Protects against accidental state corruption.

```bash
aws s3api put-bucket-versioning \
  --bucket my-terraform-state \
  --versioning-configuration Status=Enabled
```

**Step 3: Enable Encryption**

```bash
aws s3api put-bucket-encryption \
  --bucket my-terraform-state \
  --server-side-encryption-configuration '{
    "Rules": [{
      "ApplyServerSideEncryptionByDefault": {
        "SSEAlgorithm": "AES256"
      }
    }]
  }'
```

**Step 4: Block Public Access**

```bash
aws s3api put-public-access-block \
  --bucket my-terraform-state \
  --public-access-block-configuration \
    BlockPublicAcls=true,\
    IgnorePublicAcls=true,\
    BlockPublicPolicy=true,\
    RestrictPublicBuckets=true
```

**Step 5: Create DynamoDB Table for Locking**

```bash
aws dynamodb create-table \
  --table-name terraform-state-lock \
  --attribute-definitions AttributeName=LockID,AttributeType=S \
  --key-schema AttributeName=LockID,KeyType=HASH \
  --billing-mode PAY_PER_REQUEST \
  --region us-east-1
```

**Or use Terraform to bootstrap (chicken-and-egg solution):**

```hcl
# bootstrap/main.tf
terraform {
  # No backend block - uses local state for bootstrap
}

provider "aws" {
  region = "us-east-1"
}

resource "aws_s3_bucket" "terraform_state" {
  bucket = "my-terraform-state"
}

resource "aws_s3_bucket_versioning" "terraform_state" {
  bucket = aws_s3_bucket.terraform_state.id
  
  versioning_configuration {
    status = "Enabled"
  }
}

resource "aws_s3_bucket_server_side_encryption_configuration" "terraform_state" {
  bucket = aws_s3_bucket.terraform_state.id
  
  rule {
    apply_server_side_encryption_by_default {
      sse_algorithm = "AES256"
    }
  }
}

resource "aws_s3_bucket_public_access_block" "terraform_state" {
  bucket = aws_s3_bucket.terraform_state.id
  
  block_public_acls       = true
  block_public_policy     = true
  ignore_public_acls      = true
  restrict_public_buckets = true
}

resource "aws_dynamodb_table" "terraform_locks" {
  name         = "terraform-state-lock"
  billing_mode = "PAY_PER_REQUEST"
  hash_key     = "LockID"
  
  attribute {
    name = "LockID"
    type = "S"
  }
}

output "s3_bucket_name" {
  value = aws_s3_bucket.terraform_state.id
}

output "dynamodb_table_name" {
  value = aws_dynamodb_table.terraform_locks.name
}
```

Run once:
```bash
cd bootstrap
terraform init
terraform apply
```

**Step 6: Configure Backend in Your Project**

Create `backend.tf`:
```hcl
terraform {
  backend "s3" {
    bucket         = "my-terraform-state"
    key            = "project-name/terraform.tfstate"
    region         = "us-east-1"
    encrypt        = true
    dynamodb_table = "terraform-state-lock"
  }
}
```

**Step 7: Initialize Backend**

```bash
terraform init
```

Output:
```
Initializing the backend...

Successfully configured the backend "s3"! Terraform will automatically
use this backend unless the backend configuration changes.
```

Your state is now in S3!

**Verify:**
```bash
aws s3 ls s3://my-terraform-state/project-name/
# terraform.tfstate
```

</div>

</details>

---

<details>
<summary><strong>4. State Locking with DynamoDB</strong></summary>

<div style="margin-left: 16px; margin-right: 16px; margin-top: 8px; margin-bottom: 8px;">

State locking prevents two people from modifying infrastructure simultaneously.

**How it works:**

1. Alice runs `terraform apply`
2. Terraform writes a lock to DynamoDB table
3. Bob runs `terraform apply` at the same time
4. Bob's Terraform sees the lock, waits
5. Alice's apply finishes, releases lock
6. Bob's apply acquires lock, proceeds

**DynamoDB Table Structure:**

The table needs:
- **Partition key:** `LockID` (String)
- **Billing mode:** PAY_PER_REQUEST (recommended)

Terraform automatically manages lock entries.

**Lock Entry Example:**

When Alice runs apply, DynamoDB contains:
```json
{
  "LockID": "my-terraform-state/project-name/terraform.tfstate-md5",
  "Info": "{\"ID\":\"abc-123\",\"Operation\":\"OperationTypeApply\",\"Who\":\"alice@laptop\",\"Version\":\"1.9.0\",\"Created\":\"2024-01-15T10:30:00Z\"}",
  "Digest": "..."
}
```

**Testing the Lock:**

**Terminal 1:**
```bash
terraform apply
# Takes a while intentionally
```

**Terminal 2 (simultaneously):**
```bash
terraform apply
```

Output:
```
Error: Error acquiring the state lock

Lock Info:
  ID:        abc-123-def-456
  Path:      my-terraform-state/project-name/terraform.tfstate
  Operation: OperationTypeApply
  Who:       alice@laptop
  Version:   1.9.0
  Created:   2024-01-15 10:30:00 UTC

Terraform acquires a state lock to protect the state from being written
by multiple users at the same time. Please resolve the issue above and try
again. For most commands, you can disable locking with the "-lock=false"
flag, but this is not recommended.
```

**Force Unlock (Dangerous):**

If a lock is stuck (process crashed, network issue):
```bash
terraform force-unlock abc-123-def-456
```

**Only do this if you're certain no one else is running Terraform.**

**Disabling Locking (Not Recommended):**

```bash
terraform apply -lock=false
```

**Never do this in production.** You'll create race conditions.

**Backend Without Locking:**

Some backends don't support locking:
- `local`
- `http` (unless server implements locking)
- `consul` (supports locking)
- `azurerm` (supports locking)

**S3 + DynamoDB is the gold standard for AWS.**

**Lock Timeout:**

Configure how long to wait for a lock:
```hcl
terraform {
  backend "s3" {
    bucket         = "my-terraform-state"
    key            = "terraform.tfstate"
    region         = "us-east-1"
    encrypt        = true
    dynamodb_table = "terraform-state-lock"
    
    # Wait up to 10 minutes for lock
    lock_timeout   = "10m"
  }
}
```

**Monitoring Locks:**

Check DynamoDB table for stuck locks:
```bash
aws dynamodb scan \
  --table-name terraform-state-lock \
  --region us-east-1
```

If you see old locks (hours/days old), investigate before force-unlocking.

</div>

</details>

---

<details>
<summary><strong>5. Backend Configuration</strong></summary>

<div style="margin-left: 16px; margin-right: 16px; margin-top: 8px; margin-bottom: 8px;">

Backend configuration has some unique rules.

**Basic Backend Block:**

```hcl
terraform {
  backend "s3" {
    bucket         = "my-terraform-state"
    key            = "project/terraform.tfstate"
    region         = "us-east-1"
    encrypt        = true
    dynamodb_table = "terraform-state-lock"
  }
}
```

**Important Rules:**

**1. No variables allowed in backend config:**

This doesn't work:
```hcl
# ❌ Error
variable "state_bucket" {
  default = "my-terraform-state"
}

terraform {
  backend "s3" {
    bucket = var.state_bucket  # ❌ Can't use variables
  }
}
```

**2. Values must be literal strings:**

```hcl
terraform {
  backend "s3" {
    bucket = "my-terraform-state"  # ✅ Literal string
    key    = "project/terraform.tfstate"
  }
}
```

**Why?** Backend initialization happens before variable processing.

**Workaround 1: Partial Configuration**

Leave values out of the backend block:
```hcl
terraform {
  backend "s3" {}
}
```

Provide values during init:
```bash
terraform init \
  -backend-config="bucket=my-terraform-state" \
  -backend-config="key=project/terraform.tfstate" \
  -backend-config="region=us-east-1" \
  -backend-config="dynamodb_table=terraform-state-lock" \
  -backend-config="encrypt=true"
```

**Workaround 2: Backend Config File**

Create `backend.hcl`:
```hcl
bucket         = "my-terraform-state"
key            = "project/terraform.tfstate"
region         = "us-east-1"
encrypt        = true
dynamodb_table = "terraform-state-lock"
```

Init with file:
```bash
terraform init -backend-config=backend.hcl
```

**Per-Environment Backend Configs:**

```
project/
├── main.tf
├── backend.tf
└── configs/
    ├── dev-backend.hcl
    ├── staging-backend.hcl
    └── prod-backend.hcl
```

**configs/dev-backend.hcl:**
```hcl
bucket = "terraform-state-dev"
key    = "project/terraform.tfstate"
```

**configs/prod-backend.hcl:**
```hcl
bucket = "terraform-state-prod"
key    = "project/terraform.tfstate"
```

**Deploy:**
```bash
# Dev
terraform init -backend-config=configs/dev-backend.hcl
terraform apply

# Prod
terraform init -backend-config=configs/prod-backend.hcl
terraform apply
```

**Available S3 Backend Options:**

```hcl
terraform {
  backend "s3" {
    bucket                      = "my-terraform-state"
    key                         = "path/to/terraform.tfstate"
    region                      = "us-east-1"
    
    # Encryption
    encrypt                     = true
    kms_key_id                  = "arn:aws:kms:..."  # Optional: Use KMS
    
    # Locking
    dynamodb_table              = "terraform-locks"
    
    # Access
    profile                     = "default"
    shared_credentials_file     = "~/.aws/credentials"
    role_arn                    = "arn:aws:iam::..."  # Assume role
    
    # Advanced
    endpoint                    = "https://s3.amazonaws.com"  # Custom endpoint
    skip_credentials_validation = false
    skip_metadata_api_check     = false
    force_path_style            = false
  }
}
```

**Changing Backend Configuration:**

If you change backend settings:
```bash
terraform init -reconfigure
```

Terraform will migrate state to the new backend.

</div>

</details>

---

<details>
<summary><strong>6. State Migration (Local → Remote)</strong></summary>

<div style="margin-left: 16px; margin-right: 16px; margin-top: 8px; margin-bottom: 8px;">

You've been using local state. Now you want to move to remote state.

**Current state:**
```
project/
├── main.tf
├── variables.tf
└── terraform.tfstate  ← Local state
```

**Goal:**
Move `terraform.tfstate` to S3 without losing anything.

**Step 1: Backup Current State**

```bash
cp terraform.tfstate terraform.tfstate.backup
```

**Step 2: Create S3 Bucket and DynamoDB Table**

(Follow steps from section 3)

**Step 3: Add Backend Configuration**

Create `backend.tf`:
```hcl
terraform {
  backend "s3" {
    bucket         = "my-terraform-state"
    key            = "project/terraform.tfstate"
    region         = "us-east-1"
    encrypt        = true
    dynamodb_table = "terraform-state-lock"
  }
}
```

**Step 4: Initialize with Migration**

```bash
terraform init
```

Terraform detects the backend change:
```
Initializing the backend...
Do you want to copy existing state to the new backend?
  Pre-existing state was found while migrating the previous "local" backend to the
  newly configured "s3" backend. No existing state was found in the newly
  configured "s3" backend. Do you want to copy this state to the new "s3"
  backend? Enter "yes" to copy and "no" to start with an empty state.

  Enter a value: yes

Successfully configured the backend "s3"! Terraform will automatically
use this backend unless the backend configuration changes.
```

**Step 5: Verify Migration**

```bash
# Check S3
aws s3 ls s3://my-terraform-state/project/
# terraform.tfstate

# Download and compare
aws s3 cp s3://my-terraform-state/project/terraform.tfstate state-from-s3.tfstate
diff terraform.tfstate.backup state-from-s3.tfstate
# Should be identical
```

**Step 6: Remove Local State (Optional)**

```bash
rm terraform.tfstate
rm terraform.tfstate.backup
```

Local state is no longer used.

**Step 7: Test**

```bash
terraform plan
# Should show "No changes"
```

If plan shows changes, something went wrong — restore from backup.

**Migrating Between Remote Backends:**

**From S3 in us-east-1 to S3 in eu-west-1:**

**Old backend.tf:**
```hcl
terraform {
  backend "s3" {
    bucket = "terraform-state-us"
    key    = "project/terraform.tfstate"
    region = "us-east-1"
  }
}
```

**New backend.tf:**
```hcl
terraform {
  backend "s3" {
    bucket = "terraform-state-eu"
    key    = "project/terraform.tfstate"
    region = "eu-west-1"
  }
}
```

Run:
```bash
terraform init -migrate-state
```

Terraform copies state from old backend to new backend.

**Force Reconfiguration (Start Fresh):**

```bash
terraform init -reconfigure
```

Ignores existing state, starts with new backend and empty state.
**Dangerous** — only use if you want to abandon old state.

**Common Migration Issues:**

**Issue 1: "Backend configuration changed but no migration"**

Solution:
```bash
terraform init -migrate-state
```

**Issue 2: "Credentials invalid"**

Ensure AWS credentials are configured:
```bash
aws configure
# Or set environment variables
```

**Issue 3: "Bucket doesn't exist"**

Create the bucket first (step 3 in S3 Backend Setup).

</div>

</details>

---

<details>
<summary><strong>7. Sharing State Across Teams</strong></summary>

<div style="margin-left: 16px; margin-right: 16px; margin-top: 8px; margin-bottom: 8px;">

Remote state enables team collaboration, but you need to set it up correctly.

**Team Structure:**

```
Team:
- Alice (DevOps Lead)
- Bob (Developer)
- Carol (Developer)
- CI/CD Pipeline
```

Everyone needs access to state, but with different permissions.

**IAM Policy for State Access:**

**Read-Only (Developers):**
```json
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Allow",
      "Action": [
        "s3:GetObject",
        "s3:ListBucket"
      ],
      "Resource": [
        "arn:aws:s3:::my-terraform-state",
        "arn:aws:s3:::my-terraform-state/*"
      ]
    },
    {
      "Effect": "Allow",
      "Action": [
        "dynamodb:GetItem",
        "dynamodb:PutItem",
        "dynamodb:DeleteItem"
      ],
      "Resource": "arn:aws:dynamodb:us-east-1:123456789012:table/terraform-state-lock"
    }
  ]
}
```

**Read-Write (DevOps Team):**
```json
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Allow",
      "Action": [
        "s3:GetObject",
        "s3:PutObject",
        "s3:DeleteObject",
        "s3:ListBucket"
      ],
      "Resource": [
        "arn:aws:s3:::my-terraform-state",
        "arn:aws:s3:::my-terraform-state/*"
      ]
    },
    {
      "Effect": "Allow",
      "Action": [
        "dynamodb:GetItem",
        "dynamodb:PutItem",
        "dynamodb:DeleteItem"
      ],
      "Resource": "arn:aws:dynamodb:us-east-1:123456789012:table/terraform-state-lock"
    }
  ]
}
```

**CI/CD Pipeline (Assume Role):**

```hcl
terraform {
  backend "s3" {
    bucket         = "my-terraform-state"
    key            = "project/terraform.tfstate"
    region         = "us-east-1"
    encrypt        = true
    dynamodb_table = "terraform-state-lock"
    role_arn       = "arn:aws:iam::123456789012:role/TerraformCICD"
  }
}
```

CI/CD assumes `TerraformCICD` role with appropriate permissions.

**Per-Environment State Buckets:**

```
Environments:
- Dev   → terraform-state-dev
- Staging → terraform-state-staging
- Prod  → terraform-state-prod
```

Each bucket has different IAM policies:
- Dev: Everyone can read/write
- Staging: DevOps can read/write, Developers read-only
- Prod: Only DevOps Lead + CI/CD can write

**Workspace Recommendations:**

Even with remote state, use directory-based separation:
```
infrastructure/
├── environments/
│   ├── dev/
│   │   └── backend.tf      # → terraform-state-dev
│   ├── staging/
│   │   └── backend.tf      # → terraform-state-staging
│   └── prod/
        └── backend.tf      # → terraform-state-prod
```

**Onboarding New Team Members:**

**Step 1:** Grant IAM permissions
```bash
aws iam attach-user-policy \
  --user-name bob \
  --policy-arn arn:aws:iam::123456789012:policy/TerraformStateAccess
```

**Step 2:** Bob clones repo
```bash
git clone https://github.com/company/infrastructure.git
cd infrastructure
```

**Step 3:** Bob initializes
```bash
terraform init
```

Terraform downloads state from S3. Bob can now run `plan` and `apply`.

**Team Workflow:**

1. **Bob makes changes**
```bash
cd environments/dev
terraform plan
terraform apply
```

2. **Carol pulls changes**
```bash
git pull
terraform plan  # Sees Bob's changes reflected in state
```

3. **Alice reviews in staging**
```bash
cd environments/staging
terraform plan
terraform apply
```

4. **CI/CD deploys to prod**
```yaml
# .github/workflows/prod.yml
- name: Terraform Apply
  run: |
    cd environments/prod
    terraform init
    terraform apply -auto-approve
```

**Handling Conflicts:**

If Alice and Bob both run apply simultaneously:
- Alice acquires lock first
- Bob waits for lock
- Alice's changes complete
- Bob's Terraform sees Alice's changes, recalculates plan
- Bob applies remaining changes

**No conflicts. No overwrites. Safe collaboration.**

</div>

</details>

---

<details>
<summary><strong>8. State Security & Encryption</strong></summary>

<div style="margin-left: 16px; margin-right: 16px; margin-top: 8px; margin-bottom: 8px;">

State files contain sensitive information. Protect them.

**What's in State:**

- Resource IDs
- IP addresses
- Database connection strings
- **Passwords** (if you put them in Terraform)
- **API keys** (if you put them in Terraform)
- Security group rules
- IAM policies

**Security Layers:**

**Layer 1: Encryption at Rest (S3)**

```bash
aws s3api put-bucket-encryption \
  --bucket my-terraform-state \
  --server-side-encryption-configuration '{
    "Rules": [{
      "ApplyServerSideEncryptionByDefault": {
        "SSEAlgorithm": "AES256"
      }
    }]
  }'
```

Or use KMS for more control:
```hcl
terraform {
  backend "s3" {
    bucket     = "my-terraform-state"
    key        = "terraform.tfstate"
    region     = "us-east-1"
    encrypt    = true
    kms_key_id = "arn:aws:kms:us-east-1:123456789012:key/abc-123"
  }
}
```

**Layer 2: Encryption in Transit**

Terraform uses HTTPS for all S3 operations.
State is encrypted while moving from Terraform to S3.

**Layer 3: Access Control (IAM)**

Restrict who can read state:
```json
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Allow",
      "Principal": {
        "AWS": [
          "arn:aws:iam::123456789012:user/alice",
          "arn:aws:iam::123456789012:role/TerraformCICD"
        ]
      },
      "Action": ["s3:GetObject", "s3:PutObject"],
      "Resource": "arn:aws:s3:::my-terraform-state/*"
    }
  ]
}
```

**Layer 4: Versioning & Backup**

Enable S3 versioning:
```bash
aws s3api put-bucket-versioning \
  --bucket my-terraform-state \
  --versioning-configuration Status=Enabled
```

If state is corrupted, restore previous version:
```bash
aws s3api list-object-versions \
  --bucket my-terraform-state \
  --prefix terraform.tfstate

aws s3api get-object \
  --bucket my-terraform-state \
  --key terraform.tfstate \
  --version-id <VERSION_ID> \
  terraform.tfstate
```

**Layer 5: Bucket Policies**

Deny unencrypted uploads:
```json
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Deny",
      "Principal": "*",
      "Action": "s3:PutObject",
      "Resource": "arn:aws:s3:::my-terraform-state/*",
      "Condition": {
        "StringNotEquals": {
          "s3:x-amz-server-side-encryption": "AES256"
        }
      }
    }
  ]
}
```

**Layer 6: MFA Delete**

Require MFA to delete state:
```bash
aws s3api put-bucket-versioning \
  --bucket my-terraform-state \
  --versioning-configuration Status=Enabled,MFADelete=Enabled \
  --mfa "arn:aws:iam::123456789012:mfa/root-account-mfa-device 123456"
```

**Layer 7: CloudTrail Logging**

Track all access to state:
```bash
aws cloudtrail create-trail \
  --name terraform-state-audit \
  --s3-bucket-name cloudtrail-logs
  
aws s3api put-bucket-logging \
  --bucket my-terraform-state \
  --bucket-logging-status '{
    "LoggingEnabled": {
      "TargetBucket": "cloudtrail-logs",
      "TargetPrefix": "state-access/"
    }
  }'
```

**Best Practices:**

1. **Never commit state to Git**
```bash
# .gitignore
*.tfstate
*.tfstate.backup
.terraform/
```

2. **Use separate buckets per environment**
- Dev → `terraform-state-dev`
- Prod → `terraform-state-prod`

3. **Enable versioning on all state buckets**

4. **Use KMS encryption for production**

5. **Restrict IAM access**
- Principle of least privilege
- Only DevOps team writes
- Developers read-only

6. **Enable MFA delete for production state**

7. **Audit access with CloudTrail**

8. **Rotate KMS keys regularly**

9. **Store secrets outside Terraform**
```hcl
# ❌ Bad
resource "aws_db_instance" "main" {
  password = "hardcoded-password"
}

# ✅ Good
data "aws_secretsmanager_secret_version" "db_password" {
  secret_id = "prod/db/password"
}

resource "aws_db_instance" "main" {
  password = data.aws_secretsmanager_secret_version.db_password.secret_string
}
```

10. **Review state periodically**
```bash
terraform state list
terraform state show aws_db_instance.main
```

Check for accidentally exposed secrets.

**State Security Checklist:**

- [ ] S3 bucket encrypted (AES256 or KMS)
- [ ] S3 bucket versioning enabled
- [ ] S3 bucket has restrictive IAM policy
- [ ] DynamoDB table exists for locking
- [ ] Bucket policy denies unencrypted uploads
- [ ] MFA delete enabled (production)
- [ ] CloudTrail logging enabled
- [ ] State not committed to Git
- [ ] Secrets stored in Secrets Manager/Vault
- [ ] IAM follows least privilege

</div>

</details>

---

**Your state is now safe, shared, and scalable.**

Remote state enables team collaboration. S3 provides durability. DynamoDB prevents conflicts. Encryption protects sensitive data. IAM controls access.

Local state was fine for learning. Remote state is mandatory for production.

Next, we'll explore **advanced patterns and lifecycle rules** — meta-arguments that give you fine-grained control over resource behavior, provisioners for complex setup tasks, and techniques for importing and refactoring existing infrastructure.