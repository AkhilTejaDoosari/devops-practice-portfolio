# **03. Providers, Resources & Data Sources**

You understand what Terraform is and how it tracks infrastructure through state.
But Terraform itself doesn't know how to create an EC2 instance, an Azure VM, or a Kubernetes pod.
It's a coordinator, not an executor.

The actual work — talking to APIs, creating resources, reading existing infrastructure — happens through **providers**.
Providers are plugins that teach Terraform how to speak AWS, Azure, Google Cloud, or any other platform.

We'll explore how providers work, set up AWS as our primary example, create real resources, read existing infrastructure with data sources, and manage provider versions.

---

## Table of Contents
1. [What Are Providers?](#what-are-providers)
2. [AWS Provider Setup](#aws-provider-setup)
3. [How Providers Work](#how-providers-work)
4. [Resources — Creating Infrastructure](#resources--creating-infrastructure)
5. [Data Sources — Reading Existing Infrastructure](#data-sources--reading-existing-infrastructure)
6. [Provider Versioning & Lock Files](#provider-versioning--lock-files)
7. [Multi-Provider Configurations](#multi-provider-configurations)

---

<details>
<summary><strong>1. What Are Providers?</strong></summary>

<div style="margin-left: 16px; margin-right: 16px; margin-top: 8px; margin-bottom: 8px;">

Terraform is cloud-agnostic by design. It doesn't hardcode AWS, Azure, or Google Cloud into its core.
Instead, it uses a **plugin architecture** where providers extend Terraform's capabilities.

**Think of providers as translators.**

You write:
```hcl
resource "aws_instance" "web" {
  ami           = "ami-abc123"
  instance_type = "t3.micro"
}
```

The AWS provider translates this into:
```
POST https://ec2.us-east-1.amazonaws.com/
Action=RunInstances&ImageId=ami-abc123&InstanceType=t3.micro
```

**Providers handle:**
- **Authentication** — Connecting to the platform's API
- **Resource CRUD** — Create, Read, Update, Delete operations
- **Data fetching** — Reading existing infrastructure
- **Error handling** — Retries, timeouts, API limits
- **State mapping** — Converting API responses into Terraform state

**The Provider Ecosystem**

Terraform has **3,000+ providers** covering:
- **Cloud Platforms** — AWS, Azure, GCP, Oracle Cloud, Alibaba Cloud
- **Infrastructure** — Kubernetes, Docker, VMware, OpenStack
- **SaaS** — GitHub, Datadog, PagerDuty, Cloudflare
- **Databases** — PostgreSQL, MySQL, MongoDB Atlas
- **Security** — Vault, Auth0, Okta
- **Monitoring** — Grafana, New Relic, Splunk

One Terraform configuration can manage all of them together.

**Provider Types**

| Type | Description | Example |
|------|-------------|---------|
| **Official** | Maintained by HashiCorp | AWS, Azure, Google Cloud |
| **Partner** | Maintained by vendors | Datadog, MongoDB, CloudFlare |
| **Community** | Maintained by community | Hundreds of smaller integrations |

All providers are distributed through the [Terraform Registry](https://registry.terraform.io/browse/providers).

**Why This Matters**

Without providers, you'd need:
- Separate tools for each cloud (AWS CLI, az cli, gcloud)
- Different configuration formats
- Different workflows
- Manual coordination between platforms

With providers, you get:
- One tool (Terraform)
- One configuration language (HCL)
- One workflow (init → plan → apply)
- Unified state management

</div>

</details>

---

<details>
<summary><strong>2. AWS Provider Setup</strong></summary>

<div style="margin-left: 16px; margin-right: 16px; margin-top: 8px; margin-bottom: 8px;">

We'll use AWS as our primary example throughout this series, but the concepts apply to any provider.

**Step 1: Get AWS Credentials**

If you don't have AWS credentials:
1. Open AWS Console → IAM
2. Create a user with programmatic access
3. Attach `AdministratorAccess` policy (or more restricted for production)
4. Save the **Access Key ID** and **Secret Access Key**

**Step 2: Configure Credentials**

**Method 1: AWS CLI (Recommended)**
```bash
aws configure
```

Enter:
- AWS Access Key ID: `AKIAIOSFODNN7EXAMPLE`
- AWS Secret Access Key: `wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY`
- Default region: `us-east-1`
- Default output format: `json`

This creates `~/.aws/credentials`:
```ini
[default]
aws_access_key_id = AKIAIOSFODNN7EXAMPLE
aws_secret_access_key = wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY
```

Terraform automatically reads this file.

**Method 2: Environment Variables**
```bash
export AWS_ACCESS_KEY_ID="AKIAIOSFODNN7EXAMPLE"
export AWS_SECRET_ACCESS_KEY="wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY"
export AWS_DEFAULT_REGION="us-east-1"
```

**Method 3: Hardcode in Terraform (Not Recommended)**
```hcl
provider "aws" {
  region     = "us-east-1"
  access_key = "AKIAIOSFODNN7EXAMPLE"
  secret_key = "wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY"
}
```

**Never commit credentials to Git.** Use AWS CLI or environment variables.

**Step 3: Declare the Provider**

Create a new directory:
```bash
mkdir terraform-aws-demo
cd terraform-aws-demo
```

Create `main.tf`:
```hcl
terraform {
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = "~> 5.0"
    }
  }
}

provider "aws" {
  region = "us-east-1"
}
```

**Breaking this down:**

**terraform block** — Declares provider requirements
- `source` — Where to download the provider (`hashicorp/aws`)
- `version` — Version constraint (`~> 5.0` means any 5.x version)

**provider block** — Configures the provider
- `region` — AWS region to create resources in
- Credentials are read from `~/.aws/credentials` automatically

**Step 4: Initialize**

```bash
terraform init
```

**Output:**
```
Initializing the backend...

Initializing provider plugins...
- Finding hashicorp/aws versions matching "~> 5.0"...
- Installing hashicorp/aws v5.31.0...
- Installed hashicorp/aws v5.31.0 (signed by HashiCorp)

Terraform has created a lock file .terraform.lock.hcl to record the provider
selections it made above. Include this file in your version control repository
so that Terraform can guarantee to make the same selections by default when
you run "terraform init" in the future.

Terraform has been successfully initialized!
```

**What happened:**
1. Terraform read your `required_providers` block
2. Downloaded the AWS provider plugin (~200MB) from the Terraform Registry
3. Stored it in `.terraform/providers/`
4. Created `.terraform.lock.hcl` to lock the provider version

You're now ready to create AWS resources.

</div>

</details>

---

<details>
<summary><strong>3. How Providers Work</strong></summary>

<div style="margin-left: 16px; margin-right: 16px; margin-top: 8px; margin-bottom: 8px;">

Let's see what happens under the hood when you use a provider.

**The Flow:**

```
Your Code (.tf)
    ↓
Terraform Core
    ↓
AWS Provider Plugin
    ↓
AWS API
    ↓
AWS Infrastructure
```

**Step-by-Step Example:**

You write:
```hcl
resource "aws_s3_bucket" "demo" {
  bucket = "my-terraform-bucket-12345"
}
```

**When you run terraform apply:**

**1. Terraform Core reads your code**
- Sees `resource "aws_s3_bucket"`
- Knows this is an AWS resource
- Passes it to the AWS provider plugin

**2. AWS Provider translates to API call**
```
POST https://s3.amazonaws.com/
Action=CreateBucket
Bucket=my-terraform-bucket-12345
Region=us-east-1
```

**3. AWS API creates the bucket**
Returns:
```json
{
  "Location": "/my-terraform-bucket-12345",
  "BucketArn": "arn:aws:s3:::my-terraform-bucket-12345"
}
```

**4. AWS Provider passes response back to Terraform**
Terraform saves to state:
```json
{
  "type": "aws_s3_bucket",
  "name": "demo",
  "attributes": {
    "bucket": "my-terraform-bucket-12345",
    "arn": "arn:aws:s3:::my-terraform-bucket-12345",
    "region": "us-east-1"
  }
}
```

**Provider as API Wrapper**

Each provider is essentially a sophisticated API client that:
- Handles authentication (API keys, OAuth, service accounts)
- Manages rate limiting and retries
- Translates Terraform's generic operations (create, read, update, delete) into platform-specific API calls
- Converts API responses into Terraform state format
- Implements provider-specific logic (AWS tags, Azure resource groups, GCP projects)

**Provider Configuration Options**

Different providers support different configuration:

**AWS:**
```hcl
provider "aws" {
  region     = "us-east-1"
  profile    = "production"
  
  default_tags {
    tags = {
      Environment = "prod"
      ManagedBy   = "Terraform"
    }
  }
}
```

**Azure:**
```hcl
provider "azurerm" {
  features {}
  subscription_id = "xxxxx"
  tenant_id       = "xxxxx"
}
```

**Google Cloud:**
```hcl
provider "google" {
  project = "my-gcp-project"
  region  = "us-central1"
}
```

Each provider has its own authentication model and configuration options.

</div>

</details>

---

<details>
<summary><strong>4. Resources — Creating Infrastructure</strong></summary>

<div style="margin-left: 16px; margin-right: 16px; margin-top: 8px; margin-bottom: 8px;">

Resources are the most important element in Terraform. They represent infrastructure components you want to create.

**Resource Syntax:**

```hcl
resource "TYPE" "NAME" {
  argument1 = value1
  argument2 = value2
}
```

- **TYPE** — The resource type (e.g., `aws_instance`, `aws_s3_bucket`)
- **NAME** — Your local name for this resource (used in Terraform code only)
- **Arguments** — Configuration specific to the resource type

**Example 1: S3 Bucket**

```hcl
resource "aws_s3_bucket" "assets" {
  bucket = "my-app-assets-bucket"
}
```

**Example 2: EC2 Instance**

```hcl
resource "aws_instance" "web" {
  ami           = "ami-0c55b159cbfafe1f0"
  instance_type = "t3.micro"
  
  tags = {
    Name = "WebServer"
  }
}
```

**Example 3: VPC**

```hcl
resource "aws_vpc" "main" {
  cidr_block = "10.0.0.0/16"
  
  tags = {
    Name = "main-vpc"
  }
}
```

**Resource Arguments**

Each resource type has:
- **Required arguments** — Must be specified
- **Optional arguments** — Have defaults or can be omitted
- **Computed attributes** — Set by the provider after creation

**Example:**

```hcl
resource "aws_instance" "web" {
  ami           = "ami-0c55b159cbfafe1f0"  # Required
  instance_type = "t3.micro"               # Required
  
  key_name      = "my-key"                 # Optional
  monitoring    = true                     # Optional
  
  # These are computed (set after creation)
  # id            = (known after apply)
  # public_ip     = (known after apply)
  # private_ip    = (known after apply)
}
```

**Referencing Resources**

You can reference one resource from another:

```hcl
resource "aws_vpc" "main" {
  cidr_block = "10.0.0.0/16"
}

resource "aws_subnet" "public" {
  vpc_id     = aws_vpc.main.id
  cidr_block = "10.0.1.0/24"
}
```

**Syntax:** `TYPE.NAME.ATTRIBUTE`
- `aws_vpc.main.id` — The ID of the VPC resource named "main"

Terraform automatically:
- Creates the VPC first
- Waits for the VPC ID
- Creates the subnet with that VPC ID
- Tracks the dependency in state

**Resource Meta-Arguments**

All resources support these meta-arguments:

**depends_on** — Explicit dependency
```hcl
resource "aws_instance" "web" {
  ami           = "ami-abc123"
  instance_type = "t3.micro"
  
  depends_on = [aws_security_group.allow_http]
}
```

**count** — Create multiple instances
```hcl
resource "aws_instance" "web" {
  count         = 3
  ami           = "ami-abc123"
  instance_type = "t3.micro"
}
```

**for_each** — Create instances from a map/set
```hcl
resource "aws_s3_bucket" "apps" {
  for_each = toset(["app1", "app2", "app3"])
  bucket   = "${each.key}-bucket"
}
```

**We'll cover count and for_each in depth in File 05.**

**Practical Example: Complete Web Server**

```hcl
# VPC
resource "aws_vpc" "main" {
  cidr_block = "10.0.0.0/16"
  
  tags = {
    Name = "main-vpc"
  }
}

# Subnet
resource "aws_subnet" "public" {
  vpc_id     = aws_vpc.main.id
  cidr_block = "10.0.1.0/24"
  
  tags = {
    Name = "public-subnet"
  }
}

# Security Group
resource "aws_security_group" "web" {
  name   = "allow_http"
  vpc_id = aws_vpc.main.id
  
  ingress {
    from_port   = 80
    to_port     = 80
    protocol    = "tcp"
    cidr_blocks = ["0.0.0.0/0"]
  }
}

# EC2 Instance
resource "aws_instance" "web" {
  ami                    = "ami-0c55b159cbfafe1f0"
  instance_type          = "t3.micro"
  subnet_id              = aws_subnet.public.id
  vpc_security_group_ids = [aws_security_group.web.id]
  
  tags = {
    Name = "WebServer"
  }
}
```

**When you run terraform apply:**
1. Creates VPC
2. Creates Subnet (depends on VPC)
3. Creates Security Group (depends on VPC)
4. Creates EC2 Instance (depends on Subnet and Security Group)

Terraform handles the dependency graph automatically.

</div>

</details>

---

<details>
<summary><strong>5. Data Sources — Reading Existing Infrastructure</strong></summary>

<div style="margin-left: 16px; margin-right: 16px; margin-top: 8px; margin-bottom: 8px;">

**Resources** create infrastructure. **Data sources** read existing infrastructure.

Use data sources when:
- You need information about resources created outside Terraform
- You want to reference existing infrastructure without managing it
- You need dynamic lookups (latest AMI, available zones)

**Data Source Syntax:**

```hcl
data "TYPE" "NAME" {
  filter_argument = value
}
```

**Example 1: Fetch Latest Amazon Linux AMI**

```hcl
data "aws_ami" "amazon_linux" {
  most_recent = true
  owners      = ["amazon"]
  
  filter {
    name   = "name"
    values = ["amzn2-ami-hvm-*-x86_64-gp2"]
  }
}

resource "aws_instance" "web" {
  ami           = data.aws_ami.amazon_linux.id
  instance_type = "t3.micro"
}
```

**What happens:**
1. Terraform queries AWS for the latest Amazon Linux 2 AMI
2. Finds `ami-0c55b159cbfafe1f0`
3. Uses that AMI ID to create the instance

**Example 2: Read Existing VPC**

```hcl
data "aws_vpc" "existing" {
  filter {
    name   = "tag:Name"
    values = ["production-vpc"]
  }
}

resource "aws_subnet" "new" {
  vpc_id     = data.aws_vpc.existing.id
  cidr_block = "10.0.3.0/24"
}
```

You're creating a new subnet in an existing VPC that Terraform doesn't manage.

**Example 3: Get Available Availability Zones**

```hcl
data "aws_availability_zones" "available" {
  state = "available"
}

resource "aws_subnet" "multi_az" {
  count             = 3
  vpc_id            = aws_vpc.main.id
  cidr_block        = "10.0.${count.index}.0/24"
  availability_zone = data.aws_availability_zones.available.names[count.index]
}
```

Creates 3 subnets across different availability zones dynamically.

**Example 4: Fetch Current AWS Region**

```hcl
data "aws_region" "current" {}

output "region" {
  value = data.aws_region.current.name
}
```

**Resource vs Data Source**

| Aspect | Resource | Data Source |
|--------|----------|-------------|
| **Purpose** | Create/manage infrastructure | Read existing infrastructure |
| **Keyword** | `resource` | `data` |
| **State** | Tracked in state | Read-only, not fully tracked |
| **Lifecycle** | Created/updated/destroyed | Queried on each plan/apply |
| **Reference** | `aws_instance.web.id` | `data.aws_ami.latest.id` |

**Practical Example: Dynamic Infrastructure**

```hcl
# Get latest AMI
data "aws_ami" "ubuntu" {
  most_recent = true
  owners      = ["099720109477"] # Canonical
  
  filter {
    name   = "name"
    values = ["ubuntu/images/hvm-ssd/ubuntu-jammy-22.04-amd64-server-*"]
  }
}

# Get available zones
data "aws_availability_zones" "available" {
  state = "available"
}

# Get current region
data "aws_region" "current" {}

# Create instance with dynamic data
resource "aws_instance" "web" {
  ami               = data.aws_ami.ubuntu.id
  instance_type     = "t3.micro"
  availability_zone = data.aws_availability_zones.available.names[0]
  
  tags = {
    Name   = "WebServer"
    Region = data.aws_region.current.name
  }
}
```

This code works in any AWS region without modification.

</div>

</details>

---

<details>
<summary><strong>6. Provider Versioning & Lock Files</strong></summary>

<div style="margin-left: 16px; margin-right: 16px; margin-top: 8px; margin-bottom: 8px;">

Providers are versioned separately from Terraform. AWS might release v5.32.0 today, v5.33.0 next week.
Without version locking, your code could break when a new provider version introduces changes.

**Version Constraints**

```hcl
terraform {
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = "~> 5.0"
    }
  }
}
```

**Version constraint operators:**

| Constraint | Meaning | Example |
|------------|---------|---------|
| `= 5.30.0` | Exact version | Only 5.30.0 |
| `!= 5.30.0` | Not this version | Any except 5.30.0 |
| `> 5.30.0` | Greater than | 5.30.1, 5.31.0, 6.0.0 |
| `>= 5.30.0` | Greater or equal | 5.30.0 and above |
| `< 5.31.0` | Less than | 5.30.x and below |
| `<= 5.31.0` | Less or equal | 5.31.0 and below |
| `~> 5.30` | Pessimistic | 5.30.x (any patch) |
| `~> 5.0` | Pessimistic | 5.x.x (any minor/patch) |

**Recommended: Use pessimistic constraints**

```hcl
version = "~> 5.0"
```

This means:
- ✅ Allow minor and patch updates (5.1.0, 5.31.0)
- ❌ Block major updates (6.0.0)

Keeps you up to date with bug fixes and features without breaking changes.

**The Lock File**

When you run `terraform init`, Terraform creates `.terraform.lock.hcl`:

```hcl
provider "registry.terraform.io/hashicorp/aws" {
  version     = "5.31.0"
  constraints = "~> 5.0"
  hashes = [
    "h1:Xxxxxxxxxxxxxxxxxxxxxxxxxxx",
    "zh:Yyyyyyyyyyyyyyyyyyyyyyyyyyyy",
  ]
}
```

**This file:**
- Records the exact provider version used
- Includes cryptographic hashes for security
- Ensures everyone on your team uses the same version

**Commit `.terraform.lock.hcl` to Git.**

**Updating Providers**

To upgrade to a new version:

```bash
terraform init -upgrade
```

Terraform will:
1. Check for newer versions matching your constraints
2. Download the latest compatible version
3. Update `.terraform.lock.hcl`

**Example:**

Current: `v5.31.0`
Constraint: `~> 5.0`
Available: `v5.35.0`

After `terraform init -upgrade` → `v5.35.0`

**Version Management Best Practices**

1. **Always use version constraints** — Never leave version blank
2. **Use pessimistic constraints** — `~> 5.0` allows safe updates
3. **Commit lock file** — Ensures reproducible builds
4. **Test upgrades** — Run in dev/staging before production
5. **Review changelogs** — Check for breaking changes before upgrading

**Handling Breaking Changes**

Provider v6.0.0 is released with breaking changes.
Your constraint: `~> 5.0`

You're protected. Terraform won't upgrade to v6.x automatically.

When ready to upgrade:
1. Read the v6.0.0 migration guide
2. Update your code
3. Change constraint to `~> 6.0`
4. Run `terraform init -upgrade`
5. Test thoroughly

</div>

</details>

---

<details>
<summary><strong>7. Multi-Provider Configurations</strong></summary>

<div style="margin-left: 16px; margin-right: 16px; margin-top: 8px; margin-bottom: 8px;">

Terraform can manage multiple cloud providers in a single configuration.

**Example 1: AWS + Azure**

```hcl
terraform {
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = "~> 5.0"
    }
    azurerm = {
      source  = "hashicorp/azurerm"
      version = "~> 3.0"
    }
  }
}

provider "aws" {
  region = "us-east-1"
}

provider "azurerm" {
  features {}
}

# AWS resource
resource "aws_s3_bucket" "data" {
  bucket = "my-data-bucket"
}

# Azure resource
resource "azurerm_storage_account" "data" {
  name                     = "mydatastorageacct"
  resource_group_name      = "my-resource-group"
  location                 = "East US"
  account_tier             = "Standard"
  account_replication_type = "LRS"
}
```

**Example 2: Multiple AWS Regions**

```hcl
provider "aws" {
  alias  = "us_east"
  region = "us-east-1"
}

provider "aws" {
  alias  = "us_west"
  region = "us-west-2"
}

# Bucket in us-east-1
resource "aws_s3_bucket" "east" {
  provider = aws.us_east
  bucket   = "my-east-bucket"
}

# Bucket in us-west-2
resource "aws_s3_bucket" "west" {
  provider = aws.us_west
  bucket   = "my-west-bucket"
}
```

**Provider aliases** let you define multiple instances of the same provider.

**Example 3: Multi-Cloud Architecture**

```hcl
terraform {
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = "~> 5.0"
    }
    cloudflare = {
      source  = "cloudflare/cloudflare"
      version = "~> 4.0"
    }
    datadog = {
      source  = "DataDog/datadog"
      version = "~> 3.0"
    }
  }
}

provider "aws" {
  region = "us-east-1"
}

provider "cloudflare" {
  api_token = var.cloudflare_token
}

provider "datadog" {
  api_key = var.datadog_api_key
  app_key = var.datadog_app_key
}

# AWS infrastructure
resource "aws_instance" "web" {
  ami           = "ami-0c55b159cbfafe1f0"
  instance_type = "t3.micro"
}

# Cloudflare DNS
resource "cloudflare_record" "web" {
  zone_id = var.cloudflare_zone_id
  name    = "app"
  value   = aws_instance.web.public_ip
  type    = "A"
}

# Datadog monitoring
resource "datadog_monitor" "web" {
  name    = "Web Server Monitor"
  type    = "metric alert"
  message = "Web server is down!"
  query   = "avg(last_5m):avg:system.cpu.user{host:${aws_instance.web.id}} > 90"
}
```

One Terraform configuration managing:
- AWS compute
- Cloudflare DNS
- Datadog monitoring

**When to Use Multi-Provider**

- **Multi-cloud strategy** — Spread workloads across AWS and Azure
- **Regional redundancy** — Resources in multiple AWS regions
- **Service integration** — Cloud infrastructure + SaaS tools (GitHub, Datadog, PagerDuty)
- **Hybrid infrastructure** — On-prem + cloud (VMware + AWS)

**Key Points**

- Each provider downloads independently during `terraform init`
- State file tracks resources from all providers
- Dependencies work across providers (CloudFlare DNS → AWS instance IP)
- Each provider has its own authentication requirements

</div>

</details>

---

**You now understand the bridge between Terraform and the cloud.**

Providers are the translators. Resources are the things you build. Data sources are the things you read.
Version locking keeps your infrastructure stable. Multi-provider configs let you manage everything from one place.

Next, we'll make our infrastructure flexible and reusable through **variables, outputs, and locals** — the building blocks of dynamic Terraform configurations.