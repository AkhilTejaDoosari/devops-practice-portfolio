# **09. Advanced Patterns & Lifecycle — Mastering Terraform Behavior**
# Advanced Patterns & Lifecycle

You've built infrastructure with resources, modules, and remote state.
But sometimes you need more control over how Terraform behaves.

What if you want to prevent accidental deletion of a critical database?
What if you need to run a script after creating an EC2 instance?
What if you have existing infrastructure you want Terraform to manage?

**Terraform provides advanced meta-arguments and patterns for these scenarios.**

Lifecycle rules let you control resource behavior. Provisioners execute commands during resource creation. Import brings existing infrastructure under Terraform management. Moved blocks help you refactor without downtime.

We'll explore the tools that give you fine-grained control over your infrastructure's lifecycle.

---

## Table of Contents
1. [Lifecycle Meta-Arguments](#1-lifecycle-meta-arguments)
2. [Provisioners](#2-provisioners)
3. [Null Resource & Triggers](#3-null-resource--triggers)
4. [Time Provider](#4-time-provider)
5. [Terraform Import](#5-terraform-import)
6. [Moved Blocks](#6-moved-blocks)
7. [Replace & Taint](#7-replace--taint)
8. [Preconditions & Postconditions](#8-preconditions--postconditions)

---

<details>
<summary><strong>1. Lifecycle Meta-Arguments</strong></summary>

<div style="margin-left: 16px; margin-right: 16px; margin-top: 8px; margin-bottom: 8px;">

Lifecycle meta-arguments control how Terraform creates, updates, and destroys resources.

**Available lifecycle arguments:**

```hcl
resource "aws_instance" "web" {
  # ... resource config
  
  lifecycle {
    create_before_destroy = true
    prevent_destroy       = true
    ignore_changes        = [tags]
    replace_triggered_by  = [null_resource.example.id]
  }
}
```

**1.1 create_before_destroy**

By default, Terraform destroys the old resource, then creates the new one.
With `create_before_destroy`, Terraform creates the new resource first, then destroys the old one.

**Default behavior (destroy first):**
```
1. Destroy old instance
2. Create new instance
   ↓ Downtime between steps 1 and 2
```

**With create_before_destroy:**
```
1. Create new instance
2. Switch traffic
3. Destroy old instance
   ↓ No downtime
```

**Example:**

```hcl
resource "aws_instance" "web" {
  ami           = "ami-0c55b159cbfafe1f0"
  instance_type = "t3.micro"
  
  lifecycle {
    create_before_destroy = true
  }
}
```

When you change the AMI, Terraform:
1. Creates a new instance with the new AMI
2. Waits for it to be ready
3. Destroys the old instance

**Use case:** Load-balanced web servers where you can't afford downtime.

**1.2 prevent_destroy**

Protects critical resources from accidental deletion.

```hcl
resource "aws_db_instance" "production" {
  allocated_storage = 100
  engine            = "postgres"
  instance_class    = "db.t3.large"
  
  lifecycle {
    prevent_destroy = true
  }
}
```

If you try to destroy:
```bash
terraform destroy
```

Error:
```
Error: Instance cannot be destroyed

  on main.tf line 10:
  10: resource "aws_db_instance" "production" {

Resource aws_db_instance.production has lifecycle.prevent_destroy set,
but the plan calls for this resource to be destroyed.
```

**To actually destroy it:**
1. Remove `prevent_destroy` or set to `false`
2. Run `terraform apply` to update the config
3. Run `terraform destroy`

**Use case:** Production databases, S3 buckets with critical data, any resource that should never be accidentally deleted.

**1.3 ignore_changes**

Tells Terraform to ignore changes to specific attributes.

**Problem:** Auto Scaling changes instance count, but Terraform wants to revert it.

```hcl
resource "aws_autoscaling_group" "web" {
  desired_capacity = 3
  max_size         = 10
  min_size         = 1
  
  # Auto Scaling changes this based on load
  # Terraform should not revert it
  lifecycle {
    ignore_changes = [desired_capacity]
  }
}
```

**Common use cases:**

**Ignore tags added by other tools:**
```hcl
resource "aws_instance" "web" {
  ami           = "ami-abc123"
  instance_type = "t3.micro"
  
  tags = {
    Name = "WebServer"
  }
  
  lifecycle {
    ignore_changes = [tags]
  }
}
```

AWS Systems Manager adds tags → Terraform ignores them.

**Ignore all changes:**
```hcl
lifecycle {
  ignore_changes = all
}
```

**Use case:** Resource managed by Terraform initially, but modified by external systems afterward.

**1.4 replace_triggered_by**

Forces replacement when another resource changes.

```hcl
resource "null_resource" "config_version" {
  triggers = {
    config = filemd5("app-config.yaml")
  }
}

resource "aws_instance" "app" {
  ami           = "ami-abc123"
  instance_type = "t3.micro"
  
  lifecycle {
    replace_triggered_by = [null_resource.config_version.id]
  }
}
```

When `app-config.yaml` changes → `null_resource` updates → instance replaced.

**Combining lifecycle arguments:**

```hcl
resource "aws_db_instance" "prod" {
  allocated_storage = 100
  engine            = "postgres"
  
  lifecycle {
    prevent_destroy       = true
    ignore_changes        = [password]
    create_before_destroy = true
  }
}
```

**Note on for_each and count:**

Lifecycle rules work with resources created via loops (see **File 05: Loops & Conditionals** for full loop syntax):

```hcl
resource "aws_instance" "web" {
  count = 3
  
  ami           = "ami-abc123"
  instance_type = "t3.micro"
  
  lifecycle {
    create_before_destroy = true
  }
}
```

All 3 instances inherit the lifecycle rules.

</div>

</details>

---

<details>
<summary><strong>2. Provisioners</strong></summary>

<div style="margin-left: 16px; margin-right: 16px; margin-top: 8px; margin-bottom: 8px;">

Provisioners run scripts or commands on resources during creation or destruction.

**⚠️ Warning:** Provisioners are a last resort. Prefer:
1. User data scripts (for EC2)
2. Configuration management tools (Ansible, Chef)
3. Container images (with pre-configured software)

Use provisioners only when no other option works.

**Types of provisioners:**
- `local-exec` — Run command on your local machine
- `remote-exec` — Run command on the remote resource
- `file` — Copy files to the remote resource

**2.1 local-exec**

Runs commands on the machine running Terraform.

```hcl
resource "aws_instance" "web" {
  ami           = "ami-abc123"
  instance_type = "t3.micro"
  
  provisioner "local-exec" {
    command = "echo ${self.public_ip} >> ip_list.txt"
  }
}
```

After creating the instance, Terraform runs the command locally.

**Use case:** Update local configuration files, trigger webhooks, send notifications.

**Example: Send Slack notification:**

```hcl
resource "aws_instance" "web" {
  ami           = "ami-abc123"
  instance_type = "t3.micro"
  
  provisioner "local-exec" {
    command = <<-EOT
      curl -X POST https://hooks.slack.com/services/XXX \
        -H 'Content-Type: application/json' \
        -d '{"text":"Instance ${self.id} created at ${self.public_ip}"}'
    EOT
  }
}
```

**2.2 remote-exec**

Runs commands on the remote resource via SSH or WinRM.

```hcl
resource "aws_instance" "web" {
  ami           = "ami-abc123"
  instance_type = "t3.micro"
  key_name      = "my-key"
  
  connection {
    type        = "ssh"
    user        = "ubuntu"
    private_key = file("~/.ssh/id_rsa")
    host        = self.public_ip
  }
  
  provisioner "remote-exec" {
    inline = [
      "sudo apt-get update",
      "sudo apt-get install -y nginx",
      "sudo systemctl start nginx"
    ]
  }
}
```

**Connection block attributes:**

```hcl
connection {
  type        = "ssh"           # or "winrm"
  user        = "ubuntu"
  password    = var.password    # or use private_key
  private_key = file("~/.ssh/id_rsa")
  host        = self.public_ip
  port        = 22
  timeout     = "5m"
}
```

**Remote-exec with script file:**

```hcl
provisioner "remote-exec" {
  script = "setup.sh"
}
```

**2.3 file**

Copies files to the remote resource.

```hcl
resource "aws_instance" "web" {
  ami           = "ami-abc123"
  instance_type = "t3.micro"
  key_name      = "my-key"
  
  connection {
    type        = "ssh"
    user        = "ubuntu"
    private_key = file("~/.ssh/id_rsa")
    host        = self.public_ip
  }
  
  provisioner "file" {
    source      = "app-config.yaml"
    destination = "/tmp/app-config.yaml"
  }
  
  provisioner "remote-exec" {
    inline = [
      "sudo mv /tmp/app-config.yaml /etc/app/config.yaml",
      "sudo systemctl restart app"
    ]
  }
}
```

**Copy directory:**

```hcl
provisioner "file" {
  source      = "configs/"
  destination = "/tmp/configs"
}
```

**2.4 Provisioner Timing**

**Creation-time (default):**
```hcl
provisioner "local-exec" {
  command = "echo Instance created"
}
```

Runs when resource is created.

**Destroy-time:**
```hcl
provisioner "local-exec" {
  when    = destroy
  command = "echo Instance ${self.id} is being destroyed"
}
```

Runs before resource is destroyed.

**2.5 Failure Behavior**

**Default (fail):**
If provisioner fails, resource is marked as tainted.

```hcl
provisioner "remote-exec" {
  inline = ["sudo apt-get install nginx"]
}
```

If this fails, next `terraform apply` will destroy and recreate the instance.

**Continue on failure:**

```hcl
provisioner "remote-exec" {
  inline = ["sudo apt-get install nginx"]
  
  on_failure = continue
}
```

If it fails, Terraform continues without marking the resource as tainted.

**Why provisioners are discouraged:**

1. **Not idempotent** — Running twice may cause errors
2. **State not tracked** — Terraform doesn't know if script succeeded
3. **Hard to test** — Can't easily validate without creating resources
4. **Order dependencies** — Tricky to coordinate multiple provisioners
5. **Better alternatives exist** — User data, config management, containers

**When to use provisioners:**

- Bootstrapping config management (install Ansible, then Ansible handles the rest)
- Running one-time setup that can't be in user data
- Integration with external systems (webhooks, notifications)

**Better alternatives:**

**Instead of remote-exec:**
```hcl
# ❌ Provisioner
provisioner "remote-exec" {
  inline = ["sudo apt-get install nginx"]
}

# ✅ User data
resource "aws_instance" "web" {
  user_data = <<-EOF
    #!/bin/bash
    apt-get update
    apt-get install -y nginx
  EOF
}
```

**Instead of local-exec:**
```hcl
# ❌ Provisioner
provisioner "local-exec" {
  command = "ansible-playbook setup.yml"
}

# ✅ Separate Ansible run
# Run Terraform first, then Ansible
```

</div>

</details>

---

<details>
<summary><strong>3. Null Resource & Triggers</strong></summary>

<div style="margin-left: 16px; margin-right: 16px; margin-top: 8px; margin-bottom: 8px;">

`null_resource` doesn't create real infrastructure. It's a placeholder for running provisioners or tracking changes.

**Basic null_resource:**

```hcl
resource "null_resource" "example" {
  provisioner "local-exec" {
    command = "echo Hello World"
  }
}
```

Runs the command every time you apply.

**Problem:** Runs every time, even if nothing changed.

**Solution: triggers**

Triggers tell Terraform when to recreate the null_resource.

```hcl
resource "null_resource" "cluster" {
  triggers = {
    cluster_instance_ids = join(",", aws_instance.cluster[*].id)
  }
  
  provisioner "local-exec" {
    command = "echo Cluster IDs changed"
  }
}
```

Recreates only when cluster instance IDs change.

**Common trigger patterns:**

**Trigger on file change:**
```hcl
resource "null_resource" "config_deploy" {
  triggers = {
    config_hash = filemd5("config.yaml")
  }
  
  provisioner "local-exec" {
    command = "scp config.yaml server:/etc/app/config.yaml"
  }
}
```

**Trigger on variable change:**
```hcl
resource "null_resource" "restart_service" {
  triggers = {
    version = var.app_version
  }
  
  provisioner "local-exec" {
    command = "ssh server 'sudo systemctl restart app'"
  }
}
```

**Trigger always (every apply):**
```hcl
resource "null_resource" "always_run" {
  triggers = {
    timestamp = timestamp()
  }
  
  provisioner "local-exec" {
    command = "echo Always runs: ${timestamp()}"
  }
}
```

**Trigger on other resource changes:**
```hcl
resource "aws_instance" "web" {
  ami = "ami-abc123"
}

resource "null_resource" "notify" {
  triggers = {
    instance_id = aws_instance.web.id
  }
  
  provisioner "local-exec" {
    command = "echo Instance ${aws_instance.web.id} created"
  }
}
```

**Use case: Run script after all resources are ready:**

```hcl
resource "aws_instance" "web" {
  count = 3
  # ... config
}

resource "aws_lb" "main" {
  # ... config
}

resource "null_resource" "setup_complete" {
  depends_on = [
    aws_instance.web,
    aws_lb.main
  ]
  
  provisioner "local-exec" {
    command = "python3 post_deployment.py"
  }
}
```

Script runs only after all instances and load balancer are ready.

**Destroying null_resource:**

```bash
terraform destroy -target=null_resource.example
```

Or remove from code:
```hcl
# Delete this block
# resource "null_resource" "example" { ... }
```

</div>

</details>

---

<details>
<summary><strong>4. Time Provider</strong></summary>

<div style="margin-left: 16px; margin-right: 16px; margin-top: 8px; margin-bottom: 8px;">

The time provider creates resources that wait or rotate based on time.

**Install time provider:**

```hcl
terraform {
  required_providers {
    time = {
      source  = "hashicorp/time"
      version = "~> 0.9"
    }
  }
}
```

**4.1 time_sleep**

Waits a specified duration before continuing.

```hcl
resource "aws_instance" "web" {
  ami           = "ami-abc123"
  instance_type = "t3.micro"
}

resource "time_sleep" "wait_for_boot" {
  depends_on = [aws_instance.web]
  
  create_duration = "60s"
}

resource "null_resource" "configure" {
  depends_on = [time_sleep.wait_for_boot]
  
  provisioner "remote-exec" {
    # Instance has had 60 seconds to boot
    inline = ["sudo systemctl start app"]
  }
}
```

**Use case:** Wait for a service to fully start before continuing.

**4.2 time_static**

Creates a timestamp that doesn't change.

```hcl
resource "time_static" "deployment_time" {}

resource "aws_instance" "web" {
  ami           = "ami-abc123"
  instance_type = "t3.micro"
  
  tags = {
    DeployedAt = time_static.deployment_time.rfc3339
  }
}
```

The timestamp is set once and never changes, even on subsequent applies.

**4.3 time_rotating**

Creates a timestamp that rotates after a specified duration.

```hcl
resource "time_rotating" "monthly_rotation" {
  rotation_days = 30
}

resource "aws_iam_access_key" "rotated" {
  user = "service-account"
  
  lifecycle {
    replace_triggered_by = [time_rotating.monthly_rotation]
  }
}
```

Every 30 days, `time_rotating` changes, triggering replacement of the access key.

**Use case:** Automatic credential rotation.

**Time functions:**

Remember, these are built-in functions (no provider needed):

```hcl
# Current timestamp (changes every apply)
timestamp()

# Format timestamp
formatdate("YYYY-MM-DD", timestamp())

# Add duration
timeadd(timestamp(), "24h")
```

**Example: Expiring resources:**

```hcl
locals {
  expiration_date = timeadd(timestamp(), "168h")  # 7 days
}

resource "aws_instance" "temporary" {
  ami           = "ami-abc123"
  instance_type = "t3.micro"
  
  tags = {
    ExpiresAt = formatdate("YYYY-MM-DD hh:mm:ss", local.expiration_date)
  }
}
```

</div>

</details>

---

<details>
<summary><strong>5. Terraform Import</strong></summary>

<div style="margin-left: 16px; margin-right: 16px; margin-top: 8px; margin-bottom: 8px;">

Import brings existing infrastructure under Terraform management.

**Scenario:** You created an EC2 instance manually in AWS Console. Now you want Terraform to manage it.

**Step 1: Write the resource block**

```hcl
resource "aws_instance" "existing" {
  ami           = "ami-0c55b159cbfafe1f0"
  instance_type = "t3.micro"
  
  # Add other required attributes
}
```

**Step 2: Import the resource**

```bash
terraform import aws_instance.existing i-0abc123def456
```

Terraform:
1. Queries AWS for instance `i-0abc123def456`
2. Adds it to state
3. Associates it with `aws_instance.existing`

**Step 3: Align code with reality**

```bash
terraform plan
```

If plan shows changes, your code doesn't match the actual resource.
Update your code to match:

```hcl
resource "aws_instance" "existing" {
  ami                    = "ami-0c55b159cbfafe1f0"
  instance_type          = "t3.micro"
  subnet_id              = "subnet-abc123"
  vpc_security_group_ids = ["sg-def456"]
  
  tags = {
    Name = "ExistingServer"
  }
}
```

Run plan again until it shows "No changes."

**Import syntax:**

```bash
terraform import RESOURCE_TYPE.RESOURCE_NAME RESOURCE_ID
```

Examples:
```bash
# EC2 instance
terraform import aws_instance.web i-0abc123

# S3 bucket
terraform import aws_s3_bucket.data my-bucket-name

# VPC
terraform import aws_vpc.main vpc-abc123

# Security group
terraform import aws_security_group.web sg-def456
```

**Import with for_each:**

For resources created with `for_each` (see **File 05** for full syntax):

```hcl
resource "aws_instance" "servers" {
  for_each = toset(["web", "api", "cache"])
  
  ami           = "ami-abc123"
  instance_type = "t3.micro"
}
```

Import each instance:
```bash
terraform import 'aws_instance.servers["web"]' i-0abc111
terraform import 'aws_instance.servers["api"]' i-0abc222
terraform import 'aws_instance.servers["cache"]' i-0abc333
```

**Import with count:**

```hcl
resource "aws_instance" "cluster" {
  count = 3
  # ...
}
```

Import:
```bash
terraform import 'aws_instance.cluster[0]' i-0abc111
terraform import 'aws_instance.cluster[1]' i-0abc222
terraform import 'aws_instance.cluster[2]' i-0abc333
```

**Common import IDs:**

| Resource | Import ID |
|----------|-----------|
| `aws_instance` | Instance ID (`i-0abc123`) |
| `aws_s3_bucket` | Bucket name |
| `aws_vpc` | VPC ID (`vpc-abc123`) |
| `aws_subnet` | Subnet ID (`subnet-abc123`) |
| `aws_security_group` | Security group ID (`sg-abc123`) |
| `aws_db_instance` | DB instance identifier |
| `aws_iam_user` | Username |
| `aws_iam_role` | Role name |

Check provider docs for specific resource import IDs.

**Bulk import script:**

```bash
#!/bin/bash
# import_instances.sh

INSTANCES=(
  "i-0abc111:web-1"
  "i-0abc222:web-2"
  "i-0abc333:web-3"
)

for item in "${INSTANCES[@]}"; do
  id="${item%%:*}"
  name="${item##*:}"
  terraform import "aws_instance.web[\"$name\"]" "$id"
done
```

**Limitations:**

- Import only adds to state — doesn't generate code
- You must write the resource block manually
- Code must match reality exactly
- Not all resources support import (check docs)

**Import blocks (Terraform 1.5+):**

New import block syntax:

```hcl
import {
  to = aws_instance.web
  id = "i-0abc123def456"
}

resource "aws_instance" "web" {
  # Terraform will generate this for you
}
```

Run:
```bash
terraform plan -generate-config-out=generated.tf
```

Terraform generates the resource configuration automatically.

</div>

</details>

---

<details>
<summary><strong>6. Moved Blocks</strong></summary>

<div style="margin-left: 16px; margin-right: 16px; margin-top: 8px; margin-bottom: 8px;">

Moved blocks let you refactor resources without destroying and recreating them.

**Scenario:** You renamed a resource in code.

**Old code:**
```hcl
resource "aws_instance" "web" {
  ami = "ami-abc123"
}
```

**New code:**
```hcl
resource "aws_instance" "app" {
  ami = "ami-abc123"
}
```

**Without moved block:**
```bash
terraform plan
```

Output:
```
Plan: 1 to add, 0 to change, 1 to destroy.

  - aws_instance.web will be destroyed
  + aws_instance.app will be created
```

Terraform thinks you deleted one resource and added another.
**This causes downtime.**

**With moved block:**

```hcl
moved {
  from = aws_instance.web
  to   = aws_instance.app
}

resource "aws_instance" "app" {
  ami = "ami-abc123"
}
```

```bash
terraform plan
```

Output:
```
Terraform will perform the following actions:

  # aws_instance.web has moved to aws_instance.app
    resource "aws_instance" "app" {
        id = "i-0abc123"
        # ... (no changes)
    }

Plan: 0 to add, 0 to change, 0 to destroy.
```

**No destroy. No recreation. Just a state update.**

**Moved block syntax:**

```hcl
moved {
  from = OLD_ADDRESS
  to   = NEW_ADDRESS
}
```

**Example: Rename resource:**

```hcl
moved {
  from = aws_s3_bucket.data
  to   = aws_s3_bucket.storage
}
```

**Example: Move into module:**

```hcl
moved {
  from = aws_instance.web
  to   = module.web_servers.aws_instance.web
}
```

**Example: Move out of module:**

```hcl
moved {
  from = module.old.aws_vpc.main
  to   = aws_vpc.main
}
```

**Example: Rename module:**

```hcl
moved {
  from = module.web
  to   = module.application
}
```

**Multiple moved blocks:**

```hcl
moved {
  from = aws_instance.web_1
  to   = aws_instance.app[0]
}

moved {
  from = aws_instance.web_2
  to   = aws_instance.app[1]
}

resource "aws_instance" "app" {
  count = 2
  # ...
}
```

**Moved with for_each (see File 05 for loop syntax):**

```hcl
moved {
  from = aws_instance.servers[0]
  to   = aws_instance.servers["web"]
}

resource "aws_instance" "servers" {
  for_each = toset(["web", "api"])
  # ...
}
```

**When to use moved:**

- Renaming resources
- Restructuring modules
- Converting from count to for_each
- Moving resources between modules
- Refactoring without downtime

**After apply, you can remove the moved block** — it's no longer needed.

</div>

</details>

---

<details>
<summary><strong>7. Replace & Taint</strong></summary>

<div style="margin-left: 16px; margin-right: 16px; margin-top: 8px; margin-bottom: 8px;">

Sometimes you need to force Terraform to recreate a resource.

**7.1 Replace (Terraform 1.0+)**

```bash
terraform apply -replace="aws_instance.web"
```

Forces replacement of the instance even if nothing changed in code.

**Use case:** Instance is unhealthy but Terraform doesn't know.

**Replace specific instance in count/for_each:**

```bash
terraform apply -replace="aws_instance.cluster[1]"
terraform apply -replace='aws_instance.servers["api"]'
```

**Multiple replacements:**

```bash
terraform apply -replace="aws_instance.web" -replace="aws_instance.api"
```

**7.2 Taint (Deprecated, use replace instead)**

Old approach:
```bash
terraform taint aws_instance.web
terraform apply
```

Marks resource as tainted → next apply recreates it.

**Replace is better:**
- Single command (no two-step process)
- Clearer intent
- Works with -target

**7.3 Forcing Replacement in Code**

Use `replace_triggered_by` (see section 1):

```hcl
resource "null_resource" "force_replace" {
  triggers = {
    version = var.app_version
  }
}

resource "aws_instance" "app" {
  ami = "ami-abc123"
  
  lifecycle {
    replace_triggered_by = [null_resource.force_replace.id]
  }
}
```

Change `var.app_version` → instance replaced.

</div>

</details>

---

<details>
<summary><strong>8. Preconditions & Postconditions</strong></summary>

<div style="margin-left: 16px; margin-right: 16px; margin-top: 8px; margin-bottom: 8px;">

Preconditions and postconditions validate assumptions before and after resource operations.

**8.1 Preconditions**

Check conditions before creating/updating a resource.

```hcl
resource "aws_instance" "web" {
  ami           = var.ami_id
  instance_type = var.instance_type
  
  lifecycle {
    precondition {
      condition     = can(regex("^ami-", var.ami_id))
      error_message = "AMI ID must start with 'ami-'"
    }
  }
}
```

If condition fails, Terraform stops before creating the resource.

**Example: Check variable range:**

```hcl
variable "instance_count" {
  type = number
}

resource "aws_instance" "cluster" {
  count = var.instance_count
  
  ami = "ami-abc123"
  
  lifecycle {
    precondition {
      condition     = var.instance_count >= 1 && var.instance_count <= 10
      error_message = "Instance count must be between 1 and 10"
    }
  }
}
```

**Example: Check data source result:**

```hcl
data "aws_ami" "latest" {
  most_recent = true
  owners      = ["amazon"]
}

resource "aws_instance" "web" {
  ami = data.aws_ami.latest.id
  
  lifecycle {
    precondition {
      condition     = data.aws_ami.latest.state == "available"
      error_message = "AMI must be in available state"
    }
  }
}
```

**8.2 Postconditions**

Check conditions after creating/updating a resource.

```hcl
resource "aws_instance" "web" {
  ami           = "ami-abc123"
  instance_type = "t3.micro"
  
  lifecycle {
    postcondition {
      condition     = self.public_ip != ""
      error_message = "Instance must have a public IP"
    }
  }
}
```

If instance doesn't get a public IP, Terraform fails.

**Example: Verify instance is running:**

```hcl
resource "aws_instance" "web" {
  ami           = "ami-abc123"
  instance_type = "t3.micro"
  
  lifecycle {
    postcondition {
      condition     = self.instance_state == "running"
      error_message = "Instance must be in running state"
    }
  }
}
```

**8.3 Preconditions in Data Sources**

```hcl
data "aws_ami" "latest" {
  most_recent = true
  owners      = ["amazon"]
  
  lifecycle {
    postcondition {
      condition     = self.state == "available"
      error_message = "AMI must be available"
    }
  }
}
```

**8.4 Multiple Conditions**

```hcl
resource "aws_db_instance" "main" {
  allocated_storage = var.storage_gb
  engine            = var.db_engine
  
  lifecycle {
    precondition {
      condition     = var.storage_gb >= 20
      error_message = "Storage must be at least 20 GB"
    }
    
    precondition {
      condition     = contains(["postgres", "mysql"], var.db_engine)
      error_message = "Engine must be postgres or mysql"
    }
    
    postcondition {
      condition     = self.endpoint != ""
      error_message = "Database must have an endpoint"
    }
  }
}
```

**When to use preconditions/postconditions:**

**Preconditions:**
- Validate variable values before creating resources
- Check data source results
- Verify environment state

**Postconditions:**
- Verify resource was created correctly
- Check critical attributes
- Validate expected state

**Note:** Validation in variables (see **File 04**) is often better than preconditions:

```hcl
# ✅ Preferred - validate in variable
variable "instance_count" {
  type = number
  
  validation {
    condition     = var.instance_count >= 1 && var.instance_count <= 10
    error_message = "Must be 1-10"
  }
}

# ⚠️ Works but less ideal - validate in resource
resource "aws_instance" "web" {
  lifecycle {
    precondition {
      condition     = var.instance_count >= 1 && var.instance_count <= 10
      error_message = "Must be 1-10"
    }
  }
}
```

</div>

</details>

---

**You now control the lifecycle of your infrastructure.**

Lifecycle meta-arguments prevent accidents and reduce downtime. Provisioners handle edge cases. Null resources trigger side effects. Import brings existing infrastructure under management. Moved blocks enable refactoring without destruction.

These advanced patterns give you surgical control over how Terraform behaves.

Next, we'll cover **security, validation, and best practices** — how to protect your infrastructure, validate inputs, organize code, test configurations, and optimize performance.