# **10. Real-World Production Scripts — Professional Automation in Action**
> Complete production-ready scripts demonstrating all concepts in practice.

---

## Table of Contents
- [1. Why Production Scripts Matter](#1-why-production-scripts-matter)
- [2. Complete Deployment Pipeline](#2-complete-deployment-pipeline)
- [3. Backup and Recovery System](#3-backup-and-recovery-system)
- [4. Monitoring and Alerting](#4-monitoring-and-alerting)
- [5. Log Management and Analysis](#5-log-management-and-analysis)
- [6. Database Management](#6-database-management)
- [7. Infrastructure Provisioning](#7-infrastructure-provisioning)
- [8. CI/CD Integration](#8-cicd-integration)
- [9. Security Automation](#9-security-automation)
- [10. Performance Analysis](#10-performance-analysis)
- [11. Disaster Recovery](#11-disaster-recovery)
- [12. Best Practices Summary](#12-best-practices-summary)
- [13. Script Library](#13-script-library)
- [14. Final Thoughts](#14-final-thoughts)

---

<details>
<summary><strong>1. Why Production Scripts Matter</strong></summary>

<div style="margin-left: 16px; margin-right: 16px; margin-top: 8px; margin-bottom: 8px;">

You've learned the pieces.
Now see them work together.

Production scripts aren't just code.
They're the automation that keeps systems running.

What makes a script "production-ready"?
- Comprehensive error handling
- Detailed logging
- Graceful failure modes
- Security by default
- Observable behavior
- Idempotent operations
- Clear documentation

Understanding production patterns means:
- you can build reliable automation
- you can debug issues quickly
- you can scale operations
- you can sleep at night

This isn't about perfect code.
It's about code that works reliably when it matters most — in production, at 3 AM, when things go wrong.

</div>

</details>

---

<details>
<summary><strong>2. Complete Deployment Pipeline</strong></summary>

<div style="margin-left: 16px; margin-right: 16px; margin-top: 8px; margin-bottom: 8px;">

### BASH-444 — Zero-Downtime Deployment Script

```bash copy
#!/bin/bash
#
# deploy.sh - Production deployment with zero downtime
#
# USAGE:
#   deploy.sh [OPTIONS] <environment> <version>
#
# OPTIONS:
#   -v, --verbose          Verbose output
#   -d, --dry-run          Dry run mode
#   -f, --force            Skip confirmations
#   --skip-tests           Skip health checks
#   --rollback             Rollback to previous version
#
# EXAMPLES:
#   deploy.sh production v1.2.3
#   deploy.sh --dry-run staging v1.2.3
#   deploy.sh --rollback production
#

set -euo pipefail

# ============================================================================
# Configuration
# ============================================================================

readonly SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
readonly VERSION="2.0.0"
readonly LOG_DIR="/var/log/deployment"
readonly STATE_DIR="/var/lib/deployment"
readonly LOCK_FILE="/var/run/deployment.lock"

# Deployment settings
readonly HEALTH_CHECK_RETRIES=30
readonly HEALTH_CHECK_INTERVAL=2
readonly ROLLOUT_TIMEOUT=600
readonly BACKUP_RETENTION_DAYS=7

# Initialize
mkdir -p "$LOG_DIR" "$STATE_DIR"

# ============================================================================
# Global Variables
# ============================================================================

VERBOSE=0
DRY_RUN=0
FORCE=0
SKIP_TESTS=0
ROLLBACK_MODE=0

ENVIRONMENT=""
TARGET_VERSION=""
CURRENT_VERSION=""
DEPLOYMENT_ID=""
LOG_FILE=""

# ============================================================================
# Logging
# ============================================================================

setup_logging() {
    DEPLOYMENT_ID="deploy_$(date +%Y%m%d_%H%M%S)_$$"
    LOG_FILE="$LOG_DIR/${DEPLOYMENT_ID}.log"
    
    exec > >(tee -a "$LOG_FILE")
    exec 2>&1
}

log() {
    local level=$1
    shift
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] [$level] $@"
}

log_info() { log "INFO" "$@"; }
log_warn() { log "WARN" "$@"; }
log_error() { log "ERROR" "$@"; }
log_debug() { [ $VERBOSE -eq 1 ] && log "DEBUG" "$@"; }

# ============================================================================
# Error Handling
# ============================================================================

readonly ERR_INVALID_ARGS=1
readonly ERR_VALIDATION_FAILED=2
readonly ERR_DEPLOYMENT_FAILED=3
readonly ERR_ROLLBACK_FAILED=4
readonly ERR_LOCK_FAILED=5

error_handler() {
    local line=$1
    log_error "Error on line $line: ${BASH_COMMAND}"
    log_error "Deployment failed (ID: $DEPLOYMENT_ID)"
    
    # Attempt automatic rollback
    if [ "$ROLLBACK_MODE" -eq 0 ] && [ -n "$CURRENT_VERSION" ]; then
        log_warn "Attempting automatic rollback to $CURRENT_VERSION"
        rollback_deployment || log_error "Automatic rollback failed!"
    fi
    
    cleanup
    exit $ERR_DEPLOYMENT_FAILED
}

trap 'error_handler ${LINENO}' ERR

# ============================================================================
# Cleanup
# ============================================================================

cleanup() {
    log_info "Cleanup started"
    
    # Release lock
    if [ -f "$LOCK_FILE" ]; then
        local lock_pid=$(cat "$LOCK_FILE" 2>/dev/null || echo "")
        if [ "$lock_pid" = "$$" ]; then
            rm -f "$LOCK_FILE"
            log_debug "Lock released"
        fi
    fi
    
    # Cleanup temp files
    rm -rf "/tmp/deploy_$$"
    
    log_info "Cleanup complete"
}

trap cleanup EXIT

# ============================================================================
# Locking
# ============================================================================

acquire_lock() {
    if [ -f "$LOCK_FILE" ]; then
        local lock_pid=$(cat "$LOCK_FILE")
        
        if kill -0 "$lock_pid" 2>/dev/null; then
            log_error "Deployment already running (PID: $lock_pid)"
            return $ERR_LOCK_FAILED
        else
            log_warn "Removing stale lock file"
            rm -f "$LOCK_FILE"
        fi
    fi
    
    echo $$ > "$LOCK_FILE"
    log_debug "Lock acquired"
}

# ============================================================================
# Validation
# ============================================================================

validate_environment() {
    case $ENVIRONMENT in
        dev|staging|production)
            log_info "Environment: $ENVIRONMENT"
            ;;
        *)
            log_error "Invalid environment: $ENVIRONMENT"
            log_error "Must be: dev, staging, or production"
            return $ERR_INVALID_ARGS
            ;;
    esac
}

validate_version() {
    if [ "$ROLLBACK_MODE" -eq 1 ]; then
        return 0
    fi
    
    if [[ ! $TARGET_VERSION =~ ^v[0-9]+\.[0-9]+\.[0-9]+$ ]]; then
        log_error "Invalid version format: $TARGET_VERSION"
        log_error "Expected: vX.Y.Z (e.g., v1.2.3)"
        return $ERR_INVALID_ARGS
    fi
    
    log_info "Version: $TARGET_VERSION"
}

check_prerequisites() {
    log_info "Checking prerequisites"
    
    local required_commands=(kubectl docker aws jq)
    local missing=()
    
    for cmd in "${required_commands[@]}"; do
        if ! command -v "$cmd" &>/dev/null; then
            missing+=("$cmd")
        fi
    done
    
    if [ ${#missing[@]} -gt 0 ]; then
        log_error "Missing required commands: ${missing[*]}"
        return $ERR_VALIDATION_FAILED
    fi
    
    # Check kubectl connectivity
    if ! kubectl cluster-info &>/dev/null; then
        log_error "Cannot connect to Kubernetes cluster"
        return $ERR_VALIDATION_FAILED
    fi
    
    # Check AWS credentials
    if ! aws sts get-caller-identity &>/dev/null; then
        log_error "Invalid AWS credentials"
        return $ERR_VALIDATION_FAILED
    fi
    
    log_info "Prerequisites OK"
}

# ============================================================================
# State Management
# ============================================================================

save_state() {
    local state_file="$STATE_DIR/${ENVIRONMENT}.state"
    
    cat > "$state_file" << EOF
DEPLOYMENT_ID=$DEPLOYMENT_ID
TIMESTAMP=$(date +%s)
VERSION=$TARGET_VERSION
PREVIOUS_VERSION=$CURRENT_VERSION
STATUS=deployed
EOF
    
    log_debug "State saved: $state_file"
}

load_state() {
    local state_file="$STATE_DIR/${ENVIRONMENT}.state"
    
    if [ -f "$state_file" ]; then
        source "$state_file"
        CURRENT_VERSION=${VERSION:-unknown}
        log_info "Current version: $CURRENT_VERSION"
    else
        log_warn "No previous deployment state found"
        CURRENT_VERSION="unknown"
    fi
}

# ============================================================================
# Deployment Steps
# ============================================================================

pull_image() {
    log_info "Pulling Docker image"
    
    local image="registry.example.com/myapp:$TARGET_VERSION"
    local max_attempts=3
    
    for attempt in $(seq 1 $max_attempts); do
        log_debug "Pull attempt $attempt/$max_attempts"
        
        if [ $DRY_RUN -eq 1 ]; then
            log_info "[DRY RUN] Would pull: $image"
            return 0
        fi
        
        if docker pull "$image"; then
            log_info "Image pulled successfully"
            return 0
        fi
        
        if [ $attempt -lt $max_attempts ]; then
            log_warn "Pull failed, retrying in $((attempt * 2))s"
            sleep $((attempt * 2))
        fi
    done
    
    log_error "Failed to pull image after $max_attempts attempts"
    return $ERR_DEPLOYMENT_FAILED
}

create_backup() {
    log_info "Creating backup"
    
    local backup_dir="$STATE_DIR/backups/${ENVIRONMENT}"
    local backup_file="$backup_dir/backup_$(date +%Y%m%d_%H%M%S).tar.gz"
    
    mkdir -p "$backup_dir"
    
    if [ $DRY_RUN -eq 1 ]; then
        log_info "[DRY RUN] Would create backup: $backup_file"
        return 0
    fi
    
    # Backup current deployment manifests
    kubectl get deployment,service,ingress \
        --namespace="$ENVIRONMENT" \
        -o yaml > "/tmp/manifests_$$.yaml"
    
    tar -czf "$backup_file" -C /tmp "manifests_$$.yaml"
    rm -f "/tmp/manifests_$$.yaml"
    
    log_info "Backup created: $backup_file"
    
    # Cleanup old backups
    find "$backup_dir" -name "backup_*.tar.gz" \
        -mtime +$BACKUP_RETENTION_DAYS -delete
}

update_deployment() {
    log_info "Updating Kubernetes deployment"
    
    local deployment="myapp"
    local namespace="$ENVIRONMENT"
    local image="registry.example.com/myapp:$TARGET_VERSION"
    
    if [ $DRY_RUN -eq 1 ]; then
        log_info "[DRY RUN] Would update deployment"
        kubectl set image deployment/$deployment \
            $deployment=$image \
            --namespace="$namespace" \
            --dry-run=client
        return 0
    fi
    
    kubectl set image deployment/$deployment \
        $deployment=$image \
        --namespace="$namespace" \
        --record
    
    log_info "Deployment updated"
}

wait_for_rollout() {
    log_info "Waiting for rollout to complete"
    
    local deployment="myapp"
    local namespace="$ENVIRONMENT"
    
    if [ $DRY_RUN -eq 1 ]; then
        log_info "[DRY RUN] Would wait for rollout"
        return 0
    fi
    
    if ! kubectl rollout status deployment/$deployment \
        --namespace="$namespace" \
        --timeout="${ROLLOUT_TIMEOUT}s"; then
        log_error "Rollout failed or timed out"
        return $ERR_DEPLOYMENT_FAILED
    fi
    
    log_info "Rollout complete"
}

verify_deployment() {
    if [ $SKIP_TESTS -eq 1 ]; then
        log_warn "Skipping verification (--skip-tests)"
        return 0
    fi
    
    log_info "Verifying deployment"
    
    local health_url="https://${ENVIRONMENT}.example.com/health"
    local retries=$HEALTH_CHECK_RETRIES
    
    if [ $DRY_RUN -eq 1 ]; then
        log_info "[DRY RUN] Would verify: $health_url"
        return 0
    fi
    
    for attempt in $(seq 1 $retries); do
        log_debug "Health check attempt $attempt/$retries"
        
        if curl -sf --max-time 5 "$health_url" > /dev/null; then
            local response=$(curl -s "$health_url")
            local version=$(echo "$response" | jq -r '.version' 2>/dev/null || echo "unknown")
            
            if [ "$version" = "$TARGET_VERSION" ]; then
                log_info "Health check passed (version: $version)"
                return 0
            else
                log_warn "Version mismatch (expected: $TARGET_VERSION, got: $version)"
            fi
        fi
        
        if [ $attempt -lt $retries ]; then
            sleep $HEALTH_CHECK_INTERVAL
        fi
    done
    
    log_error "Health check failed after $retries attempts"
    return $ERR_DEPLOYMENT_FAILED
}

run_smoke_tests() {
    if [ $SKIP_TESTS -eq 1 ]; then
        return 0
    fi
    
    log_info "Running smoke tests"
    
    local test_script="$SCRIPT_DIR/smoke-tests.sh"
    
    if [ ! -x "$test_script" ]; then
        log_warn "Smoke test script not found: $test_script"
        return 0
    fi
    
    if [ $DRY_RUN -eq 1 ]; then
        log_info "[DRY RUN] Would run smoke tests"
        return 0
    fi
    
    if "$test_script" "$ENVIRONMENT"; then
        log_info "Smoke tests passed"
    else
        log_error "Smoke tests failed"
        return $ERR_DEPLOYMENT_FAILED
    fi
}

# ============================================================================
# Rollback
# ============================================================================

rollback_deployment() {
    log_warn "Rolling back deployment"
    
    local deployment="myapp"
    local namespace="$ENVIRONMENT"
    
    if [ $DRY_RUN -eq 1 ]; then
        log_info "[DRY RUN] Would rollback deployment"
        return 0
    fi
    
    if ! kubectl rollout undo deployment/$deployment \
        --namespace="$namespace"; then
        log_error "Rollback command failed"
        return $ERR_ROLLBACK_FAILED
    fi
    
    log_info "Rollback initiated"
    
    if ! kubectl rollout status deployment/$deployment \
        --namespace="$namespace" \
        --timeout=300s; then
        log_error "Rollback verification failed"
        return $ERR_ROLLBACK_FAILED
    fi
    
    log_info "Rollback complete"
}

# ============================================================================
# Notifications
# ============================================================================

send_notification() {
    local status=$1
    local message=$2
    
    log_info "Notification: $message"
    
    # Slack notification
    if [ -n "${SLACK_WEBHOOK:-}" ]; then
        local color="good"
        [ "$status" != "success" ] && color="danger"
        
        curl -sf -X POST "$SLACK_WEBHOOK" \
            -H 'Content-Type: application/json' \
            -d "{
                \"attachments\": [{
                    \"color\": \"$color\",
                    \"title\": \"Deployment $status\",
                    \"text\": \"$message\",
                    \"fields\": [
                        {\"title\": \"Environment\", \"value\": \"$ENVIRONMENT\", \"short\": true},
                        {\"title\": \"Version\", \"value\": \"$TARGET_VERSION\", \"short\": true},
                        {\"title\": \"Deployment ID\", \"value\": \"$DEPLOYMENT_ID\", \"short\": false}
                    ],
                    \"footer\": \"Deployment System\",
                    \"ts\": $(date +%s)
                }]
            }" &>/dev/null || log_warn "Slack notification failed"
    fi
}

# ============================================================================
# Main Deployment Flow
# ============================================================================

deploy() {
    local start_time=$(date +%s)
    
    log_info "=== Deployment Started ==="
    log_info "Environment: $ENVIRONMENT"
    log_info "Target version: $TARGET_VERSION"
    log_info "Current version: $CURRENT_VERSION"
    log_info "Deployment ID: $DEPLOYMENT_ID"
    
    # Validation
    validate_environment || return $?
    validate_version || return $?
    check_prerequisites || return $?
    
    # Production confirmation
    if [ "$ENVIRONMENT" = "production" ] && [ $FORCE -eq 0 ]; then
        echo ""
        echo "╔════════════════════════════════════════╗"
        echo "║   PRODUCTION DEPLOYMENT CONFIRMATION   ║"
        echo "╚════════════════════════════════════════╝"
        echo ""
        echo "Environment:     $ENVIRONMENT"
        echo "Current version: $CURRENT_VERSION"
        echo "Target version:  $TARGET_VERSION"
        echo ""
        read -p "Type 'yes' to proceed: " confirm
        
        if [ "$confirm" != "yes" ]; then
            log_info "Deployment cancelled by user"
            return 0
        fi
    fi
    
    # Execute deployment steps
    pull_image || return $?
    create_backup || return $?
    update_deployment || return $?
    wait_for_rollout || return $?
    verify_deployment || return $?
    run_smoke_tests || return $?
    
    # Save state
    save_state
    
    # Calculate duration
    local end_time=$(date +%s)
    local duration=$((end_time - start_time))
    
    log_info "=== Deployment Complete ==="
    log_info "Duration: ${duration}s"
    log_info "Version: $TARGET_VERSION"
    log_info "Status: SUCCESS"
    
    send_notification "success" \
        "Successfully deployed $TARGET_VERSION to $ENVIRONMENT in ${duration}s"
}

# ============================================================================
# Help
# ============================================================================

show_help() {
    sed -n '/^#/!q;s/^# \?//p' "$0"
}

# ============================================================================
# Argument Parsing
# ============================================================================

parse_args() {
    while [ $# -gt 0 ]; do
        case $1 in
            -v|--verbose)
                VERBOSE=1
                shift
                ;;
            -d|--dry-run)
                DRY_RUN=1
                shift
                ;;
            -f|--force)
                FORCE=1
                shift
                ;;
            --skip-tests)
                SKIP_TESTS=1
                shift
                ;;
            --rollback)
                ROLLBACK_MODE=1
                shift
                ;;
            -h|--help)
                show_help
                exit 0
                ;;
            -*)
                log_error "Unknown option: $1"
                show_help >&2
                exit $ERR_INVALID_ARGS
                ;;
            *)
                break
                ;;
        esac
    done
    
    # Get positional arguments
    ENVIRONMENT=${1:-}
    TARGET_VERSION=${2:-}
    
    # Validate required args
    if [ -z "$ENVIRONMENT" ]; then
        log_error "Environment required"
        show_help >&2
        exit $ERR_INVALID_ARGS
    fi
    
    if [ "$ROLLBACK_MODE" -eq 0 ] && [ -z "$TARGET_VERSION" ]; then
        log_error "Version required (or use --rollback)"
        show_help >&2
        exit $ERR_INVALID_ARGS
    fi
}

# ============================================================================
# Entry Point
# ============================================================================

main() {
    setup_logging
    parse_args "$@"
    
    log_info "Deployment script v$VERSION"
    
    # Acquire lock
    acquire_lock || exit $ERR_LOCK_FAILED
    
    # Load current state
    load_state
    
    # Execute
    if [ "$ROLLBACK_MODE" -eq 1 ]; then
        rollback_deployment
    else
        deploy
    fi
}

main "$@"
```

</div>

</details>

---

<details>
<summary><strong>3. Backup and Recovery System</strong></summary>

<div style="margin-left: 16px; margin-right: 16px; margin-top: 8px; margin-bottom: 8px;">

### BASH-445 — Comprehensive Backup Script

```bash copy
#!/bin/bash
#
# backup.sh - Automated backup system with retention and verification
#

set -euo pipefail

readonly SCRIPT_NAME="$(basename "$0")"
readonly BACKUP_ROOT="/backup"
readonly LOG_FILE="/var/log/backup.log"
readonly RETENTION_DAYS=30
readonly RETENTION_WEEKS=12
readonly RETENTION_MONTHS=12

# Backup types
declare -A BACKUP_SOURCES=(
    [database]="/var/lib/postgresql"
    [config]="/etc/myapp"
    [uploads]="/var/www/uploads"
    [logs]="/var/log/myapp"
)

log() {
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] $@" | tee -a "$LOG_FILE"
}

# Create backup
create_backup() {
    local name=$1
    local source=$2
    local timestamp=$(date +%Y%m%d_%H%M%S)
    local backup_dir="$BACKUP_ROOT/$name/daily"
    local backup_file="$backup_dir/${name}_${timestamp}.tar.gz"
    
    mkdir -p "$backup_dir"
    
    log "Creating backup: $name"
    log "Source: $source"
    log "Destination: $backup_file"
    
    local start=$(date +%s)
    
    # Create backup with progress
    tar -czf "$backup_file" \
        --exclude='*.tmp' \
        --exclude='*.log' \
        -C "$(dirname "$source")" \
        "$(basename "$source")" \
        2>&1 | tee -a "$LOG_FILE"
    
    local end=$(date +%s)
    local duration=$((end - start))
    local size=$(du -h "$backup_file" | cut -f1)
    
    log "Backup complete: $backup_file"
    log "Size: $size, Duration: ${duration}s"
    
    # Verify backup
    if tar -tzf "$backup_file" > /dev/null; then
        log "Backup verified: OK"
    else
        log "Backup verification failed!" >&2
        return 1
    fi
    
    # Create checksum
    sha256sum "$backup_file" > "${backup_file}.sha256"
    
    echo "$backup_file"
}

# Rotate backups
rotate_backups() {
    local name=$1
    local base_dir="$BACKUP_ROOT/$name"
    
    log "Rotating backups: $name"
    
    # Daily -> Weekly (keep last of week)
    local weekly_dir="$base_dir/weekly"
    mkdir -p "$weekly_dir"
    
    local last_week=$(date -d "1 week ago" +%Y%W)
    local weekly_backup=$(ls "$base_dir/daily" 2>/dev/null | \
        grep "^${name}_$(date -d "1 week ago" +%Y%m%d)" | \
        tail -1)
    
    if [ -n "$weekly_backup" ]; then
        mv "$base_dir/daily/$weekly_backup" "$weekly_dir/"
        log "Promoted to weekly: $weekly_backup"
    fi
    
    # Weekly -> Monthly (keep last of month)
    local monthly_dir="$base_dir/monthly"
    mkdir -p "$monthly_dir"
    
    local last_month=$(date -d "1 month ago" +%Y%m)
    local monthly_backup=$(ls "$weekly_dir" 2>/dev/null | \
        grep "^${name}_${last_month}" | \
        tail -1)
    
    if [ -n "$monthly_backup" ]; then
        mv "$weekly_dir/$monthly_backup" "$monthly_dir/"
        log "Promoted to monthly: $monthly_backup"
    fi
    
    # Delete old backups
    find "$base_dir/daily" -name "${name}_*.tar.gz" \
        -mtime +$RETENTION_DAYS -delete
    find "$weekly_dir" -name "${name}_*.tar.gz" \
        -mtime +$((RETENTION_WEEKS * 7)) -delete
    find "$monthly_dir" -name "${name}_*.tar.gz" \
        -mtime +$((RETENTION_MONTHS * 30)) -delete
    
    log "Rotation complete"
}

# List backups
list_backups() {
    local name=$1
    local base_dir="$BACKUP_ROOT/$name"
    
    echo "Backups for: $name"
    echo ""
    
    for type in daily weekly monthly; do
        echo "$type backups:"
        if [ -d "$base_dir/$type" ]; then
            ls -lh "$base_dir/$type" | tail -n +2 | \
                awk '{print "  " $9, "(" $5 ")"}'
        fi
        echo ""
    done
}

# Restore backup
restore_backup() {
    local backup_file=$1
    local restore_dir=${2:-/tmp/restore}
    
    if [ ! -f "$backup_file" ]; then
        log "Backup file not found: $backup_file" >&2
        return 1
    fi
    
    # Verify checksum if exists
    if [ -f "${backup_file}.sha256" ]; then
        log "Verifying checksum..."
        if ! sha256sum -c "${backup_file}.sha256"; then
            log "Checksum verification failed!" >&2
            return 1
        fi
    fi
    
    mkdir -p "$restore_dir"
    
    log "Restoring backup to: $restore_dir"
    tar -xzf "$backup_file" -C "$restore_dir"
    
    log "Restore complete"
}

# Main
main() {
    local action=${1:-backup}
    
    case $action in
        backup)
            log "=== Backup Started ==="
            for name in "${!BACKUP_SOURCES[@]}"; do
                create_backup "$name" "${BACKUP_SOURCES[$name]}"
                rotate_backups "$name"
            done
            log "=== Backup Complete ==="
            ;;
        list)
            local name=${2:-}
            if [ -n "$name" ]; then
                list_backups "$name"
            else
                for name in "${!BACKUP_SOURCES[@]}"; do
                    list_backups "$name"
                done
            fi
            ;;
        restore)
            local backup_file=${2:-}
            local restore_dir=${3:-}
            restore_backup "$backup_file" "$restore_dir"
            ;;
        *)
            echo "Usage: $SCRIPT_NAME {backup|list|restore}" >&2
            exit 1
            ;;
    esac
}

main "$@"
```

</div>

</details>

---

<details>
<summary><strong>4. Monitoring and Alerting</strong></summary>

<div style="margin-left: 16px; margin-right: 16px; margin-top: 8px; margin-bottom: 8px;">

### BASH-446 — System Monitoring Script

```bash copy
#!/bin/bash
#
# monitor.sh - Comprehensive system monitoring with alerting
#

set -euo pipefail

readonly CHECK_INTERVAL=60
readonly ALERT_THRESHOLD_CPU=80
readonly ALERT_THRESHOLD_MEMORY=85
readonly ALERT_THRESHOLD_DISK=90
readonly ALERT_COOLDOWN=300

declare -A last_alert_time

log() {
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] $@"
}

# CPU monitoring
check_cpu() {
    local cpu_usage=$(top -bn1 | grep "Cpu(s)" | \
        sed "s/.*, *\([0-9.]*\)%* id.*/\1/" | \
        awk '{print 100 - $1}')
    
    cpu_usage=${cpu_usage%.*}
    
    log "CPU usage: ${cpu_usage}%"
    
    if ((cpu_usage > ALERT_THRESHOLD_CPU)); then
        send_alert "cpu" \
            "High CPU usage: ${cpu_usage}%" \
            "Threshold: ${ALERT_THRESHOLD_CPU}%"
        
        # Get top processes
        local top_procs=$(ps aux --sort=-%cpu | head -6 | tail -5)
        log "Top CPU processes:\n$top_procs"
    fi
    
    echo "$cpu_usage"
}

# Memory monitoring
check_memory() {
    local mem_info=$(free | grep Mem)
    local total=$(echo "$mem_info" | awk '{print $2}')
    local used=$(echo "$mem_info" | awk '{print $3}')
    local mem_usage=$((used * 100 / total))
    
    log "Memory usage: ${mem_usage}%"
    
    if ((mem_usage > ALERT_THRESHOLD_MEMORY)); then
        send_alert "memory" \
            "High memory usage: ${mem_usage}%" \
            "Threshold: ${ALERT_THRESHOLD_MEMORY}%"
        
        # Get top processes
        local top_procs=$(ps aux --sort=-%mem | head -6 | tail -5)
        log "Top memory processes:\n$top_procs"
    fi
    
    echo "$mem_usage"
}

# Disk monitoring
check_disk() {
    while read -r line; do
        local filesystem=$(echo "$line" | awk '{print $1}')
        local usage=$(echo "$line" | awk '{print $5}' | tr -d '%')
        local mount=$(echo "$line" | awk '{print $6}')
        
        log "Disk usage $mount: ${usage}%"
        
        if ((usage > ALERT_THRESHOLD_DISK)); then
            send_alert "disk_${mount}" \
                "High disk usage on $mount: ${usage}%" \
                "Threshold: ${ALERT_THRESHOLD_DISK}%"
        fi
    done < <(df -h | grep '^/dev/' | grep -v '/boot')
}

# Process monitoring
check_process() {
    local process_name=$1
    
    if pgrep -x "$process_name" > /dev/null; then
        log "Process $process_name: running"
        return 0
    else
        log "Process $process_name: NOT running"
        send_alert "process_${process_name}" \
            "Process not running: $process_name" \
            "Critical process down"
        return 1
    fi
}

# Service monitoring
check_service() {
    local service=$1
    
    if systemctl is-active "$service" &>/dev/null; then
        log "Service $service: active"
        return 0
    else
        log "Service $service: NOT active"
        send_alert "service_${service}" \
            "Service not active: $service" \
            "Critical service down"
        return 1
    fi
}

# Port monitoring
check_port() {
    local host=$1
    local port=$2
    local timeout=5
    
    if timeout $timeout bash -c "echo >/dev/tcp/$host/$port" 2>/dev/null; then
        log "Port $host:$port: open"
        return 0
    else
        log "Port $host:$port: NOT reachable"
        send_alert "port_${host}_${port}" \
            "Port not reachable: $host:$port" \
            "Service may be down"
        return 1
    fi
}

# HTTP endpoint monitoring
check_http() {
    local url=$1
    local expected_code=${2:-200}
    local timeout=10
    
    local response=$(curl -sf -w "\n%{http_code}" \
        --max-time $timeout \
        "$url" 2>/dev/null || echo -e "\n000")
    
    local http_code=$(echo "$response" | tail -1)
    
    if [ "$http_code" = "$expected_code" ]; then
        log "HTTP $url: OK ($http_code)"
        return 0
    else
        log "HTTP $url: FAIL ($http_code)"
        send_alert "http_${url}" \
            "HTTP check failed: $url" \
            "Expected $expected_code, got $http_code"
        return 1
    fi
}

# Alert management
should_send_alert() {
    local alert_key=$1
    local now=$(date +%s)
    local last_alert=${last_alert_time[$alert_key]:-0}
    
    if ((now - last_alert >= ALERT_COOLDOWN)); then
        last_alert_time[$alert_key]=$now
        return 0
    else
        return 1
    fi
}

send_alert() {
    local alert_key=$1
    local title=$2
    local message=$3
    
    if ! should_send_alert "$alert_key"; then
        log "Alert suppressed (cooldown): $alert_key"
        return 0
    fi
    
    log "ALERT: $title - $message"
    
    # Slack notification
    if [ -n "${SLACK_WEBHOOK:-}" ]; then
        curl -sf -X POST "$SLACK_WEBHOOK" \
            -H 'Content-Type: application/json' \
            -d "{
                \"attachments\": [{
                    \"color\": \"danger\",
                    \"title\": \"⚠️  $title\",
                    \"text\": \"$message\",
                    \"footer\": \"$(hostname)\",
                    \"ts\": $(date +%s)
                }]
            }" &>/dev/null
    fi
    
    # Email notification
    if [ -n "${ALERT_EMAIL:-}" ]; then
        echo "$message" | mail -s "Alert: $title" "$ALERT_EMAIL"
    fi
}

# Monitoring loop
monitor_loop() {
    log "Monitoring started (interval: ${CHECK_INTERVAL}s)"
    
    while true; do
        log "=== Health Check ==="
        
        # System metrics
        check_cpu
        check_memory
        check_disk
        
        # Critical processes
        check_process "nginx"
        check_process "postgresql"
        
        # Services
        check_service "nginx"
        check_service "postgresql"
        
        # Ports
        check_port "localhost" "80"
        check_port "localhost" "5432"
        
        # HTTP endpoints
        check_http "http://localhost/health"
        check_http "http://localhost/api/status"
        
        log "=== Check Complete ==="
        
        sleep $CHECK_INTERVAL
    done
}

# Main
main() {
    local action=${1:-monitor}
    
    case $action in
        monitor)
            monitor_loop
            ;;
        once)
            check_cpu
            check_memory
            check_disk
            ;;
        *)
            echo "Usage: $0 {monitor|once}" >&2
            exit 1
            ;;
    esac
}

main "$@"
```

</div>

</details>

---

<details>
<summary><strong>5. Log Management and Analysis</strong></summary>

<div style="margin-left: 16px; margin-right: 16px; margin-top: 8px; margin-bottom: 8px;">

### BASH-447 — Log Analysis Tool

```bash copy
#!/bin/bash
#
# loganalyzer.sh - Parse and analyze application logs
#

set -euo pipefail

# Report errors by time period
analyze_errors() {
    local log_file=$1
    local time_period=${2:-hour}
    
    echo "=== Error Analysis (by $time_period) ==="
    
    case $time_period in
        hour)
            format='%Y-%m-%d %H'
            ;;
        day)
            format='%Y-%m-%d'
            ;;
        *)
            format='%Y-%m-%d %H'
            ;;
    esac
    
    awk -v fmt="$format" '
    /ERROR|FATAL/ {
        # Extract timestamp
        match($0, /[0-9]{4}-[0-9]{2}-[0-9]{2} [0-9]{2}:[0-9]{2}:[0-9]{2}/)
        timestamp = substr($0, RSTART, RLENGTH)
        
        # Format to period
        cmd = "date -d\"" timestamp "\" +\"" fmt "\""
        cmd | getline period
        close(cmd)
        
        errors[period]++
    }
    END {
        for (period in errors) {
            printf "%s: %d errors\n", period, errors[period]
        }
    }
    ' "$log_file" | sort
}

# Find slowest requests
analyze_performance() {
    local log_file=$1
    local top_n=${2:-10}
    
    echo "=== Top $top_n Slowest Requests ==="
    
    grep -E "duration=[0-9]+" "$log_file" | \
        sed -E 's/.*path=([^ ]+).*duration=([0-9]+).*/\2 \1/' | \
        sort -rn | \
        head -$top_n | \
        awk '{printf "%5dms %s\n", $1, $2}'
}

# Most common errors
analyze_error_types() {
    local log_file=$1
    local top_n=${2:-10}
    
    echo "=== Top $top_n Most Common Errors ==="
    
    grep -E "ERROR|FATAL" "$log_file" | \
        sed -E 's/.*\[(ERROR|FATAL)\] //' | \
        cut -d: -f1 | \
        sort | uniq -c | sort -rn | head -$top_n
}

# Traffic analysis
analyze_traffic() {
    local log_file=$1
    
    echo "=== Traffic Analysis ==="
    
    echo "Requests per hour:"
    awk '{
        match($0, /[0-9]{4}-[0-9]{2}-[0-9]{2} [0-9]{2}/)
        hour = substr($0, RSTART, RLENGTH)
        requests[hour]++
    }
    END {
        for (hour in requests) {
            printf "%s: %d\n", hour, requests[hour]
        }
    }' "$log_file" | sort
    
    echo ""
    echo "Top 10 endpoints:"
    grep -oE 'path=[^ ]+' "$log_file" | \
        cut -d= -f2 | \
        sort | uniq -c | sort -rn | head -10
}

# Generate report
generate_report() {
    local log_file=$1
    local report_file="report_$(date +%Y%m%d_%H%M%S).txt"
    
    {
        echo "Log Analysis Report"
        echo "Generated: $(date)"
        echo "Log file: $log_file"
        echo ""
        
        analyze_errors "$log_file"
        echo ""
        
        analyze_error_types "$log_file"
        echo ""
        
        analyze_performance "$log_file"
        echo ""
        
        analyze_traffic "$log_file"
    } > "$report_file"
    
    echo "Report generated: $report_file"
}

# Main
main() {
    local action=${1:-}
    local log_file=${2:-/var/log/app.log}
    
    if [ ! -f "$log_file" ]; then
        echo "Log file not found: $log_file" >&2
        exit 1
    fi
    
    case $action in
        errors)
            analyze_errors "$log_file" "${3:-hour}"
            ;;
        performance)
            analyze_performance "$log_file" "${3:-10}"
            ;;
        traffic)
            analyze_traffic "$log_file"
            ;;
        report)
            generate_report "$log_file"
            ;;
        *)
            echo "Usage: $0 {errors|performance|traffic|report} <logfile>" >&2
            exit 1
            ;;
    esac
}

main "$@"
```

</div>

</details>

---

<details>
<summary><strong>6. Database Management</strong></summary>

<div style="margin-left: 16px; margin-right: 16px; margin-top: 8px; margin-bottom: 8px;">

### BASH-448 — Database Management Script

```bash copy
#!/bin/bash
#
# dbmanager.sh - PostgreSQL database management
#

set -euo pipefail

readonly DB_HOST=${DB_HOST:-localhost}
readonly DB_PORT=${DB_PORT:-5432}
readonly DB_NAME=${DB_NAME:-myapp}
readonly DB_USER=${DB_USER:-postgres}
readonly BACKUP_DIR="/backup/database"

# Backup database
backup_database() {
    local timestamp=$(date +%Y%m%d_%H%M%S)
    local backup_file="$BACKUP_DIR/${DB_NAME}_${timestamp}.sql.gz"
    
    mkdir -p "$BACKUP_DIR"
    
    echo "Creating backup: $backup_file"
    
    pg_dump -h "$DB_HOST" \
            -p "$DB_PORT" \
            -U "$DB_USER" \
            -d "$DB_NAME" \
            --format=plain \
            --no-owner \
            --no-acl | \
        gzip > "$backup_file"
    
    local size=$(du -h "$backup_file" | cut -f1)
    echo "Backup complete: $backup_file ($size)"
}

# Restore database
restore_database() {
    local backup_file=$1
    
    if [ ! -f "$backup_file" ]; then
        echo "Backup file not found: $backup_file" >&2
        return 1
    fi
    
    echo "Restoring from: $backup_file"
    
    gunzip -c "$backup_file" | \
        psql -h "$DB_HOST" \
             -p "$DB_PORT" \
             -U "$DB_USER" \
             -d "$DB_NAME"
    
    echo "Restore complete"
}

# Check database size
check_size() {
    echo "=== Database Size ==="
    psql -h "$DB_HOST" -p "$DB_PORT" -U "$DB_USER" -d "$DB_NAME" -c "
        SELECT
            pg_database.datname,
            pg_size_pretty(pg_database_size(pg_database.datname)) AS size
        FROM pg_database
        ORDER BY pg_database_size(pg_database.datname) DESC;
    "
}

# Check table sizes
check_tables() {
    echo "=== Table Sizes ==="
    psql -h "$DB_HOST" -p "$DB_PORT" -U "$DB_USER" -d "$DB_NAME" -c "
        SELECT
            schemaname,
            tablename,
            pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) AS size
        FROM pg_tables
        WHERE schemaname NOT IN ('pg_catalog', 'information_schema')
        ORDER BY pg_total_relation_size(schemaname||'.'||tablename) DESC
        LIMIT 20;
    "
}

# Vacuum analyze
vacuum_database() {
    echo "Running VACUUM ANALYZE..."
    psql -h "$DB_HOST" -p "$DB_PORT" -U "$DB_USER" -d "$DB_NAME" -c "VACUUM ANALYZE;"
    echo "Complete"
}

# Check slow queries
check_slow_queries() {
    echo "=== Slow Queries ==="
    psql -h "$DB_HOST" -p "$DB_PORT" -U "$DB_USER" -d "$DB_NAME" -c "
        SELECT
            pid,
            now() - query_start AS duration,
            query
        FROM pg_stat_activity
        WHERE state = 'active'
          AND now() - query_start > interval '1 minute'
        ORDER BY duration DESC;
    "
}

# Main
main() {
    local action=${1:-}
    
    case $action in
        backup)
            backup_database
            ;;
        restore)
            restore_database "${2:-}"
            ;;
        size)
            check_size
            check_tables
            ;;
        vacuum)
            vacuum_database
            ;;
        slow)
            check_slow_queries
            ;;
        *)
            cat << EOF
Usage: $0 <command>

Commands:
    backup                  Create database backup
    restore <file>          Restore from backup
    size                    Check database and table sizes
    vacuum                  Run VACUUM ANALYZE
    slow                    Check slow queries
EOF
            exit 1
            ;;
    esac
}

main "$@"
```

</div>

</details>

---

<details>
<summary><strong>12. Best Practices Summary</strong></summary>

<div style="margin-left: 16px; margin-right: 16px; margin-top: 8px; margin-bottom: 8px;">

### The 10 Commandments of Production Bash

1. **Always use strict mode**
   ```bash copy
   set -euo pipefail
   ```

2. **Trap cleanup on exit**
   ```bash copy
   trap cleanup EXIT
   ```

3. **Log everything**
   ```bash copy
   exec > >(tee -a "$LOG_FILE")
   exec 2>&1
   ```

4. **Validate early, fail fast**
   ```bash copy
   validate_prerequisites || exit 1
   ```

5. **Quote all variables**
   ```bash copy
   echo "$var"
   process "$file"
   ```

6. **Use meaningful exit codes**
   ```bash copy
   readonly ERR_INVALID_ARGS=1
   readonly ERR_VALIDATION_FAILED=2
   ```

7. **Provide clear error messages**
   ```bash copy
   log_error "Failed to X because Y (context: Z)"
   ```

8. **Make operations idempotent**
   ```bash copy
   [ -f "$file" ] || create_file "$file"
   ```

9. **Include dry-run mode**
   ```bash copy
   if [ $DRY_RUN -eq 1 ]; then
       echo "[DRY RUN] Would do X"
       return 0
   fi
   ```

10. **Document everything**
    ```bash copy
    # Clear comments
    # Usage examples
    # Expected behavior
    ```

</div>

</details>

---

<details>
<summary><strong>13. Script Library</strong></summary>

<div style="margin-left: 16px; margin-right: 16px; margin-top: 8px; margin-bottom: 8px;">

### Essential Functions Library

```bash copy
#!/bin/bash
# common.sh - Reusable functions library

# ============================================================================
# Logging
# ============================================================================

setup_logging() {
    local log_file=${1:-/var/log/script.log}
    exec > >(tee -a "$log_file")
    exec 2>&1
}

log_info() { echo "[$(date '+%Y-%m-%d %H:%M:%S')] [INFO] $@"; }
log_warn() { echo "[$(date '+%Y-%m-%d %H:%M:%S')] [WARN] $@" >&2; }
log_error() { echo "[$(date '+%Y-%m-%d %H:%M:%S')] [ERROR] $@" >&2; }
log_debug() { [ "${DEBUG:-0}" = "1" ] && echo "[$(date '+%Y-%m-%d %H:%M:%S')] [DEBUG] $@" >&2; }

# ============================================================================
# Error Handling
# ============================================================================

die() {
    log_error "$@"
    exit 1
}

require_root() {
    [ "$EUID" -eq 0 ] || die "This script must be run as root"
}

require_command() {
    local cmd=$1
    command -v "$cmd" &>/dev/null || die "Required command not found: $cmd"
}

# ============================================================================
# File Operations
# ============================================================================

require_file() {
    local file=$1
    [ -f "$file" ] || die "Required file not found: $file"
}

require_directory() {
    local dir=$1
    [ -d "$dir" ] || die "Required directory not found: $dir"
}

safe_mkdir() {
    local dir=$1
    mkdir -p "$dir" || die "Failed to create directory: $dir"
}

backup_file() {
    local file=$1
    local backup="${file}.backup.$(date +%Y%m%d_%H%M%S)"
    cp "$file" "$backup" || die "Failed to backup: $file"
    echo "$backup"
}

# ============================================================================
# Validation
# ============================================================================

validate_integer() {
    local value=$1
    [[ $value =~ ^[0-9]+$ ]] || return 1
}

validate_ip() {
    local ip=$1
    [[ $ip =~ ^[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}$ ]] || return 1
}

validate_email() {
    local email=$1
    [[ $email =~ ^[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Za-z]{2,}$ ]] || return 1
}

# ============================================================================
# System Checks
# ============================================================================

check_disk_space() {
    local path=$1
    local required_mb=$2
    local available=$(df -m "$path" | awk 'NR==2 {print $4}')
    
    if ((available < required_mb)); then
        die "Insufficient disk space: $available MB available, $required_mb MB required"
    fi
}

check_memory() {
    local required_mb=$1
    local available=$(free -m | awk 'NR==2 {print $7}')
    
    if ((available < required_mb)); then
        die "Insufficient memory: $available MB available, $required_mb MB required"
    fi
}

# ============================================================================
# Process Management
# ============================================================================

wait_for_process() {
    local process_name=$1
    local timeout=${2:-60}
    local elapsed=0
    
    while ! pgrep -x "$process_name" > /dev/null; do
        sleep 1
        ((elapsed++))
        
        if ((elapsed >= timeout)); then
            return 1
        fi
    done
    
    return 0
}

wait_for_port() {
    local host=$1
    local port=$2
    local timeout=${3:-60}
    local elapsed=0
    
    while ! timeout 1 bash -c "echo >/dev/tcp/$host/$port" 2>/dev/null; do
        sleep 1
        ((elapsed++))
        
        if ((elapsed >= timeout)); then
            return 1
        fi
    done
    
    return 0
}

# ============================================================================
# HTTP Helpers
# ============================================================================

http_get() {
    local url=$1
    local timeout=${2:-10}
    curl -sf --max-time "$timeout" "$url"
}

http_post() {
    local url=$1
    local data=$2
    local timeout=${3:-10}
    curl -sf -X POST --max-time "$timeout" -d "$data" "$url"
}

wait_for_http() {
    local url=$1
    local timeout=${2:-60}
    local elapsed=0
    
    while ! http_get "$url" &>/dev/null; do
        sleep 1
        ((elapsed++))
        
        if ((elapsed >= timeout)); then
            return 1
        fi
    done
    
    return 0
}

# ============================================================================
# Retry Logic
# ============================================================================

retry() {
    local max_attempts=$1
    local delay=$2
    shift 2
    local command=("$@")
    
    for attempt in $(seq 1 $max_attempts); do
        if "${command[@]}"; then
            return 0
        fi
        
        if ((attempt < max_attempts)); then
            log_warn "Command failed (attempt $attempt/$max_attempts), retrying in ${delay}s"
            sleep "$delay"
        fi
    done
    
    log_error "Command failed after $max_attempts attempts"
    return 1
}

# ============================================================================
# Locking
# ============================================================================

acquire_lock() {
    local lock_file=$1
    local timeout=${2:-0}
    local elapsed=0
    
    while [ -f "$lock_file" ]; do
        local lock_pid=$(cat "$lock_file" 2>/dev/null || echo "")
        
        if [ -n "$lock_pid" ] && ! kill -0 "$lock_pid" 2>/dev/null; then
            log_warn "Removing stale lock"
            rm -f "$lock_file"
            break
        fi
        
        if ((timeout > 0)); then
            if ((elapsed >= timeout)); then
                return 1
            fi
            sleep 1
            ((elapsed++))
        else
            return 1
        fi
    done
    
    echo $$ > "$lock_file"
    return 0
}

release_lock() {
    local lock_file=$1
    local lock_pid=$(cat "$lock_file" 2>/dev/null || echo "")
    
    if [ "$lock_pid" = "$$" ]; then
        rm -f "$lock_file"
    fi
}

# ============================================================================
# Configuration
# ============================================================================

load_env_file() {
    local env_file=$1
    
    if [ ! -f "$env_file" ]; then
        die "Environment file not found: $env_file"
    fi
    
    set -a
    source "$env_file"
    set +a
}

get_config() {
    local key=$1
    local default=${2:-}
    local value="${!key:-$default}"
    
    if [ -z "$value" ]; then
        die "Configuration not set: $key"
    fi
    
    echo "$value"
}

# ============================================================================
# Date/Time
# ============================================================================

timestamp() {
    date +%s
}

timestamp_ms() {
    date +%s%3N
}

format_duration() {
    local seconds=$1
    
    if ((seconds < 60)); then
        echo "${seconds}s"
    elif ((seconds < 3600)); then
        echo "$((seconds / 60))m $((seconds % 60))s"
    else
        echo "$((seconds / 3600))h $(((seconds % 3600) / 60))m"
    fi
}

# ============================================================================
# Performance
# ============================================================================

benchmark() {
    local start=$(date +%s%N)
    "$@"
    local end=$(date +%s%N)
    local duration=$(((end - start) / 1000000))
    echo "Duration: ${duration}ms" >&2
}

# ============================================================================
# Notifications
# ============================================================================

send_slack() {
    local webhook=$1
    local message=$2
    local color=${3:-good}
    
    curl -sf -X POST "$webhook" \
        -H 'Content-Type: application/json' \
        -d "{
            \"attachments\": [{
                \"color\": \"$color\",
                \"text\": \"$message\",
                \"footer\": \"$(hostname)\",
                \"ts\": $(date +%s)
            }]
        }" &>/dev/null
}

send_email() {
    local to=$1
    local subject=$2
    local body=$3
    
    echo "$body" | mail -s "$subject" "$to"
}
```

</div>

</details>

---

<details>
<summary><strong>14. Final Thoughts</strong></summary>

<div style="margin-left: 16px; margin-right: 16px; margin-top: 8px; margin-bottom: 8px;">

### You've Learned Production Bash

Not just syntax.
Not just commands.
But the patterns that make automation reliable.

**What You Can Do Now:**

Build deployment pipelines that handle failures gracefully.
Write monitoring scripts that catch issues before users do.
Create backup systems that you can trust at 3 AM.
Automate operations with confidence.

**Remember:**

Production scripts aren't about being clever.
They're about being reliable.

Good scripts:
- Fail loudly when something's wrong
- Clean up after themselves
- Log what they're doing
- Can be debugged quickly
- Don't surprise you

**The Path Forward:**

Start small. Build one good script.
Then another. Then another.

Each one teaches you something.
Each failure makes you better.

Eventually, you don't just write scripts.
You write systems that keep production running.

That's not about knowing every bash feature.
It's about understanding what can go wrong — and handling it.

---

### Keep Building

The scripts in this file are templates.
Patterns you can adapt.
Starting points for your automation.

Take them.
Modify them.
Make them yours.

And when you deploy that first production script at 2 AM and it just works?

That's when you know you've got it.

---

### Resources for Continued Learning

**Official Documentation:**
- Bash Reference Manual: `man bash`
- Advanced Bash-Scripting Guide: tldp.org/LDP/abs/html/

**Tools:**
- ShellCheck: shellcheck.net (static analysis)
- bashdb: bash debugger
- shfmt: shell script formatter

**Best Practices:**
- Google Shell Style Guide
- Bash Hackers Wiki
- Your own experience

---

### Final Checklist

Before deploying any script to production:

- [ ] Uses strict mode (`set -euo pipefail`)
- [ ] Has comprehensive error handling
- [ ] Includes detailed logging
- [ ] Cleans up on exit (trap)
- [ ] Validates all inputs
- [ ] Quotes all variables
- [ ] Has meaningful exit codes
- [ ] Includes help text
- [ ] Tested in dry-run mode
- [ ] Reviewed by another engineer
- [ ] Documented expected behavior
- [ ] Has runbook for failures

---

**You're ready.**

Now go build something reliable.

</div>

</details>

---